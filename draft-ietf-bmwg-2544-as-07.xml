<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE rfc SYSTEM "rfc2629.dtd">
<?rfc toc="yes"?>
<?rfc tocompact="yes"?>
<?rfc tocdepth="3"?>
<?rfc tocindent="yes"?>
<?rfc symrefs="yes"?>
<?rfc sortrefs="yes"?>
<?rfc comments="yes"?>
<?rfc inline="yes"?>
<?rfc compact="yes"?>
<?rfc subcompact="no"?>
<rfc category="info" docName="draft-ietf-bmwg-2544-as-07" ipr="trust200902"
     updates="2544">
  <front>
    <title abbrev="RFC 2544 Applicability">RFC 2544 Applicability Statement:
    Use on Production Networks Considered Harmful</title>

    <author fullname="Scott Bradner" initials="S." surname="Bradner">
      <organization>Harvard University</organization>

      <address>
        <postal>
          <street>29 Oxford St.</street>

          <city>Cambridge</city>

          <region>MA</region>

          <code>02138</code>

          <country>USA</country>
        </postal>

        <phone>+1 617 495 3864</phone>

        <facsimile></facsimile>

        <email>sob@harvard.edu</email>

        <uri>http://www.sobco.com</uri>
      </address>
    </author>

    <author fullname="Kevin Dubray" initials="K." surname="Dubray">
      <organization>Juniper Networks</organization>

      <address>
        <postal>
          <street></street>

          <city></city>

          <region></region>

          <code></code>

          <country></country>
        </postal>

        <phone></phone>

        <facsimile></facsimile>

        <email>kdubray@juniper.net</email>

        <uri></uri>
      </address>
    </author>

    <author fullname="Jim McQuaid" initials="J." surname="McQuaid">
      <organization>Turnip Video</organization>

      <address>
        <postal>
          <street>6 Cobbleridge Court</street>

          <city>Durham</city>

          <region>North Carolina</region>

          <code>27713</code>

          <country>USA</country>
        </postal>

        <phone>+1 919-619-3220</phone>

        <facsimile></facsimile>

        <email>jim@turnipvideo.com</email>

        <uri>www.turnipvideo.com</uri>
      </address>
    </author>

    <author fullname="Al Morton" initials="A." surname="Morton">
      <organization>AT&amp;T Labs</organization>

      <address>
        <postal>
          <street>200 Laurel Avenue South</street>

          <city>Middletown,</city>

          <region>NJ</region>

          <code>07748</code>

          <country>USA</country>
        </postal>

        <phone>+1 732 420 1571</phone>

        <facsimile>+1 732 368 1192</facsimile>

        <email>acmorton@att.com</email>

        <uri>http://home.comcast.net/~acmacm/</uri>
      </address>
    </author>

    <date day="18" month="September" year="2012" />

    <abstract>
      <t>Benchmarking Methodology Working Group (BMWG) has been developing key
      performance metrics and laboratory test methods since 1990, and
      continues this work at present. The methods described in RFC 2544 are
      intended to generate traffic that overloads network device resources in
      order to assess their capacity. Overload of shared resources would
      likely be harmful to user traffic performance on a production network,
      and there are further negative consequences identified with production
      application of the methods. This memo clarifies the scope of RFC 2544
      and other IETF BMWG benchmarking work for isolated test environments
      only, and encourages new standards activity for measurement methods
      applicable outside that scope.</t>
    </abstract>
  </front>

  <middle>
    <section title="Introduction">
      <t>This memo clarifies the scope and use of IETF Benchmarking
      Methodology Working Group (BMWG) tests including <xref
      target="RFC2544"></xref>, which discusses and defines several tests that
      may be used to characterize the performance of a network interconnecting
      device. All readers of this memo must read and fully understand <xref
      target="RFC2544"></xref>.</t>

      <t>Benchmarking methodologies (beginning with <xref
      target="RFC2544"></xref>) have always relied on test conditions that can
      only be produced and replicated reliably in the laboratory. These
      methodologies are not appropriate for inclusion in wider specifications
      such as:</t>

      <t><list style="numbers">
          <t>Validation of telecommunication service configuration, such as
          the Committed Information Rate (CIR).</t>

          <t>Validation of performance metrics in a telecommunication Service
          Level Agreement (SLA), such as frame loss and latency.</t>

          <t>Telecommunication service activation testing, where traffic that
          shares network resources with the test might be adversely
          affected.</t>
        </list>Above, we distinguish "telecommunication service" (where a
      network service provider contracts with a customer to transfer
      information between specified interfaces at different geographic
      locations) from the generic term "service". Below, we use the adjective
      "production" to refer to networks carrying live user traffic. <xref
      target="RFC2544"></xref> used the term "real-world" to refer to
      production networks and to differentiate them from test networks.</t>

      <t>Although RFC 2544 has been held up as the standard reference for such
      testing, we believe that the actual methods used vary from <xref
      target="RFC2544"></xref> in significant ways. Since the only citation is
      to <xref target="RFC2544"></xref>, the modifications are opaque to the
      standards community and to users in general.</t>

      <t>Since applying the test traffic and methods described in <xref
      target="RFC2544"></xref> on a production network risks causing overload
      in shared resources there is direct risk of harming user traffic if the
      methods are misused in this way. Therefore, IETF BMWG developed this
      Applicability Statement for <xref target="RFC2544"></xref> to directly
      address the situation.</t>

      <section title="Requirements Language">
        <t>The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
        "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
        document are to be interpreted as described in <xref
        target="RFC2119">RFC 2119</xref>.</t>
      </section>
    </section>

    <section title="Scope and Goals">
      <t>This memo clarifies the scope of <xref target="RFC2544"></xref> with
      the goal to provide guidance to the industry on its applicability, which
      is limited to laboratory testing.</t>
    </section>

    <section title="The Concept of an Isolated Test Environment">
      <t>An Isolated Test Environment (ITE) used with <xref
      target="RFC2544"></xref> methods (as illustrated in Figures 1 through 3
      of <xref target="RFC2544"></xref>) has the ability to:<list
          style="symbols">
          <t>contain the test streams to paths within the desired set-up</t>

          <t>prevent non-test traffic from traversing the test set-up</t>
        </list></t>

      <t>These features allow unfettered experimentation, while at the same
      time protecting lab equipment management/control LANs and other
      production networks from the unwanted effects of the test traffic.</t>
    </section>

    <section title="Why RFC 2544 Methods are intended only for ITE">
      <t>The following sections discuss some of the reasons why <xref
      target="RFC2544"></xref> methods are applicable only for isolated
      laboratory use, and the consequences of applying these methods outside
      the lab environment.</t>

      <section title="Experimental Control and Accuracy">
        <t>All of the tests described in RFC 2544 require that the tester and
        device under test are the only devices on the networks that are
        transmitting data. The presence of other traffic (unwanted on the ITE
        network) would mean that the specified test conditions have not been
        achieved and flawed results are a likely consequence.</t>

        <t>If any other traffic appears and the amount varies over time, the
        repeatability of any test result will likely depend to some degree on
        the amount and variation of the other traffic.</t>

        <t>The presence of other traffic makes accurate, repeatable, and
        consistent measurements of the performance of the device under test
        very unlikely, since the complete details of test conditions will not
        be reported.</t>

        <t>For example, the RFC 2544 Throughput Test attempts to characterize
        a maximum reliable load, thus there will be testing above the maximum
        that causes packet/frame loss. Any other sources of traffic on the
        network will cause packet loss to occur at a tester data rate lower
        than the rate that would be achieved without the extra traffic.</t>
      </section>

      <section title="Containing Damage">
        <t><xref target="RFC2544"></xref> methods, specifically to determine
        Throughput as defined in <xref target="RFC1242"></xref> and other
        benchmarks, may overload the resources of the device under test, and
        may cause failure modes in the device under test. Since failures can
        become the root cause of more wide-spread failure, it is clearly
        desirable to contain all test traffic within the ITE.</t>

        <t>In addition, such testing can have a negative effect on any traffic
        that shares resources with the test stream(s) since, in most cases,
        the traffic load will be close to the capacity of the network
        links.</t>

        <t>Appendix C.2.2 of <xref target="RFC2544"></xref> (as adjusted by
        errata) gives the private IPv4 address range for testing:</t>

        <t>"...The network addresses 198.18.0.0 through 198.19.255.255 have
        been assigned to the BMWG by the IANA for this purpose. This
        assignment was made to minimize the chance of conflict in case a
        testing device were to be accidentally connected to part of the
        Internet. The specific use of the addresses is detailed below."</t>

        <t>In other words, devices operating on the Internet may be configured
        to discard any traffic they observe in this address range, as it is
        intended for laboratory ITE use only. Thus, if testers using the
        assigned testing address ranges are connected to the Internet and test
        packets are forwarded across the Internet, it is likely that the
        packets will be discarded and the test will not work.</t>

        <t>We note that a range of IPv6 addresses has been assigned to BMWG
        for laboratory test purposes, in <xref target="RFC5180"></xref> (as
        amended by errata).</t>

        <t>See the Security Considerations Section below for further
        considerations on containing damage.</t>
      </section>
    </section>

    <section title="Advisory on RFC 2544 Methods in Production Networks">
      <t>The tests in <xref target="RFC2544"></xref> were designed to measure
      the performance of network devices, not of networks, and certainly not
      production networks carrying user traffic on shared resources. There
      will be undesirable consequences when applying these methods outside the
      isolated test environment.</t>

      <t>One negative consequence stems from reliance on frame loss as an
      indicator of resource exhaustion in <xref target="RFC2544"></xref>
      methods. In practice, link-layer and physical-layer errors prevent
      production networks from operating loss-free. The <xref
      target="RFC2544"></xref> methods will not correctly assess Throughput
      when loss from uncontrolled sources is present. Frame loss occurring at
      the SLA levels of some networks could affect every iteration of
      Throughput testing (when each step includes sufficient packets to
      experience facility-related loss). Flawed results waste the time and
      resources of the testing service user and of the service provider when
      called to dispute the measurement. These are additional examples of harm
      that compliance with this advisory should help to avoid. See the
      Appendix for an example.</t>

      <t>The methods described in <xref target="RFC2544"></xref> are intended
      to generate traffic that overloads network device resources in order to
      assess their capacity. Overload of shared resources would likely be
      harmful to user traffic performance on a production network. These tests
      MUST NOT be used on production networks and as discussed above. The
      tests will not produce a reliable or accurate benchmarking result on a
      production network.</t>

      <t><xref target="RFC2544"></xref> methods have never been validated on a
      network path, even when that path is not part of a production network
      and carrying no other traffic. It is unknown whether the tests can be
      used to measure valid and reliable performance of a multi-device,
      multi-network path. It is possible that some of the tests may prove
      valid in some path scenarios, but that work has not been done or has not
      been shared with the IETF community. Thus, such testing is
      contra-indicated by the BMWG.</t>
    </section>

    <section title="Considering Performance Testing in Production Networks">
      <t>The IETF has addressed the problem of production network performance
      measurement by chartering a different working group: IP Performance
      Metrics (IPPM). This working group has developed a set of standard
      metrics to assess the quality, performance, and reliability of Internet
      packet transfer services. These metrics can be measured by network
      operators, end users, or independent testing groups. We note that some
      IPPM metrics differ from RFC 2544 metrics with similar names, and there
      is likely to be confusion if the details are ignored.</t>

      <t>IPPM has not yet standardized methods for raw capacity measurement of
      Internet paths. Such testing needs to adequately consider the strong
      possibility for degradation to any other traffic that may be present due
      to congestion. There are no specific methods proposed for activation of
      a packet transfer service in IPPM at this time. Thus, individuals who
      need to conduct capacity tests on production networks should actively
      participate in standards development to ensure their methods receive
      appropriate industry review and agreement, in the IETF or in alternate
      standards development organizations.</t>

      <t>Other standards may help to fill gaps in telecommunication service
      testing. For example, the IETF has many standards intended to assist
      with network operation, administration and maintenance (OAM), and ITU-T
      Study Group 12 has a Recommendation on service activation test
      methodology <xref target="Y.1564"></xref>.</t>

      <t>The world will not spin off axis while waiting for appropriate and
      standardized methods to emerge from the consensus process.</t>
    </section>

    <section title="Security Considerations">
      <t>This Applicability Statement intends to help preserve the security of
      the Internet by clarifying that the scope of <xref
      target="RFC2544"></xref> and other BMWG memos are all limited to testing
      in a laboratory ITE, thus avoiding accidental Denial of Service attacks
      or congestion due to high traffic volume test streams.</t>

      <t>All Benchmarking activities are limited to technology
      characterization using controlled stimuli in a laboratory environment,
      with dedicated address space and the other constraints <xref
      target="RFC2544"></xref>.</t>

      <t>The benchmarking network topology will be an independent test setup
      and MUST NOT be connected to devices that may forward the test traffic
      into a production network, or misroute traffic to the test management
      network.</t>

      <t>Further, benchmarking is performed on a "black-box" basis, relying
      solely on measurements observable external to the device under
      test/system under test (DUT/SUT).</t>

      <t>Special capabilities SHOULD NOT exist in the DUT/SUT specifically for
      benchmarking purposes. Any implications for network security arising
      from the DUT/SUT SHOULD be identical in the lab and in production
      networks.</t>
    </section>

    <section anchor="IANA" title="IANA Considerations">
      <t>This memo makes no requests of IANA.</t>
    </section>

    <section title="Acknowledgements">
      <t>Thanks to Matt Zekauskas, Bill Cerveny, Barry Constantine, Curtis
      Villamizar, David Newman, and Adrian Farrel for suggesting improvements
      to this memo.</t>

      <t>Specifically, Al Morton would like to thank his co-authors, who
      constitute the complete set of Chairmen-Emeritus of the BMWG, for
      returning from other pursuits to develop this statement and see it
      through to approval. This has been a rare privilege; one that likely
      will not be matched in the IETF again:<figure>
          <preamble></preamble>

          <artwork><![CDATA[   Scott Bradner   served as Chairman from 1990 to 1993
   Jim McQuaid     served as Chairman from 1993 to 1995
   Kevin Dubray    served as Chairman from 1995 to 2006]]></artwork>

          <postamble></postamble>
        </figure></t>

      <t>It's all about the band.</t>
    </section>

    <section title="Appendix - Example of RFC 2544 method failure in production network measurement">
      <t>This Appendix provides an example illustrating how <xref
      target="RFC2544"></xref> methods applied on production networks can
      easily produce a form of harm from flawed and misleading results.</t>

      <t>The <xref target="RFC2544"></xref> Throughput benchmarking method
      usually includes the following steps:</t>

      <t>a. Set the offered traffic level, less than max of the ingress
      link(s).</t>

      <t>b. Send the test traffic through the device under test (DUT) and
      count all frames successfully transferred.</t>

      <t>c. If all frames are received, increment traffic level and repeat
      step b.</t>

      <t>d. If one or more frames are lost, the level is in the DUT-overload
      region (Step b may be repeated at a reduced traffic level to more
      exactly determine the maximum rate at which none of the frames are
      dropped by the DUT, defined as the Throughput <xref
      target="RFC1242"></xref>).</t>

      <t>e. Report the Throughput values, the x-y of graph of frame size and
      Throughput, and other information in accordance with <xref
      target="RFC2544"></xref>.</t>

      <t>In this method, frame loss is the sole indicator of overload and
      therefore the determining factor in the measurement of Throughput using
      the <xref target="RFC2544"></xref> methodology (even though the results
      may not report frame loss per se).</t>

      <t>Frame loss is subject to many factors in addition to operating above
      the Throughput traffic level. These factors include optical interference
      (which may be due to dirty interfaces, cross-over from other signals,
      fiber bend and temperature, etc.) and electrical interference (caused by
      local sources of radio signals, electrical spikes, solar particles,
      etc.). In the laboratory environment many of these issues can be
      carefully controlled through cleaning and isolation. Since <xref
      target="RFC2544"></xref> methodologies are primarily intended to test
      devices and not paths, the total length of path, the number of
      interfaces, and compound risk of random frame loss can be kept to a
      minimum.</t>

      <t>In a production network, however, there will be many interfaces and
      many kilometres of path under test. This considerably increases the risk
      of random frame loss.</t>

      <t>The risk of frame loss caused by outside effects is significantly
      higher in production networks, and significantly higher with long paths
      (both those with long physical path lengths, and those with large
      numbers of interfaces in the path). Thus, the risk of falsely low
      reported Throughput using an <xref target="RFC2544"></xref> methodology
      test is considerably increased in a production network.</t>

      <t>Therefore, to successfully conduct tests with similar objectives to
      those in <xref target="RFC2544"></xref> in a production network, it will
      be necessary to develop modifications to the methodologies defined in
      <xref target="RFC2544"></xref> and standards to describe them.</t>
    </section>
  </middle>

  <back>
    <references title="Normative References">
      <?rfc include='reference.RFC.2544'?>

      <?rfc include='reference.RFC.1242'?>

      <?rfc include="reference.RFC.2119"?>

      <?rfc ?>

      <?rfc include="reference.RFC.5180"?>

      <?rfc ?>

      <?rfc ?>

      <?rfc ?>

      <?rfc ?>

      <?rfc ?>

      <?rfc ?>
    </references>

    <references title="Informative References">
      <reference anchor="Y.1564">
        <front>
          <title>Ethernet Service Activation Test Methodology</title>

          <author fullname="" surname="ITU-T Recommendation Y.1564">
            <organization></organization>
          </author>

          <date month="March" year="2011" />
        </front>
      </reference>

      <?rfc ?>
    </references>
  </back>
</rfc>
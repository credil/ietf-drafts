<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE rfc SYSTEM "rfc2629.dtd">
<?rfc toc="yes"?>
<?rfc tocompact="yes"?>
<?rfc tocdepth="3"?>
<?rfc tocindent="yes"?>
<?rfc symrefs="yes"?>
<?rfc sortrefs="yes"?>
<?rfc comments="yes"?>
<?rfc inline="yes"?>
<?rfc compact="yes"?>
<?rfc subcompact="no"?>
<rfc category="info" docName="draft-tripathi-roll-rpl-simulation-07"
     ipr="trust200902">
  <front>
    <title abbrev="draft-tripathi-roll-rpl-simulation-07">Performance
    Evaluation of Routing Protocol for Low Power and Lossy Networks
    (RPL)</title>

    <author fullname="Joydeep Tripathi" initials="J.T." role="editor"
            surname="Tripathi">
      <organization>Drexel University</organization>

      <address>
        <postal>
          <street>3141 Chestnut Street 7-313</street>

          <city>Philadelphia</city>

          <code>19104</code>

          <region>PA</region>

          <country>USA</country>
        </postal>

        <email>jt369@drexel.edu</email>
      </address>
    </author>

    <author fullname="Jaudelice C. de Oliveira" initials="J. C." role="editor"
            surname="de Oliveira">
      <organization>Drexel University</organization>

      <address>
        <postal>
          <street>3141 Chestnut Street 7-313</street>

          <city>Philadelphia</city>

          <code>19104</code>

          <region>PA</region>

          <country>USA</country>
        </postal>

        <email>jau@ece.drexel.edu</email>
      </address>
    </author>

    <author fullname="JP Vasseur" initials="JP" role="editor"
            surname="Vasseur">
      <organization>Cisco Systems, Inc.</organization>

      <address>
        <postal>
          <street>11, Rue Camille Desmoulins</street>

          <city>Issy Les Moulineaux</city>

          <code>92782</code>

          <region></region>

          <country>France</country>
        </postal>

        <email>jpv@cisco.com</email>
      </address>
    </author>

    <date day="16" month="August" year="2011" />

    <area>Routing Area</area>

    <workgroup>Networking Working Group</workgroup>

    <keyword>RPL</keyword>

    <keyword>ROLL</keyword>

    <abstract>
      <t>This document presents a performance evaluation of the Routing
      Protocol for Low power and Lossy Networks (RPL) for a small outdoor
      deployment of sensor nodes and for a large scale smart meter network.
      Detailed simulations are carried out to produce several routing
      performance metrics using these real-life deployment scenarios.</t>
    </abstract>

    <note title="note">
      <t></t>
    </note>
  </front>

  <middle>
    <section title="Terminology">
      <t>Please refer to the following document for terminology: <xref
      target="I-D.ietf-roll-terminology"></xref>. In addition, the following
      terms are specified:<list>
          <t>PDR: Packet delivery ratio</t>

          <t>CDF: Cumulative Distribution Function.</t>

          <t>Fractional Stretch Factor of link ETX Metric against ideal
          shortest path: The ETX path stretch is defined as the difference
          between the number of expected transmissions (ETX Metric) taken by a
          packet traveling from source to destination, following a route
          determined by RPL and a route determined by a hypothetical ideal
          shortest path routing protocol (using link ETX as the metric). The
          fractional path stretch is the ratio of ETX path stretch to ETX path
          cost for the shortest path route for that source-destination
          pair.</t>

          <t>Stretch factor for node hop distance against ideal shortest path:
          The hop stretch is defined as the difference between the number of
          hop counts taken by a packet traveling from source to destination,
          following a route determined by RPL and by a hypothetical ideal
          shortest path algorithm, both using ETX as the link cost. The
          fractional stretch factor is computed as the ratio of path stretch
          to count value between a source-destination pair for the
          hypothetical shortest path route optimizing ETX path cost.</t>
        </list></t>
    </section>

    <section title="Introduction">
      <t>Designing a routing protocol for Low power and Lossy link Networks
      (LLNs) imposes great challenges, mainly due to low data rates, high
      probability of packet delivery failure, and strict energy constraint in
      nodes. The IETF ROLL Working Group took on this task and specified the
      Routing Protocol for Low power and Lossy Networks (RPL) in <xref
      target="I-D.ietf-roll-rpl"></xref>.</t>

      <t>RPL is designed to meet the core requirements specified in <xref
      target="RFC5826"></xref>,<xref target="RFC5867"></xref>,<xref
      target="RFC5673"> </xref> and <xref target="RFC5548"></xref>.</t>

      <t>This document&rsquo;s contribution is to provide a performance
      evaluation of RPL with respect to several metrics of interest. This is
      accomplished using real data and topologies in a discrete event
      simulator, developed to reproduce the protocol behavior.</t>

      <t>The following metrics are evaluated:</t>

      <t><list style="symbols">
          <t>Path quality metrics;</t>

          <t>Control plane overhead;</t>

          <t>End-to-end delay between nodes;</t>

          <t>Ability to cope with unstable situations (link churns, node
          dying);</t>

          <t>Required resource constraints on nodes (routing table size,
          etc.).</t>
        </list></t>

      <t>Some of these metrics are mentioned in the aforementioned RFCs,
      whereas others have been introduced considering the challenges and
      unique requirements of LLNs, as mentioned in <xref
      target="I-D.ietf-roll-rpl"></xref>. For example, routing in a home
      automation deployment has strict time bounds on protocol convergence
      after any change in topology as mentioned in section 3.4 of <xref
      target="RFC5826"></xref>. <xref target="RFC5673"> </xref> requires
      bounded and guaranteed end-to-end delay for routing in an industrial
      deployment and <xref target="RFC5548"></xref> requires comparatively
      loose bound on latency for end-to-end communication. <xref
      target="RFC5548"></xref> mandates scalability in terms of protocol
      performance for a network of size ranging from 10^2 to 10^4 nodes.</t>

      <t>Although simulation cannot prove formally that a protocol operates
      properly in all situations, it can give a good level of confidence in
      protocol behavior in highly stressful conditions, if and only if real
      life data are used. Simulation is particularly useful when theoretical
      model assumptions may not be applicable to such networks and scenarios.
      In this document, real deployed network data traces have been used to
      model link behaviors and network topologies.</t>
    </section>

    <section title="Methodology and Simulation Setup">
      <t>In the context of this document, RPL has been simulated using OMNET++
      <xref target="OMNETpp"></xref>, a well-known discrete event based
      simulator written in C++ and NED. Castalia-2.2 <xref
      target="Castalia-2.2"></xref> has been used as Wireless Sensor Network
      Simulator framework within OMNET++. The output and events in the
      simulating are visualized with the help of the Network AniMator or NAM,
      which is distributed with NS (Network Simulator)<xref
      target="NS-2"></xref>.</t>

      <t>Note that NS or any of its versions are not used in this simulation
      study. Only the visualization tool was borrowed for verification
      purposes.</t>

      <t>In contrast with theoretical models, which as stated before may have
      assumptions not applicable to lossy links, real-life data has been used
      for two aspects of the simulations:</t>

      <t>* Link failure model: Time varying real network traces containing
      packet delivery probability for each link, over all channels for both
      indoor network deployment and outdoor network deployment.</t>

      <t>* Topology: Gathered from real-life deployment (traces mentioned
      above) as opposed to random topology simulations.</t>

      <t>A 45 node topology, deployed as an outdoor network, shown in Figure
      1, and a 2442 node topology, gathered from a smart meter network
      deployment, were used in the simulations.</t>

      <figure>
        <preamble></preamble>

        <artwork>Figure 1</artwork>

        <postamble>Figure 1: 45 nodes outdoor network topology.</postamble>
      </figure>

      <t>Note that this is just a start to validate the simulation before
      using large scale networks.</t>

      <t>A set of time varying link quality data was gathered from real
      network deployment to form a database used for the simulations. Each
      link in the topology randomly 'picks up' a link model (trace) from the
      database. Each link has a Packet Delivery Ratio (PDR) that varies with
      time (in the simulation, a new PDR is read from the database every 10
      minutes) according to the gathered data. Packets are dropped randomly
      from that link with probability (1 - PDR). Each time a packet is about
      to be sent, the module generates a random number using the Mersenne
      Twister Random number generation method. The random number is compared
      to the PDR to determine whether the packet should be dropped. Note that
      each link uses a different random number generator to maintain true
      randomness in the simulator, and to avoid correlation between links.
      Also, the packet drop applies to all kinds of data and control packets
      (RPL) such as the DIO, DAO, DIS packets defined in <xref
      target="I-D.ietf-roll-rpl"></xref>. Figure 2 shows a typical temporal
      characteristic of links from the indoor network traces used in the
      simulations. The figure shows several links with perfect connectivity,
      some links with PDR as low as 10% and several for which the PDR may vary
      from 30% to 80%, shaprply changing back and forth between high value
      (strong connectivity) and low value (weak connectivity).</t>

      <figure>
        <artwork>Figure 2</artwork>

        <postamble>Figure 2: Example of link characteristics.</postamble>
      </figure>

      <t>In the RPL simulator, the LBR first initiates sending out DIO
      messages, and the DAG is gradually constructed. RPL makes use of trickle
      timers: the protocol sets a minimum time period, with which the nodes
      start re-issuing DAOs, and this minimum period is denoted by the
      parameter I_min. RPL also sets an upper limit on how many times this
      time period can be doubled, and is denoted by the parameter I_doubling,
      as defined in <xref target="I-D.ietf-roll-rpl"></xref>. For the
      simulation, I_min is initially set to 1 second and I_doubling is equal
      to 16, so that maximum time between two consecutive DIO emissions by a
      node (under a steady network condition) is 18.2 hours. The trickle time
      interval for emitting DIO message assumes the initial value of 1 second,
      and then changes over simulation time as mentioned in <xref
      target="I-D.ietf-roll-trickle"></xref>.</t>

      <t>Another objective of this study is to give insight to the network
      administrator on how to tweak the trickle values. These recommendations
      could then be used in applicability statement documents.</t>

      <t>Each node in the network, other than the LBR (Low power and lossy
      Border Router), also emits DAO messages as specified in <xref
      target="I-D.ietf-roll-rpl"></xref>, to initially populate the routing
      tables with the prefixes received from children via the DAO messages to
      support Point to Point (P2P) and Point to Multipoint traffic (P2MP) in
      the "down" direction. During these simulations, it is assumed that each
      node is capable of storing route information for other nodes in the
      network (storing mode of RPL).</t>

      <t>For nodes implementing RPL, as expected, the routing table memory
      requirement varies according to the position in the DODAG (Destination
      Oriented Directed Acyclic Graph). The (worst-case) assumption is made
      that there is no route summarization (aggregation) in the network. Thus
      a node closer to the DAG will have to store more entries in its routing
      table. It is also assumed that all nodes have equal memory capacity to
      store the routing states.</t>

      <t>For simulations of the indoor network, each node sends traffic
      according to a Constant Bit Rate (CBR) to all other nodes in the
      network, over the simulation period. Each node generates a new data
      packet every 10 seconds. Each data packet has a size of 127 bytes
      including 802.15.4 PHY/MAC headers and RPL packet headers. All control
      packets are also encapsulated with 802.15.4 PHY/MAC headers. To simulate
      a more realistic scenario, 80% of the generated packets by each node are
      destined to the root, and the remaining 20% of the packets are uniformly
      assigned as destined to nodes other than the root. Therefore the root
      receives a considerably larger amount of data than other nodes. These
      values may be revised when studying P2P traffic so as to have a majority
      of traffic going to all nodes as opposed to the root. In the later part
      of the simulation, a typical home/building routing scenario is also
      simulated and different path quality metrics are computed for that
      traffic pattern.</t>

      <t>The packets are routed through the DODAG built by RPL according to
      the mechanisms specified in <xref
      target="I-D.ietf-roll-rpl"></xref>.</t>

      <t>A number of RPL parameters are studied (such as Packet Rate from each
      source, Time Period of the LBR emitting new DAG Sequence Number) to
      observe their effect on the performance metric of interest.</t>
    </section>

    <section title="Performance Metrics">
      <section title="Common Assumptions">
        <t>As the DAO messages are used to feed the routing tables in the
        network, they grow with time and size of the network. Nevertheless, no
        constraint was imposed on the size of the routing table nor on how
        much information the node can store. The routing table size is not
        expressed in terms of Kbyte of memory usage but measured in terms of
        number of entries for each node. Each entry has the next hop node and
        path cost associated with the destination node.</t>

        <t>The link ETX (Expected Transmission Count) metric is used to build
        the DODAG. The link ETX routing metric is specified in <xref
        target="I-D.ietf-roll-routing-metrics"></xref>.</t>
      </section>

      <section title="Path Quality">
        <t>Number of Hops: for each source-destination pair, the average
        number of hops for both RPL and shortest path routing is computed.
        Shortest path routing refers to a hypothetical ideal routing protocol
        that would always provide the shortest path in term of path cost ETX
        (or whichever metric is used) in the network. The Cumulative
        Distribution Function (CDF) of hop distance for all paths (n*(n-1) in
        an n-node network) in the network with respect to the number of hops
        is plotted in Figure 3 for both RPL and shortest path routing. One can
        observe that the CDF corresponding to 4 hops is around 80% for RPL and
        90% for shortest path routing. In other words, for the given topology,
        90% of paths have a path length of 4 hops or less with an ideal
        shortest path routing methodology, whereas in RPL Point-to-Point (P2P)
        routing, 90% of the paths will have a length of no more than 5 hops.
        This result indicates that despite having a non-optimized P2P routing
        scheme, the path quality of RPL is close to an optimized P2P routing
        mechanism for the topology in consideration. Another reason for this
        may relate to the fact that the sink is at the center of the network,
        thus routing through the sink is often close to an optimal (shortest
        path) routing. This result may be different in a topology where the
        sink is located at one end of the network.</t>

        <figure>
          <artwork>Figure 3</artwork>

          <postamble>Figure 3: CDF: hop distance versus number of
          hops.</postamble>
        </figure>

        <t>Path Cost ETX: The path cost ETX along the path is computed for
        each source-destination pair. In the simulation, the path ETX from
        source to destination for each packet is computed. Figure 4 shows the
        CDF of the total path cost ETX, both with RPL and shortest path
        routing. Here also one can observe that the path cost ETX from all
        source to all destinations is close to that of a shortest path routing
        for the network.</t>

        <figure>
          <artwork>Figure 4</artwork>

          <postamble>Figure 4: CDF: Total ETX along path versus link ETX
          value.</postamble>
        </figure>

        <t>Path Stretch: In this simulation, the path stretch is also
        calculated for each packet that traversed the network. The path
        stretch is determined as the difference between the number of hops
        taken by a packet while following a route built via RPL and the number
        of hops taken by shortest path routing (using link ETX as the
        metric).</t>

        <t>Once again, the CDF of the path stretch is plotted against the
        value of path stretch over all packets in Figures 5 and 6, for hop
        count stretch and ETX metric stretch, respectively. It can be observed
        that for a few packets, the path built via RPL has fewer hops than the
        ideal shortest path where path ETX is minimized along the DAG. This is
        because there are a few source-destination pairs where the total path
        ETX is equal to or less than that of the ideal shortest path when the
        packet takes a longer hop count. As the RPL implementation ignores 20%
        change in total path cost before switching to a new parent or emitting
        new DIO, RPL not necessarily provides the shortest path in terms of
        total ETX path cost. Thus, this implementation yields a few paths with
        smaller hop count but larger (or equal) total ETX path cost.</t>

        <figure>
          <artwork>Figure 5</artwork>

          <postamble>Figure 5: CDF: Hop count stretch versus hop count of a
          packet.</postamble>
        </figure>

        <figure>
          <artwork>Figure 6</artwork>

          <postamble>Figure 6: CDF: ETX metric stretch versus ETX
          value.</postamble>
        </figure>

        <t>The data for the CDF of hop count and path cost ETX for the ideal
        shortest path (SP) and a path built via RPL, along with the CDF of the
        routing table size is given in the table below. Figures 3 to 7 relate
        to the data in this table.</t>

	<texttable anchor="table_1" title="Path Quality CDFs">
	  <ttcol align="center">CDF (%age)</ttcol>
	  <ttcol align="center">Hop (SP)</ttcol>
	  <ttcol align="center">Hop (RPL)</ttcol>
	  <ttcol align="center">ETX Cost (SP)</ttcol>
	  <ttcol align="center">ETX Cost (RPL)</ttcol>
	  <ttcol align="center">Routing Table Size</ttcol>

        <c>0</c><c>1.0</c><c>1.0</c><c>1</c><c>1.0</c><c>0</c>

        <c>5</c><c>1.0</c><c>1.03</c><c>1</c><c>1.242</c><c>1</c>

        <c>10</c><c>2.0</c><c>2.0</c><c>2</c><c>2.048</c><c>2</c>

        <c>15</c><c>2.0</c><c>2.01</c><c>2</c><c>2.171</c><c>2</c>

        <c>20</c><c>2.0</c><c>2.06</c><c>2</c><c>2.400</c><c>2</c>

        <c>25</c><c>2.0</c><c>2.11</c><c>2</c><c>2.662</c><c>3</c>

        <c>30</c><c>2.0</c><c>2.42</c><c>2</c><c>2.925</c><c>3</c>

        <c>35</c><c>2.0</c><c>2.90</c><c>3</c><c>3.082</c><c>3</c>

        <c>40</c><c>3.0</c><c>3.06</c><c>3</c><c>3.194</c><c>4</c>

        <c>45</c><c>3.0</c><c>3.1</c><c>3</c><c>3.41</c><c>4</c>

        <c>50</c><c>3.0</c><c>3.15</c><c>3</c><c>3.626</c><c>4</c>

        <c>55</c><c>3.0</c><c>3.31</c><c>3</c><c>3.823</c><c>5</c>

        <c>60</c><c>3.0</c><c>3.50</c><c>3</c><c>4.032</c><c>6</c>

        <c>65</c><c>3.0</c><c>3.66</c><c>3</c><c>4.208</c><c>7</c>

        <c>70</c><c>3.0</c><c>3.92</c><c>4</c><c>4.474</c><c>7</c>

        <c>75</c><c>4.0</c><c>4.16</c><c>4</c><c>4.694</c><c>7</c>

        <c>80</c><c>4.0</c><c>4.55</c><c>4</c><c>4.868</c><c>8</c>

        <c>85</c><c>4.0</c><c>4.70</c><c>4</c><c>5.091</c><c>9</c>

        <c>90</c><c>4.0</c><c>4.89</c><c>4</c><c>5.488</c><c>10</c>

        <c>95</c><c>4.0</c><c>5.65</c><c>5</c><c>5.923</c><c>12</c>

        <c>100</c><c>5.0</c><c>7.19</c><c>9</c><c>10.125</c><c>44</c>

	<postamble></postamble>
	</texttable>

        <t>Overall, the path quality metrics give us important information
        about the protocol's performance when minimizing the path cost ETX is
        the objective to form the DAG. The protocol, as explained, does not
        always provide an optimum path, especially for peer-to-peer
        communication. However, it does end-up reducing the control overhead
        cost, reducing unnecessary parent selection and DIO message forwarding
        events, by choosing a non-optimized path. Despite this specific
        implementation technique, around 30% of the packets travel the same
        number of hops as an ideal shortest path routing mechanism, and 20% of
        packets experience the same number of attempted transmissions to reach
        the destination. On average, this implementation costs only a few
        extra transmission attempts and saves a large number of control packet
        transmissions.</t>
      </section>

      <section title="Routing Table Size">
        <t>The objective of this metric is to observe the distribution of the
        number of entries per node. Figure 7 shows the CDF of the number of
        routing table entries for all nodes. Note that 90% of the nodes need
        to store less than 10 entries in their routing table. This result
        shows that the protocol is capable of accommodating devices with low
        storage capacity. This feature has been mandated in <xref
	target="RFC5673"></xref>, <xref target="RFC5826"></xref>and <xref
        target="RFC5867"></xref>.</t>

        <figure>
          <artwork>Figure 7</artwork>

          <postamble>Figure 7: CDF of routing table size with respect to
          number of nodes.</postamble>
        </figure>
      </section>

      <section title="Delay bound for P2P Routing">
        <t>For delay sensitive applications, such as home and building
        automation, it is critical to optimize the end-to-end delay. Figure 8
        shows the upper bound and distributions of delay for paths between any
        two given nodes for different hop counts between source and
        destination. Here, the hop count refers to the number of hops a packet
        travels to reach the destination when using RPL paths. This hop
        distance does not correspond to shortest path distance between two
        nodes. Note that, each packet has a length of 127 bytes, with a 240
        kbps radio, which makes the transmission time approximately 4 ms.</t>

        <figure>
          <artwork> Figure 8</artwork>

          <postamble>Figure 8: Comparison of packet latency for different path
          length expressed in hop count.</postamble>
        </figure>

        <t>RFCs 5673<xref target="RFC5673"></xref> and 5548<xref
        target="RFC5548"></xref>mention a requirement for the end-to-end
        delivery delay to remain within a bounded latency. For instance,
        according to the industrial routing requirement, non-critical
        closed-loop applications may have a latency requirement that can be as
        low as 100 milliseconds, whereas monitoring services may tolerate a
        delay in the order of seconds. The results show that about 99% of the
        end-to end communication (where maximum hop-count is 7 hops) are
        bounded within the 100 ms requirement.</t>
      </section>

      <section title="Control Packet Overhead">
        <t>The control plane overhead is an important routing characteristic
        in LLNs. It is imperative to bound the control plane overhead. One of
        the distinctive characteristics of RPL is that it makes use of trickle
        timers so as to reduce the number of control plane packets by
        eliminating redundant messages. The aim of this performance metric is
        thus to analyse the control plane overhead both in stable conditions
        (no network element failure overhead) and in the presence of
        failures.</t>

        <t>Data and control plane traffic comparison for each node: Figure 9
        shows the comparison between the amount of data packets transmitted
        (including forwarded) and control packets (DIO and DAO messages)
        transmitted for all individual nodes when link ETX is used to optimize
        the DAG. As mentioned earlier, each node generates a new data packet
        every 10 seconds. Here one can observe that a considerable amount of
        traffic is routed through the sink itself. The x axis indicates the
        node ID in the network. Also, as expected, the nodes closer to sink
        and that act as routers (as opposed to leaves) handle much more data
        traffic than other nodes. Looking at a link close to the root, we can
        observe that the proportion of control traffic is negligible. This
        result also reinforces the fact that the amount of control plane
        traffic generated by RPL is negligible. Leaf nodes have comparable
        amount of data and control packet transmission (they do not take part
        in routing the data).</t>

        <figure>
          <artwork>Figure 9</artwork>

          <postamble>Figure 9: Amount of data and control packets transmitted
          against node ID using link ETX as routing metric.</postamble>
        </figure>

        <t>Data and Control Packet Transmission with Respect to Time: In
        Figures 10, 11 and 12, the amount of data and control packets
        transmitted for node 12 (low rank in DAG, closer to the root), node 43
        (in the middle) and node 31 (leaf node) are shown, respectively. These
        values stand for number of data and control packets transmitted for
        each 10 minute intervals for the particular node, to help understand
        what is the ratio between data and control packets exchanged in the
        network. One can observe that nodes closer to the sink have a higher
        proportion of data packets (as expected), and the proportion of
        control traffic is negligible in comparison with the data traffic.
        Also, the amount of data traffic handled by a node within given
        interval varies largely over time for a node closer to sink, because
        in each interval the destinations of the packets from same source
        changes, while 20% of the packets are destined to the sink. As a
        result, pattern of the traffic handled changes widely in each interval
        for the nodes closer to the sink. For the nodes that are farther away
        from sink, the ratio of data and control traffic is smaller since the
        amount of data traffic is greatly reduced.</t>

        <t>The control traffic load exhibits a wave-like pattern. The amount
        of control packets for each node drops quickly as the DODAG stabilizes
        due to the effect of trickle timers. However, when a new DODAG
        sequence is advertised (global repair of the DODAG), the trickle
        timers are reset and the nodes start emitting DIOs frequently again to
        rebuild the DODAG. For a node closer to the sink, the amount of data
        packets is much larger than that of control packets, and somewhat
        oscillatory around a mean value. The amount of control packets
        exhibits a 'saw-tooth' behavior. As the ETX link metric was used, when
        the PDR changes, the ETX link metric for a node to its child changes,
        which may lead to choosing a new parent, and changing the DAG rank of
        the child. This event resets the trickle timer and triggers the
        emission of a new DIO. Also, issue of a new DODAG sequence number
        triggers DODAG re-computation and resets the trickle timers.
        Therefore, one can observe that the number of control packets attains
        a high value for one interval, and comes down to lower values for
        subsequent intervals. The interval with high value of control packets
        denote the interval where the timers to emit new DIO are reset more
        frequently. As the network stabilizes, the control packets are less
        dense in volume. For leaf nodes, the amount of control packets is
        comparable to that of data packets, as leaf nodes are more prone to
        face changes in their DODAG rank as opposed to nodes closer to sink
        when the link ETX value in the topology changes dynamically.</t>

        <figure>
          <artwork>Figure 10</artwork>

          <postamble>Figure 10: Amount of data and control packets transmitted
          for node 12.</postamble>
        </figure>

        <figure>
          <artwork>Figure 11</artwork>

          <postamble>Figure 11: Amount of data and control packets transmitted
          for node 43.</postamble>
        </figure>

        <figure>
          <artwork>Figure 12</artwork>

          <postamble>Figure 12: Amount of data and control packets transmitted
          for node 31.</postamble>
        </figure>
      </section>

      <section title="Loss of connectivity">
        <t>Upon link failures, a node may lose his parents: preferred and
        backup (if any) thus to leading to a loss of connectivity (no path to
        the DODAG root). RPL specifies two mechanisms for DODAG repairs,
        referred to as the global repair and local repair. In this version of
        the document, simulation results are presented to evaluate the amount
        of time data packets are dropped due to a loss of connectivity for the
        following two cases: a) when only using global repair (i.e., the DODAG
        is rebuilt thanks to the emission of new DODAG sequence numbers by the
        DODAG root), and b) when using local repair (poisoning the sub-DAG in
        case of loss of connectivity) in addition to global repair. The idea
        is to tune the frequency at which new DODAG sequence numbers are
        generated by the DODAG root, and also to observe the effect of varying
        the frequency for global repair and the concurrent use of global and
        local repair. It is expected that more frequent increments of DODAG
        sequence number will lead to shorter duration of connectivity loss at
        a price of a higher rate of control packet in the network. For the use
        of both global and local repair, the simulation results show the
        trade-off in amount of time that a node may remain without service and
        total number of control packets for extra bit of signalling.</t>

        <t>Figure 13 shows the CDF of time spent by any node without service,
        when the rate of data packet is one packet every 10 seconds, and new
        DODAG Sequence Number is generated every 10 minutes. This plot
        reflects the property of global repair without any local repair
        scheme. When all the parents are temporarily unreachable from a node,
        the time before it hears a DIO from another node is recorded, which
        gives the time without service. We define DAG repair timer to be the
        interval at which the LBR increments the DAG sequence number, thus
        triggering a global reoptimization. In some cases, this value might go
        up to the DAG repair timer value, because until a DIO is heard, the
        node does not have a parent, and hence no route to the LBR or other
        nodes not in its own sub-DAG. Clearly, this situation indicates a lack
        of connectivity and loss of service for the node.</t>

	<t></t>
        <figure>
          <artwork>Figure 13</artwork>

          <postamble>Figure 13: CDF: Loss of connectivity with global
          repair</postamble>
        </figure>

	<t></t>

        <t>The effect of the DAG repair timer on time without service is
        plotted in Figure 14, where the source rate is 20 seconds/packet and
        in Figure 15, where the source sends a packet every 10 seconds.</t>

	<t></t>

        <figure>
          <artwork>Figure 14</artwork>

          <postamble>Figure 14: CDF: Loss of connectivity for different global
          repair period, packet rate 20/s.</postamble>
        </figure>

	<t></t>

        <figure>
          <artwork>Figure 15</artwork>

          <postamble>Figure 15: CDF: Loss of connectivity for different global
          repair period, packet rate 10/s.</postamble>
        </figure>

        <t>The data for Figures 13 and 15 can be found in the table below. The
        table shows how the CDF of time without connectivity to LBR increases
        while we increase the time period to emit new DAG sequence number,
        when the nodes generate a packet every 10 seconds.</t>

	<texttable anchor="table_2" 
		title="Loss of Connectivity time, Data rate - 1 Packet / 10 Seconds">
	  <ttcol align="center">CDF (%age)</ttcol>
	  <ttcol align="center">Repair Period 10 Minutes</ttcol>
	  <ttcol align="center">Repair Period 30 Minutes</ttcol>
	  <ttcol align="center">Repair Period 60 Minutes</ttcol>

        <c>0</c><c>0.464</c><c>0.045</c><c>0.027</c>

        <c>5</c><c>0.609</c><c>0.424</c><c>0.396</c>

        <c>10</c><c>1.040</c><c>1.451</c><c>0.396</c>

        <c>15</c><c>1.406</c><c>3.035</c><c>0.714</c>

        <c>20</c><c>1.934</c><c>3.521</c><c>0.714</c>

        <c>25</c><c>2.113</c><c>5.461</c><c>1.856</c>

        <c>30</c><c>3.152</c><c>5.555</c><c>1.856</c>

        <c>35</c><c>3.363</c><c>7.756</c><c>6.173</c>

        <c>40</c><c>4.9078</c><c>8.604</c><c>6.173</c>

        <c>45</c><c>8.575</c><c>9.181</c><c>14.751</c>

        <c>50</c><c>9.788</c><c>21.974</c><c>14.751</c>

        <c>55</c><c>13.230</c><c>30.017</c><c>14.751</c>

        <c>60</c><c>17.681</c><c>31.749</c><c>16.166</c>

        <c>65</c><c>29.356</c><c>68.709</c><c>16.166</c>

        <c>70</c><c>34.019</c><c>92.974</c><c>302.459</c>

        <c>75</c><c>49.444</c><c>117.869</c><c>302.459</c>

        <c>80</c><c>75.737</c><c>133.653</c><c>488.602</c>

        <c>85</c><c>150.089</c><c>167.828</c><c>488.602</c>

        <c>90</c><c>180.505</c><c>271.884</c><c>488.602</c>

        <c>95</c><c>242.247</c><c>464.047</c><c>488.602</c>

        <c>100</c><c>273.808</c><c>464.047</c><c>488.602</c>

	<postamble></postamble>
	</texttable>


        <t>The data for Figure 14 can be found in the table below. The table
        shows how the CDF of time without connectivity to LBR increases while
        we increase the time period to emit new DAG sequence number, when the
        nodes generate a packet every 20 seconds.</t>


	<texttable anchor="table_3" title="Loss of Connectivity time, Data rate - 1 Packet / 20 Seconds">
	  <ttcol align="center">CDF (%age)</ttcol>
	  <ttcol align="center">Repair Period 10 Minutes</ttcol>
	  <ttcol align="center">Repair Period 30 Minutes</ttcol>
	  <ttcol align="center">Repair Period 60 Minutes</ttcol>

        <c>0</c><c>0.071</c><c>0.955</c><c>0.167</c>

        <c>5</c><c>0.126</c><c>2.280</c><c>1.377</c>

        <c>10</c><c>0.403</c><c>2.926</c><c>1.409</c>

        <c>15</c><c>0.902</c><c>3.269</c><c>1.409</c>

        <c>20</c><c>1.281</c><c>16.623</c><c>3.054</c>

        <c>25</c><c>2.322</c><c>21.438</c><c>5.175</c>

        <c>30</c><c>2.860</c><c>48.479</c><c>5.175</c>

        <c>35</c><c>3.316</c><c>49.495</c><c>10.30</c>

        <c>40</c><c>3.420</c><c>93.700</c><c>25.406</c>

        <c>45</c><c>6.363</c><c>117.594</c><c>25.406</c>

        <c>50</c><c>11.500</c><c>243.429</c><c>34.379</c>

        <c>55</c><c>19.703</c><c>277.039</c><c>102.141</c>

        <c>60</c><c>22.216</c><c>284.660</c><c>102.141</c>

        <c>65</c><c>39.211</c><c>285.101</c><c>328.293</c>

        <c>70</c><c>63.197</c><c>376.549</c><c>556.296</c>

        <c>75</c><c>88.986</c><c>443.450</c><c>556.296</c>

        <c>80</c><c>147.509</c><c>452.883</c><c>1701.52</c>

        <c>85</c><c>154.26</c><c>653.420</c><c>2076.41</c>

        <c>90</c><c>244.241</c><c>720.032</c><c>2076.41</c>

        <c>95</c><c>518.835</c><c>1760.47</c><c>2076.41</c>

        <c>100</c><c>555.57</c><c>1760.47</c><c>2076.41</c>

	<postamble></postamble>
	</texttable>

        <t>Figure 16 shows the effect of DAG global repair timer period on
        control traffic. As expected, as the frequency at which new DAG
        sequence numbers are generated increases, the amount of control
        traffic decreases because DIO messages are sent less frequently to
        rebuild the DODAG. However reducing the control traffic comes at a
        price of increased loss of connectivity when only global repair is
        used.</t>

        <figure>
          <artwork>Figure 16</artwork>

          <postamble>Figure 16: Amount of control traffic for different global
          repair periods</postamble>
        </figure>

        <t>From the above results, it is clear that the time the protocol
        takes to re-stablish routes and to converge, after an unexpected link
        or device failure happens, is fairly long. <xref
        target="RFC5826"></xref>" mandates that the routing protocol MUST
        converge within 0.5 seconds if no nodes have moved". Clearly,
        implementation of a repair mechanism based on new DAG sequence number
        alone would not meet the requirements. Hence a local repair mechanism,
        in form of poisoning the sub-DAG and issuing DIS, has been
        adopted.</t>

        <t>The effect of the DAG Repair Timer on time without service when
        local repair is activated is now observed and plotted in Figure 17,
        where the source rate is 20 seconds/packet. A comparison of the CDF of
        loss of connectivity for global repair mechanism and global + local
        repair mechanism is shown in Figures 18 and 19 (semilog plots, x axis
        in logarithmic and y axis in linear scale), where the source generates
        a packet every 10 seconds and 20 seconds, respectively. For these
        plots, the x axis shows time in log scale, and y axis denotes the
        corresponding CDF in linear scale. One can observe that using local
        repair (with poisoning of the sub-DAG) greatly reduces loss of
        connectivity.</t>

        <figure>
          <artwork>Figure 17</artwork>

          <postamble>Figure 17: CDF: Loss of connectivity for different DAG
          repair timer values for global+local repair, packet rate
          20/s.</postamble>
        </figure>

        <figure>
          <artwork>Figure 18</artwork>

          <postamble>Figure 18: CDF: comparing Loss of connectivity for global
          repair and global+local repair, packet rate 10/s.</postamble>
        </figure>

        <figure>
          <artwork>Figure 19</artwork>

          <postamble>Figure 19: CDF: comparing Loss of connectivity for global
          repair and global+local repair, packet rate 20/s.</postamble>
        </figure>

        <t>A comparison between the amount of control plane overhead used for
        global repair only and global plus local repair mechanism is shown in
        Figure 20, which highlights the improved performance of RPL in terms
        of convergence time at very little extra overhead. From Figure 19, in
        85% of the cases the protocol finds connectivity to the LBR for the
        concerned nodes within fraction of seconds when local repair is
        employed. Using only global repair leads to 150 - 154 seconds as
        observed in Figures 13 and 14.</t>

        <figure>
          <artwork>Figure 20</artwork>

          <postamble>Figure 20: Number of control packets for different DAG
          Seq Number period, for both global repair and global+local
          repair.</postamble>
        </figure>
      </section>
    </section>

    <section title="RPL in a Building Automation Routing Scenario">
      <t>Unlike the previous traffic pattern, where a majority of the total
      traffic generated by any node is destined to the root, this section
      considers a different traffic pattern, which is more prominent in home
      or building routing scenario. In the simulations shown below, the nodes
      send 60% of their total generated traffic to the physically 1-hop
      distant node, 20% of traffic to a 2-hop distant node (again this is a
      typical traffic pattern in building and home automation networks). The
      other 20% of traffic is distributed among other nodes in the network.
      The CDF of average hop distance path stretch in terms of hop distance,
      ETX path cost and delay for P2P routing for all pair of nodes is
      calculated. Maintaining low delay bound for P2P traffic is of high
      importance in this traffic scenario, as the applications in home and
      building routing have typically low delay tolerance.</t>

      <section title="Path Quality">
        <t>Figure 21 shows the CDF of number of hops for both RPL and ideal
        shortest path routing for the traffic pattern described above. Figure
        22 shows CDF of the expected number of transmission (ETX) for each
        packet to reach destination. Figures 23 and 24 show CDF of the stretch
        factor for these two metrics. To illustrate the stretch factor, an
        example from figure 24 will be given next. For all paths built by RPL,
        85% of the time the path cost is less than the path cost for the ideal
        shortest path plus one.</t>

        <figure>
          <artwork>Figure 21</artwork>

          <postamble>Figure 21: Comparison of end-to-end hop distance for RPL
          and ideal shortest path in home routing.</postamble>
        </figure>

        <figure>
          <artwork>Figure 22</artwork>

          <postamble>Figure 22: Comparison of path ETX metric for RPL and
          ideal shortest path in home routing.</postamble>
        </figure>

        <figure>
          <artwork>Figure 23</artwork>

          <postamble>Figure 23: Stretch factor for node hop distance from
          ideal shortest path.</postamble>
        </figure>

        <figure>
          <artwork>Figure 24</artwork>

          <postamble>Figure 24: Stretch Factor of path ETX metric from ideal
          shortest path.</postamble>
        </figure>
      </section>

      <section title="Delay">
        <t>To get an idea of maximum observable delay in the mentioned traffic
        pattern, the delay for different number of hops to the destination for
        RPL is considered. Figure 25 shows how the end-to-end packet latency
        is distributed for different packets with different hop counts in the
        network.</t>

        <figure>
          <artwork>Figure 25</artwork>

          <postamble>Figure 25: Comparison of packet latency for different hop
          count in RPL.</postamble>
        </figure>

        <t>For this deployment scenario, 60% of the traffic has been
        restricted to 1-hop neighborhood. Hence, intuitively, the protocol is
        expected to yield path qualities which are close to that of ideal
        shortest path routing for most of the paths. From the CDF of hop
        distance and ETX path cost, it is clear that peer-to-peer paths are
        more often closer to an ideal shortest path. The end-to-end delay for
        distances within 2 hops are less than 60 ms for 99% of the delivered
        packets, while packets traversing 5 hops and more are delivered within
        100 ms 99% of the time. These results demonstrate that, for a normal
        routing scenario of an LLN deployment in a building, RPL performs
        fairly well without incurring much control plane overhead, and it can
        be applied for delay critical applications as well.</t>
      </section>
    </section>

    <section title="RPL in a Large Scale Network">
      <t>In this section we focus on simulating how RPL operates in a large
      network and study its scalability by focusing on a few performance
      metrics: the latency and path cost stretch, and the amount of control
      packets for scalability. The 2442 node smart meter network with its
      corresponding link traces is used in this scalability study. To simulate
      a more realistic scenario for a smart meter network, 100% of the
      generated packets by each node are destined to the root. Therefore, no
      traffic is destined to nodes other than the root.</t>

      <section title="Path Quality">
        <t>To investigate RPL's scalability, the CDF of ETX path cost in the
        large scale smart meter network is compared to a hypothetical ideal
        shortest path routing protocol which minimizes the total path ETX
        (Figure 26). In this simulation, the path stretch is also calculated
        for each packet that traverses the network. The path stretch is
        determined as the difference between the path ETX taken by a packet
        while following a route built via RPL and a path computed using an
        ideal shortest path routing protocol. Here, the CDF of fractional path
        stretch, which is determined as the path stretch value over the path
        cost of an ideal shortest path, is plotted in Figure 27. The same
        fractional path stretch value for hop distance is shown in Figure
        28.</t>

        <t>Looking at the path quality plots, it is obvious that RPL works in
        a non-optimal fashion in this deployment scenario as well. However, on
        average, for each source-destination pair, the fractional stretch is
        limited to 30% of the ideal shortest path cost. This fraction is
        higher for paths with shorter distance, and lower for paths where
        source-destination are far apart. The negative stretch factor for hop
        count is an interesting feature of this deployment and is due to RPL's
        decision of not switching to another parent where the improvement in
        path quality is not significant. As mentioned, in this implementation,
        any node will not switch to a new parent unless the advertised path
        cost to LBR through the new candidate parent is 20% better the old
        one. Hence, there are paths where the ETX path cost to LBR is small
        for a path with a larger number of hops. The nodes tend to hear DIOs
        from a smaller hop count first, and later do not always shift to a
        larger hop count and smaller ETX path cost. As the traffic is mostly
        to the DAG root, some P2P paths built via RPL do yield a smaller hop
        count from source to destination, albeit a larger ETX path cost.</t>

        <t>As observed in Figure 26, 90% of the packets transmitted during the
        simulation have a (shortest) path cost to destination less than or
        equal to 12. However, via RPL, 90% of the packets will follow paths
        that have a total ETX path cost of up to 14. Though all packets are
        destined to the LBR, it is to be noted that this implementation
        ignores a change of up to 20% in total path cost. Figures 27 and 28
        indicate all paths have a very low fractional stretch factor as total
        path cost ETX is concerned, and some of the paths have lesser hop
        counts to LBR as well when compared to the hop count of ideal shortest
        path.</t>

        <figure>
          <artwork>Figure 26</artwork>

          <postamble>Figure 26: CDF of total ETX path cost.</postamble>
        </figure>

        <figure>
          <artwork>Figure 27</artwork>

          <postamble>Figure 27: CDF of fractional stretch in ETX path
          cost.</postamble>
        </figure>

        <figure>
          <artwork>Figure 28</artwork>

          <postamble>Figure 28: CDF of fractional stretch in hop
          count.</postamble>
        </figure>
      </section>

      <section title="Delay">
        <t>Figure 29 shows how the end-to-end packet latency is distributed
        for different hop counts. According to <xref target="RFC5826"></xref>,
        U-LLNs are delay tolerant, and the information, except for critical
        alarms, should arrive within a fraction of the reporting interval
        (within a few seconds). The packet generation for this deployment has
        been set higher than usual to incur high traffic volume, and nodes
        generate data once every 30 seconds. However, the end-to-end latency
        for most of the packets is condensed between 500 ms to 1s, where the
        upper limit corresponds to packets traversing longer (larger than or
        equal to 6 hops) paths.</t>

        <figure>
          <artwork>Figure 29</artwork>

          <postamble>Figure 29: End-to-end packet delivery latency for
          different hop count.</postamble>
        </figure>

        <t></t>
      </section>

      <section title="Control Packet Overhead">
        <t>Figure 30 shows the comparison between data packets (originated and
        forwarded) and control packets (DIO and DAO messages) transmitted by
        each node (link ETX is used as the routing metric). Here one can
        observe that in spite of the large scale of the network, the amount of
        control traffic in the protocol is negligible in comparison to data
        packet transmission. The smaller node id for this network actually
        indicates closer proximity to the sink and nodes with high ID are
        actually further away from the sink. Also, as expected, we can observe
        on Figures 31, 32, 33 that the (non-leaf) nodes closer to the sink
        have much more data packet transmission than other nodes. The leaf
        nodes have comparable amount of data and control packet transmission,
        as they do not take part in routing the data. As seen before, the data
        traffic for a child node has much less variation than the nodes which
        are closer to the sink. This variation decreases with increase in DAG
        depth. In this topology, Nodes 1, 2, and 3, etc., are direct children
        of the LBR.</t>

        <figure>
          <artwork>Figure 30</artwork>

          <postamble>Figure 30: Data and control packet
          comparison.</postamble>
        </figure>

        <figure>
          <artwork>Figure 31</artwork>

          <postamble>Figure 31: Data and control packet over time for Node
          1.</postamble>
        </figure>

        <figure>
          <artwork>Figure 32</artwork>

          <postamble>Figure 32: Data and control packet over time for Node
          78.</postamble>
        </figure>

        <figure>
          <artwork>Figure 33</artwork>

          <postamble>Figure 33: Data and control packet over time for Node
          300.</postamble>
        </figure>

        <t>In Figure 34, the effect of global repair period timer on control
        packet overhead is shown.</t>

        <figure>
          <artwork>Figure 34</artwork>

          <postamble>Figure 34: Amount of control packet for different global
          repair timer period.</postamble>
        </figure>
      </section>
    </section>

    <section title="Scaling Property and Routing Stability">
      <t>An important metric of interest is the maximum load experienced by
      any node (CPU usage) in terms of the number of control packets
      transmitted by the node. Also, to get an idea of scaling properties of
      RPL in large scale networks, it is also key to analyze the number of
      packets handled by the RPL nodes for different sizes of the network.</t>

      <t>In these simulations, at any given interval, the node with maximum
      control overhead load is identified. The amount of maximum control
      overhead processed by that node is plotted against time for three
      different networks under study. The first one is Network 'A', which has
      45 nodes and is shown in figure 1 in section 3; Network 'B', which is
      another deployed outdoor network with 86 nodes; and finally, Network
      'C', which is the large deployed smart meter network with 2442 nodes
      being considered in this document.</t>

      <t>In Figure 35, the comparison of maximum control load is shown for
      different network sizes. For the network with 45 nodes, the maximum
      number of control packets in the network stays within a limit of 50
      packets (per 1 minute interval), where for the networks with 86 and 2442
      nodes, this limit stretches to 100 and 2 * 10^3 packets per 1 minute
      interval, respectively.</t>

      <figure>
        <artwork>Figure 35</artwork>

        <postamble>Figure 35: Scaling property of maximum control packets
        processed by any node over time.</postamble>
      </figure>

      <t>For a network built with low power devices interconnected by lossy
      links, it is of the utmost importance to ensure that routing packets are
      not flooded in the entire network, and that the routing topology stays
      as stable as possible. Any change in routing information, specially
      parent-child relationship, would reset the timer leading to emitting new
      DIOs, and hence, change the node's path metric to reach the root. This
      change will trigger a series of control place messages (RPL packets) in
      the DODAG. Therefore, it is important to carefully control the
      triggering of DIO control packets via the use of thresholds.</t>

      <t>In this study, the effect of the tolerance value before emitting new
      DIO reflecting a new path cost is analyzed. Four cases are considered in
      this study:</t>

      <t><list style="symbols">
          <t>No change in DAG depth of a node is ignored.</t>

          <t>The implementation ignores 10% of change in the ETX path cost to
          the root. That is, if the change in total path cost to LBR, due to a
          DIO reception from most preferred parent or due to shifting to
          another parent, is less than 10%, the node will not advertise the
          new metric to the root,</t>

          <t>The implementation ignores 20% change in path cost to the root
          for any node before deciding to advertise a new depth, and</t>

          <t>The implementation ignores 30% change in the total path cost to
          root of a node before deciding to advertise a new depth.</t>
        </list></t>

      <t>This decision does affect the optimum path quality to the root. As
      observed in Figure 36, for 0% tolerance, 95% of paths used have a
      stretch factor less than 10%. Similarly, for 10% and 20% tolerance
      level, 95% of paths will have a 15% and 20% fractional path stretch.
      However, the increased routing stability and decreased control overhead
      is the profit gained from the 10% extra increase in path length or ETX,
      whichever is used as the metric to optimize DAG.</t>

      <figure>
        <artwork>Figure 36</artwork>

        <postamble>Figure 36: Fractional stretch factor for different
        tolerance levels.</postamble>
      </figure>

      <t>As the above mentioned threshold also affects the path taken by a
      packet, this study also demonstrates the effect of the threshold on
      routing stability (number of times P2P paths change between a source and
      a destination). For Network 'A' shown in Figure 1 and the large smart
      meter network 'C', the CDF of path change is plotted against fraction of
      path change for different thresholds triggering the emission of a new
      DIO upon path cost change.</t>

      <t>In Figures 37 and 38, we show the CDF of fraction of times a path has
      changed (for each source-destination pair). If X packets are transferred
      from source A to destination B, and out of X times, Y times the path
      between this source-destination pair is changed, then we compute the
      fraction of path change as Y/X * 100% . This metric is computed over all
      source-destination pairs, and the CDF is plotted in the Y axis.</t>

      <figure>
        <artwork>Figure 37</artwork>

        <postamble>Figure 37: Distribution of fraction of path change, Network
        `A'</postamble>
      </figure>

      <figure>
        <artwork>Figure 38</artwork>

        <postamble>Figure 38: Distribution of fraction of path change, large
        Network `C'</postamble>
      </figure>

      <t>This document also compares the CDF of fraction of path change for
      three different networks, A, B and C. Figure 39 shows how the three
      networks exhibit change of P2P path when 30% change in metric cost to
      the root is ignored before shifting to a new parent.</t>

      <figure>
        <artwork>Figure 39</artwork>

        <postamble>Figure 39: Comparison of distribution of fraction of path
        change</postamble>
      </figure>
    </section>

    <section title="Comments">
      <t>All the simulation results presented in this document point that the
      protocol does behave as expected for the particular target scenarios.
      For the discussed scenarios, the protocol is shown to meet the desired
      delay and convergence requirements and to exhibit self healing without
      external intervention, incurring negligible control overhead (only a
      small fraction of data traffic). RPL also provided path quality which is
      close to optimum or ideal shortest path for most of the packets in the
      scenarios considered and is able to trade-off control overhead for path
      quality as per the application and device requirement through
      configurable parameters (such as decision on when to switch to new
      parent), and thus can trade-off routing stability for control overhead
      as well. Finally, as per the requirement of Urban LLN deployments, the
      protocol is shown to scale to larger topologies (few thousand
      nodes).</t>
    </section>

    <section title="Acknowledgements">
      <t>The authors would like to acknowledge Jerald P. Martocci, Mukul
      Goyal, Emmanuel Monnerie, Philip Levis, Omprakash Gnawali and Craig
      Partridge for their valuable and helpful suggestions over metrics to
      include and overall feedback.</t>
    </section>
  </middle>

  <back>
    <references title="Normative References">
      <?rfc include='reference.RFC.2119'?>

      <?rfc ?>

      <?rfc ?>

      <?rfc ?>

      <?rfc ?>

      <?rfc ?>

      <?rfc ?>

      <?rfc ?>

      <?rfc ?>

      <?rfc ?>

      <?rfc ?>

      <?rfc ?>

      <?rfc ?>

      <?rfc ?>
    </references>

    <references title="Informative References">
      <reference anchor="RFC5867">
        <front>
          <title>Building Automation Routing Requirements in Low Power and
          Lossy Networks</title>

          <author fullname="" initials=""
                  surname="Martocci, J., Riou, N., Mil, P., and W. Vermeylen">
            <organization></organization>
          </author>

          <date month="" year="June 2010" />
        </front>
      </reference>

      <reference anchor="OMNETpp">
        <front>
          <title>The OMNeT++ Discrete Event Simulation System, in Proceedings
          of the European Simulation Multiconference (ESM'2001)</title>

          <author fullname="" initials="A" surname="Varga"></author>

          <date month="" year="June 2001" />
        </front>
      </reference>

      <reference anchor="Castalia-2.2">
        <front>
          <title>Castalia: Revealing pitfalls in designing distributed
          algorithms in WSN, in Proceedings of the 5th international
          conference on Embedded networked sensor systems (SenSys'07)</title>

          <author fullname="" initials="" surname="Boulis, A."></author>

          <date month="" year="2007" />
        </front>
      </reference>

      <reference anchor="NS-2">
        <front>
          <title>The Network Simulator-2, http://www.isi.edu/nsnam/ns/</title>

          <author />
        </front>
      </reference>

      <reference anchor="I-D.ietf-roll-rpl">
        <front>
          <title>RPL: Routing Protocol for Low Power and Lossy Networks,
          draft-ietf-roll-rpl-19 (work in progress)</title>

          <author surname="Winter, T., Thubert, P., et al.">
            <organization></organization>
          </author>

          <date year="March 2011" />
        </front>
      </reference>

      <reference anchor="RFC5826">
        <front>
          <title>Home Automation Routing Requirements in Low Power and Lossy
          Networks</title>

          <author fullname="" initials=""
                  surname="Brandt, A., Buron, J., and G. Porcu">
            <organization></organization>
          </author>

          <date month="" year="April 2010" />
        </front>
      </reference>

      <reference anchor="RFC5673">
        <front>
          <title>Industrial Routing Requirements in Low Power and Lossy
          Networks</title>

          <author fullname="" initials=""
                  surname="Pister, K., Thubert, P.,  Dwars, S., Phinney, T.">
            <organization></organization>
          </author>

          <date month="" year="October 2009" />
        </front>
      </reference>

      <reference anchor="I-D.ietf-roll-terminology">
        <front>
          <title>Terminology in Low power And Lossy Networks,
          draft-ietf-roll-terminology-05 (work in progress)</title>

          <author surname="JP Vasseur">
            <organization></organization>
          </author>

          <date year="March 2011" />
        </front>
      </reference>

      <reference anchor="I-D.ietf-roll-routing-metrics">
        <front>
		<title>Routing Metrics used for  Path Calculation in Low Power and 
		Lossy Networks, draft-ietf-roll-routing-metrics-19 (work in
              	progress)</title>

          <author fullname="" initials=""
                  surname="Vasseur, JP., Kim, M., Pister, K., Dejean, N., Barthel, D.">
            <organization></organization>
          </author>

          <date year="March 2011" />
        </front>
      </reference>

      <reference anchor="draft-iphc">
        <front>
          <title>Limited IP Header Compression over PPP,
          draft-jurski-pppext-iphc-02.txt (work in progress)</title>

          <author surname="J. Jurski">
            <organization></organization>
          </author>

          <date year="March 2007" />
        </front>
      </reference>

      <reference anchor="RFC5548">
        <front>
          <title>Routing Requirements for Urban Low-Power and Lossy
          Networks</title>

          <author fullname="" initials=""
                  surname="Dohler, M., Watteyne, T., Winter, T., Barthel, D.">
            <organization></organization>
          </author>

          <date month="" year="May 2009" />
        </front>
      </reference>

      <?rfc include='reference.I-D.ietf-roll-trickle'?>

      <?rfc ?>

      <?rfc ?>
    </references>
  </back>
</rfc>

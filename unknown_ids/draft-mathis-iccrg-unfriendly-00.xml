<?xml version="1.0" encoding="UTF-8"?>

<!-- Use the getbibs script to install a local copy of the bibs directory -->

<!DOCTYPE rfc SYSTEM "rfc2629.dtd" [
    <!ENTITY rfc2309 PUBLIC '' 'bibs/bibxml/reference.RFC.2309.xml'>
]>

<rfc category="info" ipr="pre5378Trust200902"
     docName="draft-mathis-iccrg-unfriendly-00">

<?xml-stylesheet type='text/xsl' href='rfc2629.xslt' ?>

<?rfc toc="no" ?>
<?rfc symrefs="" ?>
<?rfc compact="yes" ?>
<?rfc sortrefs=""?>
<?rfc iprnotified="no" ?>
<?rfc strict="no" ?>

<front>
  <title>Rethinking TCP Friendly</title>
  <author initials='M.' surname="Mathis " fullname='Matthew Mathis'>
    <organization>Pittsburgh Supercomputing Center</organization>
    <address>
      <postal>
	<street>300 S. Craig St.</street>
	<city>Pittsburgh</city><region>PA</region><code>15213</code>
      </postal>
      <email>mathis@psc.edu</email>
    </address>
  </author>
  <date/>
  <workgroup>Internet Congestion Control Research Group</workgroup>
  <abstract>

    <t>The current Internet fairness paradigm mandates that all protocols have
      equivalent response to packet loss, such
      that relatively simple network devices can attain a weak form of fairness
      by sending uniform signals to all flows. This "TCP-friendly" paradigm has
      been the policy of the IETF for nearly two decades.   Although it was
      only an informal policy in the beginning, it progressively became more formal
      following the publication of RFC 2001 in 1997.</t>

    <t>However we observe two trends that differ from this policy: an
      increasing number of environments where applications and other
      circumstances create situations that are "unfair", and ISPs that are
      responding to these situation by imposing traffic control in the network
      itself.</t>

    <t>This note explores the question of whether TCP-friendly paradigm is still
      appropriate for the huge breadth of technology and scale encompassed by
      today's global Internet.  It considers the merits and difficulties of
      changing IETF policy to embrace these changes by progressively moving the
      responsibility for capacity allocation from the end-system to the
      network.  Ultimately this policy change might eliminate or redefine the
      requirement that all protocols be "TCP-Friendly".</t>

    <t>This note is intended foster discussion in the community and eventually
      become input to the IESG and IAB, where it might evolve into a future
      architecture statement.</t>

  </abstract>
</front>

<middle>
  <section anchor="parable" title="Parable">
    <t>We have built a global village, with no explicit traffic control, no stop
      lights or stop signs, only implicit yield signs at every intersection.
      This works, because for the most part we have carefully trained the
      traffic to have a calibrated sense of fairness, and to take turns at all
      bottlenecks.  This approach was optimal when the Internet was a club of
      friends, who believed in serving the common good.</t>

    <t>Now that the Internet has become truly global, encompassing all of the
      best and worst of mankind, it is not too surprising that we are finding
      that we need traffic control.  Furthermore, there are more and more
      situations where the "one-size-fits-all" approach to congestion control
      doesn't work well enough.  In some parts of the world the infrastructure
      is under utilized because the prescribed fairness makes the traffic too
      timid to effectively fill the available capacity, either due to adverse
      conditions along the path or due to the scale of the available capacity.
      In addition, in some contexts the users or applications are simply
      being greedy, without regard to their impact on others.</t>

    <t>If we embrace traffic controls, then we can permit traffic to be less
      timid, which will eventually raise overall network utilization and 
      efficiency.</t>

    <section anchor="instructions" title="[[Instructions to contributors">
      <t>Everyone is welcome to contribute!  Be especially careful to note any
      issues that I may have overlooked.  Our goal is to be complete as
      possible, covering the potential good, bad and ugly consequences of
      changing the TCP-friendly paradigm.</t>

      <t>Please use the ICCRG list for discussion: iccrg@cs.ucl.ac.uk.   If
      you have simple document additions or fixes you can send them directly
      to me at mathis@psc.edu.</t>

      <t>Word counts are only advisory (none yet).  An RFC page is about 400
      words.</t>

      <t>Ellipsis (...) indicate text still needing to be written.  Generally a
      sentience fragment ending with ellipsis is likely to become a full
      paragraph, if not more.</t>

      <t>Text in double square brackets, such as this entire section, are notes
      to authors and will be removed prior to being submitted for RFC
      publication.</t>

      <t>Additional author information and document revision history will be
	posted on a document management page at
	http://staff.psc.edu/mathis/unfriendly/drafts/</t>

      <t>]]</t>

    </section>
  </section>
  <section anchor="introduction" title="Introduction">
    <t>The current Internet fairness model is based on separate
      principles.....</t>

    <t>First, that bottlenecks can send "independent signals" (drops or marks) to all flows....</t>

    <t>Second, that all protocols and application have "uniform response" to
      these .....</t>

    <t>Third, that the congestion response has to be "AIMD like".....</t>

    <t>This paradigm approximates "window fairness"  [CJ89 - Chiu and Jain, Analysis of
      AIMD for Congestion Control...]</t>

    <t>Our position is that we should consider explicitly inverting the first
      principle: require that the network be able to isolate flows and send different
      congestion signals to each, according to some explicit capacity
      allocation mechanism.</t>

    <t>As the network progressively takes on more responsibility for capacity allocation, we
      can progressively relax both of the other assumptions.... which can
      solve a number of other long standing problems...</t>

    <t><xref target="motivation" /> describes some of the problems with
      the current paradigm....</t>

    <t><xref target="difficulties" /> describes some of the problems
      that need to be overcome to implement the new paradigm....</t>

    <t><xref target="forward" /> describes a plausible path forward....</t>

  </section>

  <section anchor="motivation" title="Reasons to Change the TCP-friendly paradigm">

    <t>The motivation to change the Internet fairness model comes from a number
      problems with the current model.
      They fall into two broad categories: situations where the
      Internet fails to attain a reasonable definition of fair, and scaling
      problems associated with the AIMD algorithm itself.  These are discussed
      seperatly in sections <xref target="unfair" /> and <xref target="AIMD" /> respectively.</t>

    <section anchor="unfair" title="TCP-friendly isn't fair enough">

      <t>The current Internet fairness model is based on the assumption that
	fairness can be achieved by sending independent signals to different
	flows.   This assumption fails in a number of very common situations
	in todays internet.  Part of the difficulty is that 
	"fairness" itself is sometimes subjective in the sense that what is fair from one point of
	view may be quite unfair from other points of view.  However, in many
	situations the Internet fairness model fails to attain fairness by any
	definition of fairness.</t>

      <t>[[Consider pulling additional examples and text from
      draft-briscoe-tsvwg-relax-fairness-01.txt..]]</t>

      <section anchor="multiple" title="Multiple Connections">
	<t>Applications that open many connections...</t>
      </section>

      <section anchor="nonstandard" title="Non-standard protocols">
	<t>Non-IETF protocols (typically UDP based) that don't try to be
	  fair...</t>
      </section>

      <section anchor="droptail" title="Drop-tail queues">
	<t>Lockout and other problems with drop tail queues, as documented in
	  <xref target="RFC2309">RFC 2309</xref>...</t>
      </section>

      <section anchor="RTT" title="Wildy Different Round Trip Times">
	<t>If the RTTs are very different then window fair becomes egregiously rate unfair...</t>
      </section>

      <section anchor="average" title="Instantaneous and Average Fairness">
	<t>The distinction between instantaneous and average fairness...</t>
      </section>

    </section>

    <section anchor="AIMD" title="AIMD is not suitable for the entire Internet">

      <t>The current TCP-friendly model assumes that the AIMD algorithm is
      suitable for all parts of the Internet.....</t>

      <t>AMID performance goes as 1/sqrt(p)  [[Review math, including E(loss), E(period)]].....</t>

      <t>These are problems that follow from AIMD....</t>

      <section title="AIMD requires excessivly small loss rates">
	<t>Wireless and LFNs requires excessively small loss....... (cite
	work)</t>
      </section>

      <section title="Long convergence times">
	<t>LFNs require extremely long convergence
	  time...... (Mention S. Low scalability work)</t>
      </section>

      <section title="A new standard congestion control?">

	<t>Note that we might pick a new reference congestion control
	  algorithm to replace AIMD.  This would require breaking all three
	  fairness principles during
	  a transition, but would asymptotically reestablish the second
	  principle that protocols have uniform response to congestion
	  signals.</t>

	<t>Such an approach would mitigate a number of the problems discussed
	  int <xref target="difficulties" />, however it requires reestablishing a new
	  standard one-size-fits-all congestion algorithm.  Given the likely
	  extended debate to come to consensus on such a standard and
	  the very long deployment cycle, we take
	  the position that the transition itself should be viewed as the long
	  term steady state, with diverse congestion control algorithms
	  co-existing in the operational Internet.</t>

	<t>This in not to say that a new, better standard congestion control
	  might not emerge in the future, but it is a not a goal at this
	  time.</t>
      </section>

      <section title="No provider input">
	<t>Providers want to be able to make business policy re-traffic....</t>
	<t>Are moving away from "independent signals" anyhow...</t>
	<t>We are not proposing to break net neutrality...</t>
	<t>[[This entire section may belong elsewhere]]</t>
      </section>


    </section>

  </section>

  <section anchor="difficulties" title="Difficulties to be Overcome">
    <t>Reasons not to change and/or problems we must solve first....</t>
    <section title="The Transition">
      <t>Must avoid new CC into old bottlenecks...</t>
    </section>

    <section anchor="collapse" title="Risk of Congestion Collapse">
      <t>TCP-friendly was used as a proxy for preventing congestion collapse.
	We need new methods for assuring that protocols are not subject to
	congestion collapse....</t>

    </section>

    <section anchor="economic" title="Loss of Appropriate Economic Incentives">
      <t>Current TCP provides window fair....</t>

      <t>Current network based techniques are likely enforce rate fair....</t>

      <t>...causes loss of incentive for traffic locality....</t>

      <t>No incentive for CDN and other techniques for content providers to
	move data closer to clients ...</t>

      <t>No incentives for clients to choose close data.... No incentives for ALTO...</t>
      
    </section>

    <section anchor="implicit" title="Loss of Implicit Fairness">
      <t>Even if it the existing models only provide weak fairness, there are
	many situations where this is important...</t>

      <t>In particular the independent congestion signal assumption does not
	depend on flow classification.   The new paradigm requires
	explicit flow classification.   If the flow granularity is too large
	(more than one concurrent micro-flow), then we would like to have
	implicit fairness within the large flow.   This requires uniform
	congestion response within the larger flow, but does not require that
	the individual micro-flows have AIMD like response...</t>

    </section>

    <section anchor="scale" title="Scale Limitations">
      <t>We do not know if the Internet core will be protected well enough from
	congestion....</t>
      
      <t>It has been observed that congestion at the edges tends to
	protect the core...</t>

      <t>AFD works at very large scale, but is it large enough....</t>
    </section>

    <section anchor="research" title="Our Research May be off Base">
      <t>Much CC research has been influenced by one of more of the assumptions
	underlying TCP-Friendly.  If we abandon TCP-Friendly, then some large
	portion of past research may no longer be relevant.....</t>
    </section>

    <section anchor="documents" title="Many IETF Standards may need to be revised">
      <t>Roughly a half dozen have definitional language about TCP-Friendly and
	TCP-Friendly Rate Control.</t>
      <t>Roughly 60 RFC contain references to TCP-Friendly.</t>      
    </section>

  </section>

  <section anchor="forward" title="A Plausable Path Forward">
    <t>[[TBD.  Don't start yet.]]</t>
  </section>

  <section anchor="security" title="Security Considerations">
    <t>Traffic controls in the network can only improve the overall protection from
      DDoS.....
    </t>
  </section>
</middle>

<back>
  <references>  <!-- NB: not standards track - all refs are informative -->
    &rfc2309;
  </references>

  <section anchor="acknowledgments" title="Acknowledgments">
    <t>Thank you everyone...</t>
  </section>

</back>

</rfc>

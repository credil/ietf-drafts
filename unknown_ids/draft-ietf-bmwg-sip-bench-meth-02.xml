<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE rfc SYSTEM "http://xml.resource.org/authoring/rfc2629.dtd" [
<!ENTITY rfc2119 SYSTEM "http://xml.resource.org/public/rfc/bibxml/reference.RFC.2119.xml">
<!ENTITY rfc2544 SYSTEM "http://xml.resource.org/public/rfc/bibxml/reference.RFC.2544.xml">
<!ENTITY rfc3261 SYSTEM "http://xml.resource.org/public/rfc/bibxml/reference.RFC.3261.xml">
]?>

<?rfc toc="yes" ?>
<?rfc compact="yes" ?>
<?rfc sortrefs="no" ?>
<?rfc symrefs="yes" ?>

<rfc docName="DOCNAME"
      ipr="trust200902">

<front>
  <title abbrev="SIP Benchmarking Methodology">
         Methodology for Benchmarking SIP Networking Devices
  </title>
	
  <author initials="S." surname="Poretsky" fullname="Scott Poretsky">
     <organization>Allot Communications</organization>
     <address>
     <postal>
          <street>300 TradeCenter, Suite 4680</street>
          <city>Woburn</city>
          <region>MA</region>
          <code>08101</code>
          <country>USA</country>
       </postal>
       <phone>+1 508 309 2179</phone>
       <email>sporetsky@allot.com</email>
     </address>
     </author>

     <author initials="V." surname="Gurbani" fullname="Vijay K. Gurbani">
     <organization>Bell Laboratories, Alcatel-Lucent</organization>
     <address>
     <postal>
          <street>1960 Lucent Lane</street>
          <street>Rm 9C-533</street>
          <city>Naperville</city>
          <region>IL</region>
          <code>60566</code>
          <country>USA</country>
       </postal> 
       <phone>+1 630 224 0216</phone>
       <email>vkg@bell-labs.com</email>
     </address>
     </author>

     <author initials="C." surname="Davids" fullname="Carol Davids">
     <organization>Illinois Institute of Technology</organization>
     <address>
     <postal>
          <street>201 East Loop Road</street>
          <city>Wheaton</city>
          <region>IL</region>
          <code>60187</code>
          <country>USA</country>
     </postal> 
     <phone>+1 630 682 6024</phone>
     <email>davids@iit.edu</email>
     </address>
     </author>
	
     <date year="2010"/>
	<area>Operations and Management Area</area>
     <workgroup>Benchmarking Methodology Working Group</workgroup>

<abstract>
<t>This document describes the methodology for benchmarking Session Initiation Protocol (SIP) performance as described in SIP benchmarking terminology document.  The methodology and terminology are to be used for benchmarking signaling plane performance with varying signaling and media load.  Both scale and establishment rate are measured by signaling plane performance.  The SIP Devices to be benchmarked may be a single device under test (DUT) or a system under test (SUT).  Benchmarks can be obtained and compared for different types of devices such as SIP Proxy Server, SBC, and server paired with a media relay or Firewall/NAT device. </t> </abstract>

</front>

<middle>

<section title="Terminology">
  <t>In this document, the key words "MUST", "MUST NOT", "REQUIRED",
  "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "NOT
  RECOMMENDED", "MAY", and "OPTIONAL" are to be interpreted as described
  in BCP 14, conforming to <xref target="RFC2119"/> and indicate
  requirement levels for compliant implementations.</t>

  <t>Terms specific to SIP <xref target="RFC3261"/> performance benchmarking
  are defined in <xref target="I-D.sip-bench-term"/>.</t>

  <t>RFC 2119 defines the use of these key words to help make the
  intent of standards track documents as clear as possible.  While this
  document uses these keywords, this document is not a standards track
  document.  The term Throughput is defined in <xref target="RFC2544"/>.</t>

</section> <!-- Terminology -->

<section title="Introduction">
<t>This document describes the methodology for benchmarking Session
   Initiation Protocol (SIP) performance as described in Terminology
   document <xref target="I-D.sip-bench-term"/>.  The methodology and
   terminology are to be used for benchmarking signaling plane performance
   with varying signaling and media load.  Both scale and establishment
   rate are measured by signaling plane performance.</t>

<t>The SIP Devices to be benchmarked may be a single device under test
   (DUT) or a system under test (SUT).  The DUT is a SIP Server, which
   may be any <xref target="RFC3261"/> conforming device.
   The SUT can be any device or group of devices containing RFC 3261 conforming
   functionality along with Firewall and/or NAT functionality.  This
   enables benchmarks to be obtained and compared for different types
   of devices such as SIP Proxy Server, SBC, SIP proxy server
   paired with a media relay or Firewall/NAT device. SIP Associated Media benchmarks can also
   be made when testing SUTs.</t>

<t>The test cases covered in this methodology document provide
   benchmarks metrics of  Registration Rate, SIP Session Establishment Rate,
   Session Capacity, IM Rate, and Presence Rate.  These can be
   benchmarked with or without associated Media.  Some cases are also
   included to cover Forking, Loop detecion, Encrypted SIP, and SIP
   Flooding.  The test topologies that can be used are described in
   the Test Setup section.  Topologies are provided for benchmarking
   of a DUT or SUT.  Benchmarking with Associated Media can be
   performed when using a SUT.</t>

<t>SIP permits a wide range of configuration options that are also
   explained in the Test Setup section.  Benchmark metrics could
   possibly be impacted by Associated Media. The selected values for
   Session Duration and Media Streams Per Session enable benchmark
   metrics to be benchmarked without Associated Media.  Session Setup
   Rate could possibly be impacted by the selected value for Maximum
   Sessions Attempted.  The benchmark for Session Establishment Rate is
   measured with a fixed value for maximum Session Attempts.</t>

</section> <!-- Introduction -->

<section title="Test Topologies" anchor="test-topologies">

  <t> Figures 1 through 3 below provide various topologies to perform
  the SIP Performance Benchmarking.  These figures show the Device
  Under Test (DUT) to be a single server or a System Under Test (SUT).
  Test Topology options to include benchmarking with Associated Media
  require use of a SUT and are shown in Figures 3.</t>

  <figure anchor = "figure-1"
          title = "Basic SIP Test Topology">
  <artwork><![CDATA[
           DUT
         ---------               ---------
         |       |               |       |
         |signal-|
         |ing    |               |       |
         |server |      SIP      |       |
         |       |<------------->|   EA  |
         |       |               |       |
         |       |               |       |
         |       |               |       |
         ---------               ---------
  ]]></artwork></figure>

  <figure anchor= "figure-2"
          title="SIP Test Topology with Firewall">

  <artwork><![CDATA[
                   SUT
         ------------------------
         ---------      ---------         ---------
         |       |      |media- |         |       |
         |signal-|      | relay |         |       |
         |ing    |  SIP |   OR  |   SIP   |       |
         |server |<---------------------->|   EA  |
         |       |      |fire   |         |       |
         |       |      |wall OR|         |       |
         |       |      |  NAT  |         |       |
         ---------      ---------         ---------

  ]]></artwork></figure>

  
  <figure anchor= "figure-3"
          title="SIP Test Topology with Media through Firewall">

  <artwork><![CDATA[
                   SUT
         ------------------------
         ---------      ---------         ---------
         |       |      | media-|         |       |
         |signal-|      |  relay|         |       |
         |ing    |  SIP |   OR  |   SIP   |       |
         |server |<---------------------->|   EA  |
         |       |      |fire   |         |       |
         |       |      |wall OR|  Media  |       |
         |       |   ---|  NAT  |---------|       |
         ---------   |  ---------         ---------
                     |             Media      ^
                     -------------------------|

  ]]></artwork></figure>

  <figure anchor = "figure-4"
          title = "Baseline Test Topology">
  <artwork><![CDATA[
        
                                 ---------
                                 |       |
                  |------------->|       |
                  ^              |       |
                  |      SIP     |       |
                  |<-------------|   EA  |
                                 |       |
                                 |       |
                                 |       |
                                 ---------
  ]]></artwork></figure>


</section> <!-- Test Setup -->

<section title="Test Considerations" anchor="test-considerations">

<section title="Selection of SIP Transport Protocol"
          anchor="SIP-Trans-Pro selection">
  <t>
  <list style="hanging">
    <t>Test cases may be performed with any transport protocol supported
    by SIP.  This includes, but is not limited to, SIP TCP, SIP UDP,
    and TLS.  The protocol used for the SIP transport protocol must
    be reported with benchmarking results.</t>
   <t></t>
  </list>
  </t>
</section>

<section title="Signaling Server" anchor="Signaling-Server">
  <t>
  <list style="hanging">
    <t>The Server is a SIP-speaking device that complies with RFC 3261.
    The purpose of this document is to benchmark SIP performance, not
    conformance.  Conformance to <xref target="RFC3261"/> is
    assumed for all tests.  The Server may be the DUT or a component
    of a SUT that includes Firewall and/or NAT functionality. The
    components of the SUT may be a single physical device or
    separate devices.</t>
   <t></t>
  </list>
  </t>
</section>

<section title="Associated Media" anchor="associated-media">
  <t>
  <list style="hanging">
    <t>Some tests may require associated media to be present for each SIP
    session.  The Server is not involved in the forwarding of media.
    Associated Media can be benchmarked only with a SUT in which the
    media traverses a Media Relay, Firewall, NAT, or Firewall/NAT device.  The
    test topologies to be used when benchmarking SUT performance
    for Associated Media are shown in Figures 4 and 5, in which the SIP
    signaling is bidirectional and the Associated Media is unidirectional.</t>
  </list>
  </t>
</section>

<section title="Selection of Associated Media Protocol"
  anchor="associated-media-pro-selection">
  <t>
  <list style="hanging">
    <t>The test cases specified in this document provide SIP performance
    independent of the protocol used for the media stream.  Any media
    protocol supported by SIP may be used.  This includes, but is not
    limited to, RTP, RTSP, and SRTP.  The protocol used for
    Associated Media MUST be reported with benchmarking results. </t>
  </list>
  </t>
</section>

<section title="Number of Associated Media Streams per SIP Session"
           anchor="assoc-media-stream-number-per-SIP-session">
  <t>
  <list style="hanging">
    <t>Benchmarking results may vary with the number of media
    streams per SIP session.  When benchmarking a SUT for voice, a
    single media stream is used.  When benchmarking a SUT for voice
    and video, two media streams are used.  The number of Associated
    Media Streams MUST be reported with benchmarking results. </t>
  </list>
  </t>
</section>

<section title="Session Duration" anchor="session-duration">
  <t>
  <list style="hanging">
    <t>SUT performance benchmarks may vary with the duration
    of SIP sessions. Session Duration MUST be reported with
    benchmarking results.  A Session Duration of zero seconds
    indicates transmission of a BYE immediately following successful
    SIP establishment indicate by receipt of a 200 OK.  An infinite
    Session Duration indicates that a BYE is never transmitted.</t>
  </list>
  </t>
</section>

<section title="Attempted Sessions per Second"
          anchor="sessions-attempted-per-second">
  <t>
  <list style="hanging">
    <t>DUT and SUT performance benchmarks may vary with the
    the rate of attempted sessions offered by the Tester.  Attempted
    Sessions per Second MUST be reported with benchmarking results.</t>
  </list>
  </t>
</section>

<section title="Stress Testing" anchor="stress-testing">
  <t>
  <list style="hanging">
   <t hangText="Discussion:"></t>
    <t>The purpose of this document is to benchmark SIP performance, not
    system stability under stressful conditions such as a high rate
    of Attempted Sessions per Second.</t>
  </list>
  </t>
</section>

</section> <!-- test-considerations -->

<section title="Reporting Format"
          anchor="reporting-format">

<section title="Test Setup Report"
          anchor="test-setup-report">
  <t><figure><artwork>
  SIP Transport Protocol = ___________________________ 
  (valid values: TCP|UDP|TLS|SCTP|specify-other) 
  Session Attempt Rate = _____________________________ 
  (session attempts/sec)
  IS Media Attempt Rate = ____________________________ 
  (IS media attempts/sec)
  Total Sessions Attempted = _________________________ 
  (total sessions to be created over duration of test)
  Media Streams Per Session =  _______________________ 
  (number of streams per session)
  Associated Media Protocol =  _______________________ 
  (RTP|RTSP|specify-other)
  Media Packet Size =  _______________________________ 
  (bytes)
  Media Offered Load =  ______________________________ 
  (packets per second)
  Media Session Hold Time =  _________________________ 
  (seconds)
  Establishment Threshold time =  ____________________ 
  (seconds)
  Loop Detecting Option =  ___________________________ 
  (on|off)
  Forking Option 
     Number of endpoints request sent to = ___________ 
  (1, means forking is not enabled)
     Type of forking = _______________________________ 
  (serial|parallel)
  </artwork></figure></t>

  <t> Note: Total Sessions Attempted is used in the calculation of the Session 
  Establishment Performance (<xref target="I-D.sip-bench-term"/>, Section 3.4.5).  
  It is the number of session attempts (<xref target="I-D.sip-bench-term"/>, 
  Section 3.1.6) that will be made over the duration of the test.</t>

</section> <!-- Test setup report-->

<section title="Device Benchmarks for IS"
          anchor="device-benchmarks-IS">
  <t><figure><artwork>
  Registration Rate =  _______________________________ 
  (registrations per second)
  Re-registration Rate =  ____________________________ 
  (registrations per second)
  Session Capacity = _________________________________ 
  (sessions)
  Session Overload Capacity = ________________________ 
  (sessions)
  Session Establishment Rate =  ______________________ 
  (sessions per second)
  Session Establishment Performance =  _______________ 
  (total established sessions/total sessions attempted)(no units)
  Session Attempt Delay =  ___________________________ 
  (seconds)
 
  </artwork></figure></t>

</section> <!-- device-benchmark-IS -->

<section title="Device Benchmarks for NS"
          anchor="device-benchmarks-NS">
  <t><figure><artwork>
  IM Rate =  _______________________________ (IM messages per second)
  </artwork></figure></t>

</section> <!-- device-benchmark-NS -->

</section> <!-- reporting-format -->

<section title="Test Cases"
          anchor="test-cases"> 
<section title="Baseline Session Establishment Rate" anchor="base-sess-est-rate">
  <t>
  <list style="hanging">
   <t hangText="Objective:"></t>
    <t>To benchmark the Session Establishment Rate
       of the DUT/SUT with zero failures.</t>

   <t hangText="Procedure:">
    <list style= "numbers">
     <t>Configure the test bed in the test topology shown in Figure 4.</t>
     <t>Configure Tester with a Session Attempt Rate =
      100 SPS, maximum Session Attempts = 100,000 and Media Streams Per
          Session=0.</t>
     <t>Start Tester to initiate SIP Session establishment with the DUT.</t>
     <t>Measure Session Attempt Failures and total Established Sessions at
      the Tester.</t>
     <t>If a Session Attempt Failure is recorded then reduce the Session
          Attempt Rate configured on the Tester by 50%.</t>
     <t>If no Session Attempt Failure is recorded then increase the
      Session Attempt Rate configured on the Tester by 50%.</t>
     <t>Repeat steps 3 through 6 until the Session Establishment
      Rate is obtained and recorded.</t>
   </list> </t>
  <t hangText="Expected Results:">This is the scenario to obtain the maximum 
  Session Establishment Rate of the test bed when no DUT?SUT is present.  The results of 
  this test might be used to normalize test results performed on different test beds or simply to better
  understand the impact of the DUT/SUT on the test bed in question.</t>
  </list>
  </t>
</section> <!-- Session Establishment Rate -->

<section title="Session Establishment Rate" anchor="sess-est-rate">
  <t>
  <list style="hanging">
   <t hangText="Objective:"></t>
    <t>To benchmark the Session Establishment Rate
       of the DUT/SUT with zero failures.</t>

   <t hangText="Procedure:">
    <list style= "numbers">
     <t>Configure the DUT in the test topology shown in Figure 1 or
      SUT as shown in Figures 2 or 3.</t>
     <t>Configure Tester with a Session Attempt Rate =
      100 SPS, maximum Session Attempts = 100,000 and Media Streams Per
          Session=0.</t>
     <t>Start Tester to initiate SIP Session establishment with the DUT.</t>
     <t>Measure Session Attempt Failures and total Established Sessions at
      the Tester.</t>
     <t>If a Session Attempt Failure is recorded then reduce the Session
          Attempt Rate configured on the Tester by 50%.</t>
     <t>If no Session Attempt Failure is recorded then increase the
      Session Attempt Rate configured on the Tester by 50%.</t>
     <t>Repeat steps 3 through 6 until the Session Establishment
      Rate is obtained and recorded.</t>
   </list> </t>
  <t hangText="Expected Results:">This is the scenario to obtain the maximum 
  Session Establishment Rate of the DUT/SUT.</t>
  </list>
  </t>
</section> <!-- Session Establishment Rate -->

<section title="Session Establishment Rate with Media"
          anchor="session-attempt-rate-with-media">
  <t>
  <list style="hanging">
   <t hangText="Objective:"></t>
    <t>To benchmark the Session Establishment Rate of the SUT with
     zero failures when Associated Media is included in the benchmark test.</t>

   <t hangText="Procedure:">
   <list style= "numbers">
    <t>Configure the SUT in the test topology shown in Figure 2 or 3.</t>
    <t>Configure Tester for a Session Attempt Rate = 100 SPS,
     maximum Session Attempts = 100,000 and Media Streams Per Session = 1.
         The rate of offered load for each media stream SHOULD be (eq 1)
         Offered Load per Media Stream = Throughput / maximum sessions
         attempted, where Throughput is defined in <xref target="RFC2544"/>.</t>
    <t>Start Tester to initiate SIP Session establishment with the
     SUT and transmit media through the SUT to a destination other
     than the server.</t>
    <t>At the Tester measure Session Attempt Failures, total Established
     Sessions, and Packet Loss <xref target="RFC2544"/> of the media.</t>
    <t>If a Session Attempt Failure or Packet Loss is recorded then
     reduce the Session Attempt Rate configured on the Tester by 50%.</t>
    <t>If no Session Attempt Failure or Packet Loss is recorded then
     increase the Session Attempt Rate configured on the Tester by 50%.</t>
    <t>Repeat steps 3 through 6 until the Session Establishment Rate is
     obtained and recorded.</t>
    <t>Repeat steps 1 through 7 for multimedia in which Media Streams
     Per Session = 2. </t>
  </list></t>

  <t hangText="Expected Results:">Session Establishment Rate results obtained 
  with Associated Media with any number of media streams per SIP session  
  are expected to be identical to the Session Establishment Rate results 
  obtained without media in the case where the server is running on a 
  platform separate from the platform on which the Media Relay, NAT or 
  Firewall is running.  Session Establishment Rate results obtained with 
  Associated Media may be lower than those obtained without media in 
  the case where the server and the NAT, Firewall or Media Relay are running 
  on the same platform.</t>
  </list>
  </t>

</section> <!-- Session Establishment Rate with media -->

<section title="Session Establishment Rate with Loop Detection Enabled"
          anchor="ssr-loop-detection-enabled">
  <t>
  <list style="hanging">
   <t hangText="Objective:"></t>
    <t>To benchmark the Session Establishment Rate of the DUT/SUT with
       zero failures when the Loop Detection option is enabled.</t>

   <t hangText="Procedure:">
   <list style= "numbers">
    <t>Configure the DUT in the test topology shown in Figure 1 or
     SUT as shown in Figures 2 or 3.</t>
    <t>Configure Tester for a Session Attempt Rate =
     100 SPS, maximum Session Attempts = 100,000 and Media Streams Per
         Session=0.</t>
    <t>Turn on the Loop Detection option in the DUT or SUT.</t>
    <t>Start Tester to initiate SIP Session establishment with the DUT.</t>
    <t>Measure Session Attempt Failures and total Established Sessions at
     the Tester.</t>
    <t>If a Session Attempt Failure is recorded then reduce the
     Session Attempt Rate configured on the Tester by 50%.</t>
    <t>If no Session Attempt Failure is recorded then increase the
     Session Attempt Rate configured on the Tester by 50%.</t>
    <t>Repeat steps 4 through 7 until the Session Establishment Rate is
     obtained and recorded.</t>
    </list></t>

  <t hangText="Expected Results:">Session Establishment Rate results 
  obtained with Loop Detection may be lower than those obtained without 
  Loop Detection enabled.</t>
  </list>
  </t>
</section> <!-- Session Establishment Rate with loop detection enabled -->

<section title="Session Establishment Rate with Forking"
          anchor="ssr-forking">
  <t>
  <list style="hanging">
   <t hangText="Objective:"></t>
   <t>To benchmark the Session Establishment Rate of the DUT/SUT with
       zero failures when the Forking Option is enabled.</t>

   <t hangText="Procedure:">
   <list style= "numbers">
    <t>Configure the DUT in the test topology shown in Figure 1 or
     SUT as shown in Figures 2 or 3.</t>
    <t>Configure Tester for a Session Attempt Rate =
     100 SPS, maximum Session Attempts = 100,000 and Media Streams Per
         Session=0.</t>
    <t>Set the number of endpoints that will receive the forked
       invitation to a value of 2 or more (subsequent tests may increase 
       this value at the discretion of the tester.)</t>
    <t>Start Tester to initiate SIP Session establishment with the DUT.</t>
    <t>Measure Session Attempt Failures and total Established Sessions at
     the Tester.</t>
    <t>If a Session Attempt Failure is recorded then reduce the
     Session Attempt Rate configured on the Tester by 50%.</t>
    <t>If no Session Attempt Failure is recorded then increase the
     Session Attempt Rate configured on the Tester by 50%.</t>
    <t>Repeat steps 4 through 7 until the Session Establishment Rate
     is obtained and recorded.</t>
   </list></t>

  <t hangText="Expected Results:">Session Establishment Rate results obtained 
  with Forking may be lower than those obtained without Forking enabled.</t>
  </list>
  </t>
</section> <!-- Session Establishment Rate with forking -->

<section title="Session Establishment Rate with Forking and Loop Detection"
          anchor="ssr-forking-and-loop-detection">
  <t>
  <list style="hanging">
   <t hangText="Objective:"></t>
   <t>To benchmark the Session Establishment Rate of the DUT/SUT with zero
    failures when both the Forking and Loop Detection Options are
    enabled.</t>

   <t hangText="Procedure:">
   <list style= "numbers">
    <t>Configure the DUT in the test topology shown in Figure 1 or
     SUT as shown in Figures 2 or 3.</t>
    <t>Configure Tester for a Session Attempt Rate =
     100 SPS, maximum Session Attempts = 100,000 and Media Streams Per
     Session=0.</t>
    <t>Start Tester to initiate SIP Session establishment with the DUT.</t>
    <t>Enable the Loop Detection Options on the DUT.</t>
    <t>Set the number of endpoints that will receive the forked
       invitation to a value of 2 or more (subsequent tests may increase 
       this value at the discretion of the tester.)</t>
    <t>Measure Session Attempt Failures and total Established Sessions at
     the Tester.</t>
    <t>If a Session Attempt Failure is recorded then reduce the
     Session Attempt Rate configured on the Tester by 50%.</t>
    <t>If no Session Attempt Failure is recorded then increase the
     Session Attempt Rate configured on the Tester by 50%.</t>
    <t>Repeat steps 4 through 7 until the Session Establishment
     Rate is obtained and recorded.</t>
   </list></t>

  <t hangText="Expected Results:">Session Establishment Rate results 
  obtained with Forking and Loop Detection may be lower than those 
  obtained with only Forking or Loop Detection enabled.</t>
  </list>
  </t>
</section> <!-- Session Establishment Rate with forking and loop 
detection-->

<section title="Session Establishment Rate with TLS Encrypted SIP"
          anchor="ssr-with-TLS-Encrypted-SIP">
  <t>
  <list style="hanging">
   <t hangText="Objective:"></t>
   <t>To benchmark the Session Establishment Rate
       of the DUT/SUT with zero failures when using TLS encrypted SIP.</t>

   <t hangText="Procedure:">
   <list style= "numbers">
    <t>Configure the DUT in the test topology shown in Figure 1 or
     SUT as shown in Figures 2 or 3.</t>
    <t>Configure Tester for SIP TCP, enable TLS, Session Attempt Rate =
    100 SPS, maximum Session Attempts = 100,000 and Media Streams Per
    Session = 0.</t>
   <t>Start Tester to initiate SIP Session establishment with the DUT.</t>
   <t>Measure Session Attempt Failures and total Established Sessions
      at the Tester.</t>
   <t>If a Session Attempt Failure is recorded then reduce the
    Session Attempt Rate configured on the Tester by 50%.</t>
   <t>If no Session Attempt Failure is recorded then increase the
    Session Attempt Rate configured on the Tester by 50%.</t>
   <t>Repeat steps 3 through 6 until the Session Establishment
    Rate is obtained and recorded.</t>
  </list></t>

  <t hangText="Expected Results:">Session Establishment Rate results 
  obtained with TLS Encrypted SIP may be lower than those obtained 
  with plaintext SIP.</t>
  </list>
  </t>
</section> <!-- Session Establishment Rate with TLS Encrypted SIP -->

<section title="Session Establishment Rate with IPsec Encrypted SIP"
          anchor="ssr-with-IPsec-Encrypted-SIP">
  <t>
  <list style="hanging">
   <t hangText="Objective:"></t>
    <t>To benchmark the Session Establishment Rate
       of the DUT/SUT with zero failures when using IPsec Encryoted SIP.</t>

   <t hangText="Procedure:">
   <list style= "numbers">
    <t>Configure the DUT in the test topology shown in Figure 1 or
     SUT as shown in Figures 2 or 3.</t>
    <t>Configure Tester for SIP TCP, enable IPSec, Session Attempt Rate =
    100 SPS, maximum Session Attempts = 100,000 and Media Streams Per
    Session = 0.</t>
   <t>Start Tester to initiate SIP Session establishment with the DUT.</t>
   <t>Measure Session Attempt Failures and total Established Sessions at
    the Tester.</t>
   <t>If a Session Attempt Failure is recorded then reduce the
    Session Attempt Rate configured on the Tester by 50%.</t>
   <t>If no Session Attempt Failure is recorded then increase the
    Session Attempt Rate configured on the Tester by 50%.</t>
   <t>Repeat steps 3 through 6 until the Session Establishment
    Rate is obtained and recorded.</t>
   </list></t>

  <t hangText="Expected Results:">Session Establishment Rate results 
  obtained with IPSec Encrypted SIP may be lower than those obtained 
  with plaintext SIP.</t>
  </list>
  </t>
</section> <!-- Session Establishment Rate with IPsec Encrypted SIP -->

<section title="Session Establishment Rate with SIP Flooding"
          anchor="session-setup-rate-with-SIP-Flooding">
  <t>
  <list style="hanging">
   <t hangText="Objective:"></t>
    <t>To benchmark the Session Establishment Rate
       of the SUT with zero failures when SIP Flooding is occurring.</t>

   <t hangText="Procedure:">
   <list style= "numbers">
    <t>Configure the DUT in the test topology shown in Figure 1 or
     the SUT as shown in Figure 2.</t>
    <t>Configure Tester for SIP UDP with an Session Attempt Rate =
     100 SPS, maximum Session Attempts = 100,000, Associated Media Streams
         Per Session = 0, and SIP INVITE Message Flood = 500 per second. 
</t>
    <t>Start Tester to initiate SIP Session establishment with the
     SUT and SIP Flood targetted at the Server.</t>
    <t>At the Tester measure Session Attempt Failures, total Established
     Sessions, and Packet Loss <xref target="RFC2544"/> of the media.</t>
    <t>If a Session Attempt Failure or Packet Loss is recorded then
     reduce the Session Attempt Rate configured on the Tester by 50%.</t>
    <t>If no Session Attempt Failure or Packet Loss is recorded then
     increase the Session Attempt Rate configured on the Tester by 50%.</t>
    <t>Repeat steps 3 through 6 until the Session Establishment Rate is
     obtained and recorded.</t>
    <t> Repeat steps 1 through 7 with SIP INVITE Message Flood =
     1000 per second.</t>
    </list></t>

  <t hangText="Expected Results:">Session Establishment Rate results obtained 
  with SIP Flooding may be degraded.</t>
  </list>
  </t>
</section> <!-- Session Establishment Rate with SIP Flooding -->

<section title="Maximum Registration Rate"
          anchor="registration-rate">
  <t>
  <list style="hanging">
   <t hangText="Objective:"></t>
    <t>To benchmark the maximum registration rate of the DUT/SUT with
       zero failures.</t>

   <t hangText="Procedure:">
   <list style= "numbers">
    <t>Configure the DUT in the test topology shown in Figure 1 or
     SUT as shown in Figures 2 or 3.</t>
    <t>Configure Tester with a Registration Rate =
     100 SPS and maximum registrations attempted = 100,000. </t>
    <t>Set the registration timeout value to at least 3600 seconds.</t>
    <t>At the Tester measure failed registration attempts, total registrations
     and packet loss.</t>
    <t>If a Failed Registration Attempt or Packet Loss is recorded then
     reduce the Attempted Registration Rate configured on the Tester by 50%.</t>
    <t>If no Failed Registration or Packet Loss is recorded then
     increase the Attempted Registration Rate configured on the Tester
     by 50%.</t>
    <t>Repeat steps 5 and 6 until the all registrations have succeeded.
       This number is obtained and recorded.</t>
   </list></t>

  <t hangText="Expected Results:"></t>
  </list>
  </t>
</section> <!-- Maximum Registration Rate -->


<section title="Maximum Re-Registration Rate"
          anchor="re-registration-rate">
  <t>
  <list style="hanging">
   <t hangText="Objective:"></t>
    <t>To benchmark the maximum re-registration rate of the DUT/SUT with
       zero failures.</t>

   <t hangText="Procedure:">
   <list style= "numbers">
    <t>Configure the DUT in the test topology shown in Figure 1 or
     SUT as shown in Figures 2 or 3.</t>
    <t>Execute test detailed in <xref target="registration-rate"/>
     to register the endpoints with the registrar.  The rest of the
     steps below MUST be performed at least 5 minutes after, but no more than
     15 minutes after the test performed in <xref target="registration-rate"/>.
    </t>
    <t>Configure Tester for an attempted Registration Rate =
     100 SPS and maximum registrations attempted = 100,000.</t>
    <t>Configure Tester to re-register the same address-of-records that
       were registered in <xref target="registration-rate"/>.</t>
    <t>At the Tester measure failed registration attempts, total registrations
     and packet loss.</t>
    <t>If a Failed Registration Attempt or Packet Loss is recorded then
     reduce the Attempted Registration Rate configured on the Tester by 50%.</t>
    <t>If no Failed Registration or Packet Loss is recorded then
     increase the Attempted Registration Rate configured on the Tester
     by 50%.</t>
    <t>Repeat steps 6 and 7 until the all re-registrations have succeeded.
       This number is obtained and recorded.</t>

   </list></t>

  <t hangText="Expected Results:">The rate should be at least equal to 
  but not more than the result of <xref target="registration-rate"/>.</t>
  </list>
  </t>
</section> <!-- Maximum Registration Rate -->

<section title="Maximum IM Rate" anchor="IM-rate">
  <t>
  <list style="hanging">
   <t hangText="Objective:"></t>
    <t>To benchmark the maximum IM rate of the SUT with
       zero failures.</t>

   <t hangText="Procedure:">
   <list style= "numbers">
    <t>Configure the DUT in the test topology shown in Figure 1 or
     SUT as shown in Figures 2 or 3.</t>
    <t>Configure Tester for an IM Rate = 100 SPS,
       Maximum IM Attempted = 100,000. </t>
    <t>At the Tester measure Failed IM Attempts, Total IM and Packet Loss.</t>
    <t>If a Failed IM Attempt or Packet Loss is recorded then reduce the
     Attempted IM Rate configured on the Tester by 50%.</t>
    <t>If no Failed IM or Packet Loss is recorded then increase the Attempted
     IM Rate configured on the Tester by 50%.</t>
    <t>Repeat steps 3 through 6 until the Maximum IM Rate is
    obtained and recorded.</t>


   </list></t>

   <t hangText="Expected Results:"></t>
  </list>
  </t>
</section> <!-- Maximum IM Rate -->

<section title="Session Capacity without Media" anchor="max-sess-cao">
  <t>
  <list style="hanging">
   <t hangText="Objective:"></t>
    <t>To benchmark the Session Capacity of the SUT without Associated 
       Media.</t>

   <t hangText="Procedure:">
   <list style= "numbers">
    <t>Configure the DUT in the test topology shown in Figure 1 or
     SUT as shown in Figures 2 or 3.</t>
    <t>Configure Tester for a Session Attempt Rate =
     Session Establishment Rate,
     maximum Session Attempts = 10,000 and Media Streams Per Session = 0.</t>
    <t>Start Tester to initiate SIP Session establishment with the DUT.</t>
    <t>Measure Session Attempt Failures, total Established Sessions,
     and Packet Loss <xref target="RFC2544"/> at the Tester.</t>
    <t>If a Session Attempt Failure or Packet Loss is recorded then
     reduce the maximum Session Attempts configured on the Tester by
     5,000.</t>
    <t>If no Session Attempt Failure or Packet Loss is recorded then
     increase the maximum Session Attempts configured on the Tester by
     10,000.</t>
    <t>Repeat steps 3 through 6 until the Session Capacity is obtained and
    recorded.</t>
    <t> Repeat steps 1 through 7 for multimedia in which media streams per
     session = 2. </t>
   </list></t>

  <t hangText="Expected Results:">This is the scenario to obtain the 
  maximum Session Capacity of the DUT/SUT.</t>

  </list>
  </t>
</section> <!-- Session Capacity  -->

<section title="Session Capacity with Media"
          anchor="session-cao-w-media">
  <t>
  <list style="hanging">
   <t hangText="Objective:"></t>
    <t>To benchmark the session capacity of the DUT/SUT with Associated 
    Media.</t>

   <t hangText="Procedure:">
   <list style= "numbers">
    <t>Configure the DUT in the test topology shown in Figure 1 or
     SUT as shown in Figures 2 or 3.</t>
    <t>Configure Tester for a Session Attempt Rate =
     100 SPS, Session Duration = 30 sec, maximum Session Attempts
     = 100,000 and Media Streams Per Session = 1.
     <list style="empty">
      <t>NOTE: The total offered load to the DUT/SUT SHOULD be
      equal to the Throughput of the DUT/SUT as defined in
      <xref target="RFC2544"/>.  The offered load to the DUT/SUT for
      each media stream SHOULD be equal to</t>
      <t>Throughput/Maximum Session Attemps.</t>
     </list>
    </t>
    <t>Start Tester to initiate SIP Session establishment with the
     SUT and transmit media through the SUT to a destination other
     than the server.</t>
    <t>Measure Session Attempt Failures and total Established Sessions
     at the Tester.</t>
    <t>If a Session Attempt Failure is recorded then reduce the
     maximum Session Attempts configured on the Tester by 5,000.</t>
    <t>If no Session Attempt Failure is recorded then increase the
     maximum Session Attempts configured on the Tester by 10,000.</t>
    <t>Repeat steps 3 through 6 until the Session Capacity is obtained
    and recorded.</t>
   </list></t>

  <t hangText="Expected Results:">Session Capacity results obtained 
  with Associated Media with any number of media streams per SIP 
  session will be identical to the Session Capacity results obtained 
  without media.</t>
  </list>
  </t>
</section> <!-- max session est rate with media -->

<section title="Session Capacity with Media and a Media Relay/NAT
                and/or Firewall"
         anchor="sc-m-fw">

   <t>
   <list style="hanging">
   <t hangText="Objective:"></t>
    <t>To benchmark the Session Establishment Rate of the SUT with
      Associated Media.</t>
   <t hangText="Procedure:">
   <list style= "numbers">
    <t>Configure the SUT in the test topology shown in Figure 3.</t>
    <t>Configure Tester for a Session Attempt Rate =
     100 SPS, Session Duration = 30 sec, maximum Session Attempts
     = 100,000 and Media Streams Per Session = 1.
     <list style="empty">
      <t>NOTE: The offered load for each media stream SHOULD be as
      in Equation 1.</t>
     </list>
    </t>
    <t>Start Tester to initiate SIP Session establishment with the
       SUT and transmit media through the SUT to a destination other
       than the server.</t>
    <t>Measure Session Attempt Failures and total Established
       Sessions at the Tester.</t>
    <t>If a Session Attempt Failure is recorded then reduce the
       maximum Session Attempts configured on the Tester by 5,000.</t>
    <t>If no Session Attempt Failure is recorded then increase the
       maximum Session Attempts configured on the Tester by 10,000.</t>
    <t>Repeat steps 3 through 6 until the Session Capacity is
       obtained and recorded.</t>
   </list></t>

  <t hangText="Expected Results:">Session Capacity results obtained with
  Associated Media with any number of media streams per SIP session
  may be lower than the Session Capacity without Media result if the
  Media Relay, NAT or Firewall is sharing a platform with the server.</t>
  </list>
  </t>

</section> <!-- sc-m-fw -->

</section> <!-- test-cases -->

<section title="IANA Considerations" anchor="iana">

  <t>This document does not requires any IANA considerations.</t>

</section>

<section title="Security Considerations" anchor="security">

  <t>Documents of this type do not directly affect the security of Internet
    or corporate networks as long as benchmarking is not performed on
    devices or systems connected to production networks.  Security threats
    and how to counter these in SIP and the media layer is discussed
    in RFC3261, RFC3550, and RFC3711 and various other drafts.  This document
    attempts to formalize a set of common methodology for benchmarking
    performance of SIP devices in a lab environment.</t> </section>

<section title="Acknowledgments" anchor="acks">

  <t>The authors would like to thank Keith Drage and Daryl Malas for their
  contributions to this document.</t>

</section>


</middle>

<back>

<references title="Normative References">
   &rfc2119;
   &rfc2544;
   <reference anchor="I-D.sip-bench-term">
    <front>
     <title>SIP Performance Benchmarking Terminology</title>
     <author initials="S." surname="Poretsky"><organization/></author>
     <author initials="V." surname="Gurbani"><organization/></author>
     <author initials="C." surname="Davids"><organization/></author>
     <date month="July" year="2010"/>
    </front>
    <seriesInfo name="Internet-Draft"
                value="draft-ietf-bmwg-sip-bench-term-02"/>
    <format type="TXT"
            target="http://www1.tools.ietf.org/html/draft-ietf-bmwg-sip-bench-te
rm-02.txt"/>
   </reference>

 </references>

<references title="Informative References">
   &rfc3261;
</references>

</back>

</rfc>


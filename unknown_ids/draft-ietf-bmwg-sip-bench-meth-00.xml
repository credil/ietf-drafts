<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE rfc SYSTEM "http://xml.resource.org/authoring/rfc2629.dtd" [
<!ENTITY rfc2119 SYSTEM "http://xml.resource.org/public/rfc/bibxml/reference.RFC.2119.xml">
<!ENTITY rfc2544 SYSTEM "http://xml.resource.org/public/rfc/bibxml/reference.RFC.2544.xml">
<!ENTITY rfc3261 SYSTEM "http://xml.resource.org/public/rfc/bibxml/reference.RFC.3261.xml">
]>
<?rfc toc="yes" ?>
<?rfc compact="yes" ?>
<?rfc sortrefs="no" ?>
<?rfc symrefs="yes" ?>

<rfc docName="DOCNAME"
     ipr="trust200902">

<front>
 <title abbrev="SIP Benchmarking Methodology">
        Methodology for Benchmarking SIP Networking Devices
 </title>
	
 <author initials="S." surname="Poretsky" fullname="Scott Poretsky">
    <organization>Allot Communications</organization>
    <address>
      <postal>
         <street>67 South Bedford Street, Suite 400</street>
         <city>Burlington</city>
         <region>MA</region>
         <code>08103</code>
         <country>USA</country>
      </postal>
      <phone>+1 508 309 2179</phone>
      <email>sporetsky@allot.com</email>
    </address>
    </author>

    <author initials="V." surname="Gurbani" fullname="Vijay K. Gurbani">
    <organization>Bell Laboratories, Alcatel-Lucent</organization>
    <address>
      <postal>
         <street>1960 Lucent Lane</street>
         <street>Rm 9C-533</street>
         <city>Naperville</city>
         <region>IL</region>
         <code>60566</code>
         <country>USA</country>
      </postal>
      <phone>+1 630 224 0216</phone>
      <email>vkg@alcatel-lucent.com</email>
    </address>
    </author>

    <author initials="C." surname="Davids" fullname="Carol Davids">
    <organization>Illinois Institute of Technology</organization>
    <address>
      <postal>
         <street>201 East Loop Road</street>
         <city>Wheaton</city>
         <region>IL</region>
         <code>60187</code>
         <country>USA</country>
      </postal>
      <email>davids@iit.edu</email>
    </address>
    </author>
	
    <date year="2009"/>
	<area>Operations and Management Area</area>
    <workgroup>Benchmarking Methodology Working Group</workgroup>

<abstract>
<t>This document describes the methodology for benchmarking Session 
Initiation Protocol (SIP) performance as described in SIP
benchmarking terminology document.  The methodology and 
terminology are to be used for benchmarking signaling plane performance 
with varying signaling and media load.  Both scale and establishment 
rate are measured by signaling plane performance.  The SIP Devices to 
be benchmarked may be a single device under test (DUT) or a system 
under test (SUT).  Benchmarks can be obtained and compared for different 
types of devices such as SIP Proxy Server, SBC, P-CSCF, and Server 
paired with a Firewall/NAT device. </t>
</abstract>

</front>

<middle>

<section title="Terminology">
 <t>In this document, the key words "MUST", "MUST NOT", "REQUIRED",
 "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "NOT
 RECOMMENDED", "MAY", and "OPTIONAL" are to be interpreted as described
 in BCP 14, conforming to <xref target="RFC2119"/> and indicate
 requirement levels for compliant implementations.</t>

 <t>Terms specific to SIP <xref target="RFC3261"/> performance benchmarking 
 are defined in <xref target="I-D.sip-bench-term"/>.</t>

 <t>RFC 2119 defines the use of these key words to help make the
 intent of standards track documents as clear as possible.  While this
 document uses these keywords, this document is not a standards track
 document.  The term Throughput is defined in <xref target="RFC2544"/>.</t>

</section> <!-- Terminology -->

<section title="Introduction">
<t>This document describes the methodology for benchmarking Session
  Initiation Protocol (SIP) performance as described in Terminology
  document <xref target="I-D.sip-bench-term"/>.  The methodology and
  terminology are to be used for benchmarking signaling plane performance
  with varying signaling and media load.  Both scale and establishment
  rate are measured by signaling plane performance.</t>

<t>The SIP Devices to be benchmarked may be a single device under test
  (DUT) or a system under test (SUT).  The DUT is a SIP Server, which
  may be any <xref target="RFC3261"/> conforming device.
  The SUT can be any device or group of devices containing RFC 3261 conforming
  functionality along with Firewall and/or NAT functionality.  This
  enables benchmarks to be obtained and compared for different types
  of devices such as SIP Proxy Server, SBC, P-CSCF, Proxy Server
  paired with a Firewall/NAT device, and P-CSCF paired with a
  Firewall/NAT device.  SIP Associated Media benchmarks can also
  be made when testing SUTs.</t>

<t>The test cases covered in this methodology document provide
  benchmarks metrics of  Registration Rate, SIP Session Establishment Rate,
  Session Capacity, IM Rate, and Presence Rate.  These can be
  benchmarked with or without associated Media.  Some cases are also
  included to cover Forking, Loop detecion, Encrypted SIP, and SIP
  Flooding.  The test topologies that can be used are described in
  the Test Setup section.  Topologies are provided for benchmarking
  of a DUT or SUT.  Benchmarking with Associated Media can be
  performed when using a SUT.</t>

<t>SIP permits a wide range of configuration options that are also
  explained in the Test Setup section.  Benchmark metrics could
  possibly be impacted by Associated Media. The selected values for
  Session Duration and Media Streams Per Session enable benchmark
  metrics to be benchmarked without Associated Media.  Session Setup
  Rate could possibly be impacted by the selected value for Maximum
  Sessions Attempted.  The benchmark for Session Establishment Rate is
  measured with a fixed value for maximum Session Attempts.</t>

</section> <!-- Introduction -->

<section title="Test Topologies" anchor="test-topologies">

 <t> Figures 1 through 5 below provide various topologies to perform
 the SIP Performance Benchmarking.  These figures show the Device
 Under Test (DUT) to be a single server or a System Under Test (SUT).
 Test Topology options to include benchmarking with Associated Media
 require use of a SUT and are shown in Figures 4 and 5.</t>

 <figure anchor = "figure 1"
         title = "Basic SIP Test Topology">
 <artwork><![CDATA[
          DUT
        ---------               ---------
        |       |               |       |
        |       |               |       |
        |       |      SIP      |       |
        |Server |<------------->| Tester|
        |       |               |       |
        |       |               |       |
        |       |               |       |
        ---------               ---------
 ]]></artwork></figure>

 <figure anchor= "figure 2"
         title="SIP Test Topology with Firewall">

 <artwork><![CDATA[
                  SUT
        ------------------------
        ---------      ---------         ---------
        |       |      |       |         |       |
        |       |      |       |         |       |
        |       |  SIP |Fire-  |   SIP   |       |
        | Server|<---------------------->| Tester|
        |       |      |Wall   |         |       |
        |       |      |       |         |       |
        |       |      |       |         |       |
        ---------      ---------         ---------

 ]]></artwork></figure>

 <figure anchor= "figure 3"
         title="SIP Test Topology with NAT Device">

 <artwork><![CDATA[
                  SUT
        ------------------------
        ---------      ---------         ---------
        |       |      |       |         |       |
        |       |      |       |         |       |
        |       |  SIP | NAT   |   SIP   |       |
        | Server|<---------------------->| Tester|
        |       |      |       |         |       |
        |       |      |       |         |       |
        |       |      |       |         |       |
        ---------      ---------         ---------


 ]]></artwork></figure>

 <figure anchor= "figure 4"
         title="SIP Test Topology with Media through Firewall">

 <artwork><![CDATA[
                  SUT
        ------------------------
        ---------      ---------         ---------
        |       |      |       |         |       |
        |       |      |       |         |       |
        |       |  SIP |Fire-  |   SIP   |       |
        | Server|<---------------------->| Tester|
        |       |      |Wall   |         |       |
        |       |      |       |  Media  |       |
        |       |   ---|       |---------|       |
        ---------   |  ---------         ---------
                    |             Media      ^
                    -------------------------|

 ]]></artwork></figure>

 <figure anchor= "figure 5"
         title="SIP Test Topology with Media through NAT Device">

 <artwork><![CDATA[
                   SUT
        ------------------------
        ---------      ---------         ---------
        |       |      |       |         |       |
        |       |      |       |         |       |
        |       |  SIP |  NAT  |   SIP   |       |
        | Server|<---------------------->| Tester|
        |       |      |       |         |       |
        |       |      |       |  Media  |       |
        |       |   ---|       |---------|       |
        ---------   |  ---------         ---------
                    |             Media      ^
                    -------------------------|


 ]]></artwork></figure>

</section> <!-- Test Setup -->

<section title="Test Considerations" anchor="test-considerations">

<section title="Selection of SIP Transport Protocol"
         anchor="SIP Trans-Pro selection">
 <t>
 <list style="hanging">
  <t hangText="Discussion:"></t>
   <t>Test cases may be performed with any transport protocol supported
   by SIP.  This includes, but is not limited to, SIP TCP, SIP UDP,
   and TLS.  The protocol used for the SIP transport protocol must
   be reported with benchmarking results.</t>
  <t></t>
 </list>
 </t>
</section>

<section title="Server" anchor="Server">
 <t>
 <list style="hanging">
  <t hangText="Discussion:"></t>
   <t>The Server is a SIP-speaking device that complies with RFC 3261.
   The purpose of this document is to benchmark SIP performance, not
   conformance.  Conformance to <xref target="RFC3261"/> is
   assumed for all tests.  The Server may be the DUT or a component
   of a SUT that includes Firewall and/or NAT functionality. The
   components of the SUT may be a single physical device or
   separate devices.</t>
  <t></t>
 </list>
 </t>
</section>

<section title="Associated Media" anchor="associated-media">
 <t>
 <list style="hanging">
  <t hangText="Discussion:"></t>
   <t>Some tests may require associated media to be present for each SIP
   session.  The Server is not involved in the forwarding of media.
   Associated Media can be benchmarked only with a SUT in which the
   media traverses a Firewall, NAT, or Firewall NAT device.  The
   test topologies to be used when benchmarking SUT performance
   for Associated Media are shown in Figures 4 and 5, in which the SIP
   signaling is bidirectional and the Associated Media is unidirectional.</t>
 </list>
 </t>
</section>

<section title="Selection of Associated Media Protocol"
 anchor="associated-media pro selection">
 <t>
 <list style="hanging">
  <t hangText="Discussion:"></t>
   <t>The test cases specified in this document provide SIP performance
   independent of the protocol used for the media stream.  Any media
   protocol supported by SIP may be used.  This includes, but is not
   limited to, RTP, RTSP, and SRTP.  The protocol used for
   Associated Media must be reported with benchmarking results. </t>
 </list>
 </t>
</section>

<section title="Number of Associated Media Streams per SIP Session"
          anchor="assoc-media stream number per SIP session">
 <t>
 <list style="hanging">
  <t hangText="Discussion:"></t>
   <t>Benchmarking results may vary with the number of media
   streams per SIP session.  When benchmarking a SUT for voice, a
   single media stream is used.  When benchmarking a SUT for voice
   and video, two media streams are used.  The number of Associated
   Media Streams must be reported with benchmarking results. </t>
 </list>
 </t>
</section>

<section title="Session Duration" anchor="session-duration">
 <t>
 <list style="hanging">
  <t hangText="Discussion:"></t>
   <t>SUT performance benchmarks may vary with the duration
   of SIP sessions. Session Duration must be reported with
   benchmarking results.  A Session Duration of zero seconds
   indicates transmission of a BYE immediately following successful
   SIP establishment indicate by receipt of a 200 OK.  An infinite
   Session Duration indicates that a BYE is never transmitted.</t>
 </list>
 </t>
</section>

<section title="Attempted Sessions per Second"
         anchor="sessions attempted per second">
 <t>
 <list style="hanging">
  <t hangText="Discussion:"></t>
   <t>DUT and SUT performance benchmarks may vary with the
   the rate of attempted sessions offered by the Tester.  Attempted
   Sessions per Second must be reported with benchmarking results.</t>
 </list>
 </t>
</section>

<section title="Stress Testing" anchor="stress-testing">
 <t>
 <list style="hanging">
  <t hangText="Discussion:"></t>
   <t>The purpose of this document is to benchmark SIP performance, not
   system stability under stressful conditions such as a high rate
   of Attempted Sessions per Second.</t>
 </list>
 </t>
</section>

</section> <!-- test-considerations -->

<section title="Reporting Format" 
         anchor="reporting-format">

<section title="Test setup Report" 
         anchor="test-setup report">
 <t><figure><artwork>
 SIP Transport Protocol = ___________________________ 
 Session Attempt Rate = _____________________________
 IS Media Attempt Rate = ____________________________
 Total Sessions Attempted = _________________________
 Media Streams Per Session =  _______________________
 Associated Media Protocol =  _______________________
 Media Packet Size =  _______________________________ 
 Media Offered Load =  ______________________________ 
 Media Session Hold Time =  _________________________
 Establishment Threshold Time =  ____________________
 Loop Detecting Option =  ___________________________
 Forking Option =  __________________________________
 </artwork></figure></t>

</section> <!-- Test setup report-->

<section title="Device Benchmarks for IS" 
         anchor="device-benchmarks-IS">
 <t><figure><artwork>
 Registration Rate =  _______________________________
 Session Capacity = _________________________________ 
 Session Overload Capacity = ________________________ 
 Session Establishment Rate =  ______________________ 
 Session Establishment Performance =  ______________
 Session Attempt Delay =  ___________________________
 Session Disconnect Delay =  ________________________ 
 </artwork></figure></t>

</section> <!-- device-benchmark-IS -->

<section title="Device Benchmarks for NS" 
         anchor="device-benchmarks-NS">
 <t><figure><artwork>
 IM Rate =  _______________________________
 </artwork></figure></t>

</section> <!-- device-benchmark-NS -->

</section> <!-- reporting-format -->

<section title="Test Cases" 
         anchor="test-cases">

<section title="Session Establisment Rate" anchor="sess-est-rate">
 <t>
 <list style="hanging">
  <t hangText="Objective:"></t>
   <t>To benchmark the Session Establishment Rate
      of the DUT/SUT with zero failures.</t>
 
  <t hangText="Procedure:">
   <list style= "numbers">
    <t>Configure the DUT in the test topology shown in Figure 1 or
     SUT as shown in Figures 2 or 3.</t>
    <t>Configure Tester for SIP UDP with an Session Attempt Rate =
     100 SPS, maximum Session Attempts = 100,000 and Media Streams Per
         Session=0.</t>
    <t>Start Tester to initiate SIP Session establishment with the DUT.</t>
    <t>Measure Session Attempt Failures and total Established Sessions at
     the Tester.</t>
    <t>If a Session Attempt Failure is recorded then reduce the Session
         Attempt Rate configured on the Tester by 50%.</t>
    <t>If no Session Attempt Failure is recorded then increase the
     Session Attempt Rate configured on the Tester by 50%.</t>
    <t>Repeat steps 3 through 6 until the Session Establishment
     Rate is obtained and recorded.</t>
  </list> </t>
 <t hangText="Expected Results:"> </t>
 </list>
 </t>
</section> <!-- Session Establishment Rate -->

<section title="Session Establishment Rate with Media" 
         anchor="session-attempt rate with media">
 <t>
 <list style="hanging">
  <t hangText="Objective:"></t>
   <t>To benchmark the Session Establishment Rate of the SUT with
    zero failures when Associated Media is included in the benchmark test.</t>
 
  <t hangText="Procedure:">
  <list style= "numbers">
   <t>Configure the SUT in the test topology shown in Figure 4 or 5.</t>
   <t>Configure Tester for SIP UDP with an Session Attempt Rate = 100 SPS,
    maximum Session Attempts = 100,000 and Media Streams Per Session = 1.
        The rate of offered load for each media stream SHOULD be (eq 1)
        Offered Load per Media Stream = Throughput / maximum sessions
        attempted, where Throughput is defined in <xref target="RFC2544"/>.</t>
   <t>Start Tester to initiate SIP Session establishment with the
    SUT and transmit media through the SUT to a destination other
    than the server.</t>
   <t>At the Tester measure Session Attempt Failures, total Established
    Sessions, and Packet Loss <xref target="RFC2544"/> of the media.</t>
   <t>If a Session Attempt Failure or Packet Loss is recorded then
    reduce the Session Attempt Rate configured on the Tester by 50%.</t>
   <t>If no Session Attempt Failure or Packet Loss is recorded then
    increase the Session Attempt Rate configured on the Tester by 50%.</t>
   <t>Repeat steps 3 through 6 until the Session Establishment Rate is
    obtained and recorded.</t>
   <t>Repeat steps 1 through 7 for multimedia in which Media Streams
    Per Session = 2. </t>
 </list></t>

 <t hangText="Expected Results:"></t>
 <t>Session Establishment Rate results obtained
  with Associated Media with any number of media streams per SIP session
  will be identical to the Session Establishment Rate results obtained without
  media.</t>
 </list>
 </t>

</section> <!-- Session Establishment Rate with media -->

<section title="Session Establishment Rate with Loop Detection Enabled" 
         anchor="ssr-loop detection enabled">
 <t>
 <list style="hanging">
  <t hangText="Objective:"></t>
   <t>To benchmark the Session Establishment Rate of the DUT/SUT with
      zero failures when the Loop Detection option is enabled.</t>

  <t hangText="Procedure:">
  <list style= "numbers">
   <t>Configure the DUT in the test topology shown in Figure 1 or
    SUT as shown in Figures 2 or 3.</t>
   <t>Configure Tester for SIP UDP with an Session Attempt Rate =
    100 SPS, maximum Session Attempts = 100,000 and Media Streams Per
        Session=0.</t>
   <t>Turn on the Loop Detection option in the DUT or SUT.</t>
   <t>Start Tester to initiate SIP Session establishment with the DUT.</t>
   <t>Measure Session Attempt Failures and total Established Sessions at
    the Tester.</t>
   <t>If a Session Attempt Failure is recorded then reduce the
    Session Attempt Rate configured on the Tester by 50%.</t>
   <t>If no Session Attempt Failure is recorded then increase the
    Session Attempt Rate configured on the Tester by 50%.</t>
   <t>Repeat steps 4 through 7 until the Session Establishment Rate is
    obtained and recorded.</t>
   </list></t>

 <t hangText="Expected Results:"> </t>

 </list>
 </t>
</section> <!-- Session Establishment Rate with loop detection enabled -->

<section title="Session Establishment Rate with Forking"
         anchor="ssr-forking">
 <t>
 <list style="hanging">
  <t hangText="Objective:"></t>
  <t>To benchmark the Session Establishment Rate of the DUT/SUT with
      zero failures when the Forking Option is enabled.</t>

  <t hangText="Procedure:">
  <list style= "numbers">
   <t>Configure the DUT in the test topology shown in Figure 1 or
    SUT as shown in Figures 2 or 3.</t>
   <t>Configure Tester for SIP UDP with an Session Attempt Rate =
    100 SPS, maximum Session Attempts = 100,000 and Media Streams Per
        Session=0.</t>
   <t>Turn on the Forking Option in the DUT or SUT.</t>
   <t>Start Tester to initiate SIP Session establishment with the DUT.</t>
   <t>Measure Session Attempt Failures and total Established Sessions at
    the Tester.</t>
   <t>If a Session Attempt Failure is recorded then reduce the
    Session Attempt Rate configured on the Tester by 50%.</t>
   <t>If no Session Attempt Failure is recorded then increase the
    Session Attempt Rate configured on the Tester by 50%.</t>
   <t>Repeat steps 4 through 7 until the Session Establishment Rate
    is obtained and recorded.</t>
  </list></t>

 <t hangText="Expected Results:"> </t>
 </list>
 </t>
</section> <!-- Session Establishment Rate with forking -->

<section title="Session Establishment Rate with Forking and Loop Detection"
         anchor="ssr-forking and loop detection">
 <t>
 <list style="hanging">
  <t hangText="Objective:"></t>
  <t>To benchmark the Session Establishment Rate of the DUT/SUT with zero
   failures when both the Forking and Loop Detection Options are
   enabled.</t>

  <t hangText="Procedure:">
  <list style= "numbers">
   <t>Configure the DUT in the test topology shown in Figure 1 or
    SUT as shown in Figures 2 or 3.</t>
   <t>Configure Tester for SIP UDP with an Session Attempt Rate =
    100 SPS, maximum Session Attempts = 100,000 and Media Streams Per 
    Session=0.</t>
   <t>Start Tester to initiate SIP Session establishment with the DUT.</t>
   <t>Enable both the Forking and Loop Detection Options on the DUT.</t>
   <t>Measure Session Attempt Failures and total Established Sessions at
    the Tester.</t>
   <t>If a Session Attempt Failure is recorded then reduce the
    Session Attempt Rate configured on the Tester by 50%.</t>
   <t>If no Session Attempt Failure is recorded then increase the
    Session Attempt Rate configured on the Tester by 50%.</t>
   <t>Repeat steps 4 through 7 until the Session Establishment
    Rate is obtained and recorded.</t>
  </list></t>

 <t hangText="Expected Results:"> </t>

 </list>
 </t>
</section> <!-- Session Establishment Rate with forking and loop detection-->

<section title="Session Establishment Rate with TLS Encrypted SIP"
         anchor="ssr-with TLS Encrypted SIP">
 <t>
 <list style="hanging">
  <t hangText="Objective:"></t>
  <t>To benchmark the Session Establishment Rate
      of the DUT/SUT with zero failures when using TLS encrypted SIP.</t>

  <t hangText="Procedure:">
  <list style= "numbers">
   <t>Configure the DUT in the test topology shown in Figure 1 or
    SUT as shown in Figures 2 or 3.</t>
   <t>Configure Tester for SIP TCP, enable TLS, Session Attempt Rate =
   100 SPS, maximum Session Attempts = 100,000 and Media Streams Per
   Session = 0.</t>
  <t>Start Tester to initiate SIP Session establishment with the DUT.</t>
  <t>Measure Session Attempt Failures and total Established Sessions
     at the Tester.</t>
  <t>If a Session Attempt Failure is recorded then reduce the
   Session Attempt Rate configured on the Tester by 50%.</t>
  <t>If no Session Attempt Failure is recorded then increase the
   Session Attempt Rate configured on the Tester by 50%.</t>
  <t>Repeat steps 3 through 6 until the Session Establishment
   Rate is obtained and recorded.</t>
 </list></t>

 <t hangText="Expected Results:"> </t>
 </list>
 </t>
</section> <!-- Session Establishment Rate with TLS Encrypted SIP -->

<section title="Session Establishment Rate with IPsec Encrypted SIP"
         anchor="ssr-with IPsec Encrypted SIP">
 <t>
 <list style="hanging">
  <t hangText="Objective:"></t>
   <t>To benchmark the Session Establishment Rate
      of the DUT/SUT with zero failures when using IPsec Encryoted SIP.</t>

  <t hangText="Procedure:">
  <list style= "numbers">
   <t>Configure the DUT in the test topology shown in Figure 1 or
    SUT as shown in Figures 2 or 3.</t>
   <t>Configure Tester for SIP TCP, enable IPSec, Session Attempt Rate =
   100 SPS, maximum Session Attempts = 100,000 and Media Streams Per
   Session = 0.</t>
  <t>Start Tester to initiate SIP Session establishment with the DUT.</t>
  <t>Measure Session Attempt Failures and total Established Sessions at
   the Tester.</t>
  <t>If a Session Attempt Failure is recorded then reduce the
   Session Attempt Rate configured on the Tester by 50%.</t>
  <t>If no Session Attempt Failure is recorded then increase the
   Session Attempt Rate configured on the Tester by 50%.</t>
  <t>Repeat steps 3 through 6 until the Session Establishment
   Rate is obtained and recorded.</t>
  </list></t>

 <t hangText="Expected Results:"> </t>
 </list>
 </t>
</section> <!-- Session Establishment Rate with IPsec Encrypted SIP -->

<section title="Session Establishment Rate with SIP Flooding"
         anchor="session-setup rate with SIP Flooding">
 <t>
 <list style="hanging">
  <t hangText="Objective:"></t>
   <t>To benchmark the Session Establishment Rate
      of the SUT with zero failures when SIP Flooding is occurring.</t>

  <t hangText="Procedure:">
  <list style= "numbers">
   <t>Configure the DUT in the test topology shown in Figure 1 or
    the SUT as shown in Figure 2.</t>
   <t>Configure Tester for SIP UDP with an Session Attempt Rate =
    100 SPS, maximum Session Attempts = 100,000, Associated Media Streams
        Per Session = 0, and SIP INVITE Message Flood = 500 per second. </t>
   <t>Start Tester to initiate SIP Session establishment with the
    SUT and SIP Flood targetted at the Server.</t>
   <t>At the Tester measure Session Attempt Failures, total Established
    Sessions, and Packet Loss <xref target="RFC2544"/> of the media.</t>
   <t>If a Session Attempt Failure or Packet Loss is recorded then
    reduce the Session Attempt Rate configured on the Tester by 50%.</t>
   <t>If no Session Attempt Failure or Packet Loss is recorded then
    increase the Session Attempt Rate configured on the Tester by 50%.</t>
   <t>Repeat steps 3 through 6 until the Session Establishment Rate is
    obtained and recorded.</t>
   <t> Repeat steps 1 through 7 with SIP INVITE Message Flood =
    1000 per second.</t>
   </list></t>

 <t hangText="Expected Results:">Session Establishment Rate results obtained
    with SIP Flooding may be degraded.</t>
 </list>
 </t>
</section> <!-- Session Establishment Rate with SIP Flooding -->

<section title="Maximum Registration Rate" 
         anchor="registration-rate">
 <t>
 <list style="hanging">
  <t hangText="Objective:"></t>
   <t>To benchmark the maximum registration rate of the SUT with
      zero failures.</t>

  <t hangText="Procedure:">
  <list style= "numbers">
   <t>Configure the DUT in the test topology shown in Figure 1 or
    SUT as shown in Figures 2 or 3.</t>
   <t>Configure Tester for SIP UDP with an attempted Registration Rate =
    100 SPS and maximum registrations attempted = 100,000. </t>
   <t>At the Tester measure failed registration attempts, total registrations
    and packet loss.</t>
   <t>If a Failed Registration Attempt or Packet Loss is recorded then
    reduce the Attempted Registration Rate configured on the Tester by 50%.</t>
   <t>If no Failed Registration or Packet Loss is recorded then
    increase the Attempted Registration Rate configured on the Tester
    by 50%.</t>
   <t>Repeat steps 3 through 6 until the Session Establishment Rate is 
   obtained and recorded.</t>
  </list></t>

 <t hangText="Expected Results:"></t>
 </list>
 </t>
</section> <!-- Maximum Registration Rate -->

<section title="Maximum IM Rate" anchor="IM-rate">
 <t>
 <list style="hanging">
  <t hangText="Objective:"></t>
   <t>To benchmark the maximum IM rate of the SUT with
      zero failures.</t>

  <t hangText="Procedure:">
  <list style= "numbers">
   <t>Configure the DUT in the test topology shown in Figure 1 or
    SUT as shown in Figures 2 or 3.</t>
   <t>Configure Tester for SIP UDP with an Attempted IM Rate = 100 SPS,
      Maximum IM Attempted = 100,000. </t>
   <t>At the Tester measure Failed IM Attempts, Total IM and Packet Loss.</t>
   <t>If a Failed IM Attempt or Packet Loss is recorded then reduce the
    Attempted IM Rate configured on the Tester by 50%.</t>
   <t>If no Failed IM or Packet Loss is recorded then increase the Attempted
    IM Rate configured on the Tester by 50%.</t>
   <t>Repeat steps 3 through 6 until the Session Establishment Rate is 
   obtained and recorded.</t>
  </list></t>

  <t hangText="Expected Results:"></t>
 </list>
 </t>
</section> <!-- Maximum IM Rate -->

<section title="Session Capacity" anchor="max-sess-cao">
 <t>
 <list style="hanging">
  <t hangText="Objective:"></t>
   <t>To benchmark the Session Capacity of the SUT
      with Associated Media.</t>

  <t hangText="Procedure:">
  <list style= "numbers">
   <t>Configure the DUT in the test topology shown in Figure 1 or
    SUT as shown in Figures 2 or 3.</t>
   <t>Configure Tester for SIP UDP with an Session Attempt Rate =
    Session Establishment Rate,
    maximum Session Attempts = 10,000 and Media Streams Per Session = 0.</t>
   <t>Start Tester to initiate SIP Session establishment with the DUT.</t>
   <t>Measure Session Attempt Failures, total Established Sessions,
    and Packet Loss <xref target="RFC2544"/> at the Tester.</t>
   <t>If a Session Attempt Failure or Packet Loss is recorded then
    reduce the maximum Session Attempts configured on the Tester by
    5,000.</t>
   <t>If no Session Attempt Failure or Packet Loss is recorded then
    increase the maximum Session Attempts configured on the Tester by
    10,000.</t>
   <t>Repeat steps 3 through 6 until the Session Capacity is obtained and 
   recorded.</t>
   <t> Repeat steps 1 through 7 for multimedia in which media streams per
    session = 2. </t>
  </list></t>

 <t hangText="Expected Results:"> </t>

 </list>
 </t>
</section> <!-- Session Capacity  -->

<section title="Session Capacity with Media" 
         anchor="session-cao-w-media">
 <t>
 <list style="hanging">
  <t hangText="Objective:"></t>
   <t>To benchmark the Session Establishment Rate of the
    DUT/SUT with Associated Media.</t>

  <t hangText="Procedure:">
  <list style= "numbers">
   <t>Configure the DUT in the test topology shown in Figure 1 or
    SUT as shown in Figures 2 or 3.</t>
   <t>Configure Tester for SIP UDP with a Session Attempt Rate =
    100 SPS, Session Duration = 30 sec, maximum Session Attempts
    = 100,000 and Media Streams Per Session = 1.  The rate of offered load
    for each media stream SHOULD be (eq 1) Offered Load per Media Stream =
    Throughput / maximum Session Attempts, where Throughput is defined
    in <xref target="RFC2544"/>.</t>
   <t>Start Tester to initiate SIP Session establishment with the
    SUT and transmit media through the SUT to a destination other
    than the server.</t>
   <t>Measure Session Attempt Failures and total Established Sessions
    at the Tester.</t>
   <t>If a Session Attempt Failure is recorded then reduce the
    maximum Session Attempts configured on the Tester by 5,000.</t>
   <t>If no Session Attempt Failure is recorded then increase the
    maximum Session Attempts configured on the Tester by 10,000.</t>
   <t>Repeat steps 3 through 6 until the Session Capacity is obtained 
   and recorded.</t>
  </list></t>

 <t hangText="Expected Results:">Session establishment rate results obtained
  with Associated Media with any number of media streams per SIP session
  will be identical to the Session Capacity results obtained without media.</t>
 </list>
 </t>
</section> <!-- max session est rate with media -->

</section> <!-- test-cases -->

<section title="IANA Considerations" anchor="iana">

 <t>This document does not requires any IANA considerations.</t>

</section>

<section title="Security Considerations" anchor="security">

 <t>Documents of this type do not directly affect the security of Internet
   or corporate networks as long as benchmarking is not performed on
   devices or systems connected to production networks.  Security threats
   and how to counter these in SIP and the media layer is discussed
   in RFC3261, RFC3550, and RFC3711 and various other drafts.  This document
   attempts to formalize a set of common methodology for benchmarking
   performance of SIP devices in a lab environment.</t>
</section>

<section title="Acknowledgments" anchor="acks">

 <t>The authors would like to thank Keith Drage and Daryl Malas for their
 contributions to this document.</t>

</section>


</middle> 

<back>

 <references title="Normative References">
   &rfc2119;
   &rfc2544;
   <reference anchor="I-D.sip-bench-term">
    <front>
     <title>SIP Performance Benchmarking Terminology</title>
     <author initials="S." surname="Poretsky"><organization/></author>
     <author initials="V." surname="Gurbani"><organization/></author>
     <author initials="C." surname="Davids"><organization/></author>
     <date month="March" year="2009"/>
    </front>
    <seriesInfo name="Internet-Draft" 
                value="draft-ietf-bmwg-sip-bench-term-00"/>
    <format type="TXT"
            target="http://www1.tools.ietf.org/html/draft-ietf-bmwg-sip-bench-term-00.txt"/>
   </reference>

 </references>

<references title="Informative References">
   &rfc3261;
</references>

</back>

</rfc>

<?xml version="1.0" encoding="US-ASCII"?>
<!-- This template is for creating an Internet Draft using xml2rfc,
     which is available here: http://xml.resource.org. -->
<!DOCTYPE rfc SYSTEM "rfc2629.dtd" [
<!ENTITY RFC1122 PUBLIC "" "http://xml.resource.org/public/rfc/bibxml/reference.RFC.1122.xml">
<!ENTITY RFC2775 PUBLIC "" "http://xml.resource.org/public/rfc/bibxml/reference.RFC.2775.xml">
<!ENTITY RFC3261 PUBLIC "" "http://xml.resource.org/public/rfc/bibxml/reference.RFC.3261.xml">
<!ENTITY RFC3724 PUBLIC "" "http://xml.resource.org/public/rfc/bibxml/reference.RFC.3724.xml">
<!ENTITY RFC4033 PUBLIC "" "http://xml.resource.org/public/rfc/bibxml/reference.RFC.4033.xml">
<!ENTITY RFC4084 PUBLIC "" "http://xml.resource.org/public/rfc/bibxml/reference.RFC.4084.xml">
<!ENTITY RFC4301 PUBLIC "" "http://xml.resource.org/public/rfc/bibxml/reference.RFC.4301.xml">
<!ENTITY RFC4924 PUBLIC "" "http://xml.resource.org/public/rfc/bibxml/reference.RFC.4924.xml">
<!ENTITY RFC5246 PUBLIC "" "http://xml.resource.org/public/rfc/bibxml/reference.RFC.5246.xml">
<!ENTITY RFC5782 PUBLIC "" "http://xml.resource.org/public/rfc/bibxml/reference.RFC.5782.xml">
<!ENTITY RFC6480 PUBLIC "" "http://xml.resource.org/public/rfc/bibxml/reference.RFC.6480.xml">
]>
<?xml-stylesheet type='text/xsl' href='rfc2629.xslt' ?>
<!-- used by XSLT processors -->
<!-- For a complete list and description of processing instructions (PIs), 
     please see http://xml.resource.org/authoring/README.html. -->
<!-- Below are generally applicable Processing Instructions (PIs) that most I-Ds might want to use.
     (Here they are set differently than their defaults in xml2rfc v1.32) -->
<?rfc strict="yes" ?>
<!-- give errors regarding ID-nits and DTD validation -->
<!-- control the table of contents (ToC) -->
<?rfc toc="yes"?>
<!-- generate a ToC -->
<?rfc tocdepth="4"?>
<!-- the number of levels of subsections in ToC. default: 3 -->
<!-- control references -->
<?rfc symrefs="yes"?>
<!-- use symbolic references tags, i.e, [RFC2119] instead of [1] -->
<?rfc sortrefs="yes" ?>
<!-- sort the reference entries alphabetically -->
<!-- control vertical white space 
     (using these PIs as follows is recommended by the RFC Editor) -->
<?rfc compact="yes" ?>
<!-- do not start each main section on a new page -->
<?rfc subcompact="no" ?>
<!-- keep one blank line between list items -->
<!-- end of list of popular I-D processing instructions -->
<rfc category="info" docName="draft-iab-filtering-considerations-02.txt"
     ipr="trust200902">
  <!-- category values: std, bcp, info, exp, and historic
     ipr values: full3667, noModification3667, noDerivatives3667
     you can add the attributes updates="NNNN" and obsoletes="NNNN" 
     they will automatically be output with "(if approved)" -->

  <!-- ***** FRONT MATTER ***** -->

  <front>
    <!-- The abbreviated title is used in the page header - it is only necessary if the 
         full title is longer than 39 characters -->

    <title abbrev="Filtering Considerations">Technical Considerations for
    Internet Service Blocking and Filtering</title>

    <!--add 'role="editor"' below for the editors if appropriate -->

    <!-- Another author who claims to be an editor -->

    <author fullname="Richard Barnes" initials="R." surname="Barnes">
      <organization>BBN Technologies</organization>

      <address>
        <postal>
          <street>1300 N. 17th St</street>

          <!-- Reorder these if your country does things differently -->

          <city>Arlington</city>

          <region>VA</region>

          <code>22209</code>

          <country>USA</country>
        </postal>

        <phone>+1 703 284 1340</phone>

        <email>rbarnes@bbn.com</email>

        <!-- uri and facsimile elements may also be added -->
      </address>
    </author>

    <author fullname="Alissa Cooper" initials="A." surname="Cooper">
      <organization>CDT</organization>

      <address>
        <postal>
          <street>1634 Eye St. NW, Suite 1100</street>

          <city>Washington</city>

          <region>DC</region>

          <code>20006</code>

          <country>USA</country>
        </postal>

        <email>acooper@cdt.org</email>

        <!-- uri and facsimile elements may also be added -->
      </address>
    </author>

    <author fullname="Olaf Kolkman" initials="O." surname="Kolkman">
      <organization>NLnet Labs</organization>
      <address>
	<postal>
	  <street>Science Park 400</street>
	  <city>Amsterdam</city>
	  <code>1422 JB</code> <!-- NB postal code convention is to put the code in front of the city -->
	  <country>Netherlands</country>
	</postal>
        <email>olaf@nlnetlabs.nl</email>
      </address>
    </author>

    <date day="23" month="February" year="2013"/>

    <!-- If the month and year are both specified and are the current ones, xml2rfc will fill 
         in the current day for you. If only the current year is specified, xml2rfc will fill 
	 in the current day and month for you. If the year is not the current one, it is 
	 necessary to specify at least a month (xml2rfc assumes day="1" if not specified for the 
	 purpose of calculating the expiry date).  With drafts it is normally sufficient to 
	 specify just the year. -->

    <!-- Meta-data Declarations -->

    <area>General</area>

    <workgroup>Internet Architecture Board</workgroup>

    <!-- WG name at the upperleft corner of the doc,
         IETF is fine for individual submissions.  
	 If this element is not present, the default is "Network Working Group",
         which is used by the RFC Editor as a nod to the history of the IETF. -->

    <abstract>
      <t>
	The Internet is structured to be an open communications
	medium. This openness is one of the key underpinnings of
	Internet innovation, but it can also allow communications that
	may be viewed as undesirable by certain parties. Thus, as the
	Internet has grown, so have mechanisms to limit the extent and
	impact of abusive or allegedly illegal
	communications. Recently, there has been an increasing
	emphasis on "blocking" and "filtering," the active prevention
	of such communications. 
	This document
	examines several technical approaches to Internet content
	blocking and filtering in terms of their alignment with the
	overall Internet architecture. In general, the approach to
	content blocking and filtering that is most coherent with the
	Internet architecture is to inform endpoints about potentially
	undesirable services, so that the communicants can avoid
	engaging in abusive or illegal communications.
      </t>
    </abstract>
  </front>

  <middle>
    <section title="Introduction">
      <t>
	The original design goal of the Internet was to enable
	communications between hosts. As this goal was met and people
	started using the Internet to communicate, however, it became
	apparent that some hosts were engaging in arguably undesirable
	communications. The most famous early example of undesirable
	communications was the Morris worm <xref target="Morris" />, which used the Internet to
	infect many hosts in 1988. As the Internet has evolved into a
	rich communications medium, so too have mechanisms to restrict
	undesirable communications.
	<!-- Danny suggested to include a reference for the Morris Worm 
	I cannog find one.-->
      </t>

      <t>
	Efforts to restrict or deny access to Internet resources have
	evolved over time. As noted in <xref target="RFC4084"/>, some
	Internet service providers impose restrictions on which
	applications their customers may use and which traffic they
	allow on their networks. These restrictions are often imposed
	with customer consent, where customers may be enterprises or
	individuals. Increasingly, however, both governmental and
	private sector entities are seeking to block or filter
	access to certain content, traffic, or communications without
	the knowledge or agreement of affected users. Where these
	entities do not directly control networks themselves, they
	commonly aim to make use of intermediary systems to effectuate
	the blocking or filtering.
      </t>

      <t>
	Entities may seek to block or filter Internet content for a
	diversity of reasons, including defending against security
	threats, restricting access to content thought to be
	objectionable, and preventing nefarious or illegal
	activity. While blocking and filtering remain highly
	contentious in many cases, the desire to restrict access to
	content will likely continue to exist.
      </t>
      
      <t>
	The difference between "blocking" and "filtering" is a
	matter of scale and perspective. "Blocking" often refers to preventing access to resources in the aggregate, while "filtering" refers to preventing access to specific resources within an aggregate. Both blocking and filtering can be effectuated at the level of "services" (web hosting or video streaming, for example) or at the level of particular "content." For the analysis presented in this document, the distinction between blocking and filtering does not create meaningfully different conclusions. Hence,
	in the remainder of this document, we will treat the terms as
	being generally equivalent.
      </t>

      <t>
	This document aims to clarify the technical implications and
	trade-offs of various blocking strategies and to identify the
	potential for different strategies to come into conflict with
	the Internet's architecture, or potentially cause harmful side effects
	("collateral damage"). Blocking is principally taken up (whether voluntarily or not) by three types of entities:
      </t>
      
      <t><list style="numbers">
	<t>
	  Operators of networks (including enterprises)
	</t>
	<t>
	  Operators of infrastructure services (for naming, routing, and other core Internet functions)
	</t>
	
	<t>
	  Operators of endpoints (including end users and application providers)
	</t>
      </list>
      Examples of blocking or attempted blocking using the DNS, HTTP
      proxies, spam filters, and RPKI
      manipulation are used to illustrate each category's properties.
      </t>


      
      <t>
	Filtering may be considered legal, illegal, ethical, or unethical in different places, at different times, and by different parties.  This document is intended for an audience of entities that are filtering or are considering filtering and who want to understand the implications of their decisions with respect to the Internet architecture and the trade-offs that come with each type of filtering strategy.  This document does not present formulas on how to
	make those trade-offs; it is likely that filtering decisions require knowledge of context-specific details.  Whether particular forms of filtering are
	lawful in particular jurisdictions raises complicated legal
	questions that are outside the scope of this document. For
	similar reasons questions about the ethics of particular forms of filtering are also out of scope. 
      </t>

      <t>
	In <xref target="SAC-056"/>, ICANN's Security and Stability
	Advisory Committee (SSAC) assessed the aspects of blocking using the
	DNS. This document attempts to take a broader perspective on blocking
	and filtering and genaralizes from some of SSAC's findings.
      </t>
      
    </section>
    
    <section title="Architectural Principles">
      <t>
	To understand the implications of different blocking
	strategies, it is important to understand the key principles
	that have informed the design of the Internet. While much of
	this ground has been well trod before, this section highlights
	four architectural principles that have a direct impact on the
	viability of content blocking: end-to-end connectivity and
	"transparency," layering, distribution and mobility, and
	locality and autonomy.
      </t>
      
      <section title="End-to-End Connectivity and &quot;Transparency&quot;">
        <t>
	  The end-to-end principle is "the core architectural
	  guideline of the Internet" <xref
	  target="RFC3724"/>. Adherence to the principle of vesting
	  endpoints with the functionality to accomplish end-to-end
	  tasks results in a "transparent" network in which packets
	  are not filtered or transformed en route <xref
	  target="RFC2775"/>. This transparency in turn is a key
	  requirement for providing end-to-end security features on
	  the network. Modern security mechanisms that rely on trusted
	  hosts communicating via a secure channel without
	  intermediary interference enable the network to support
	  e-commerce, confidential communication, and an array of
	  other similar uses.
	</t>

        <t>
	  The end-to-end principle is fundamental for Internet
	  security, and the foundation on which Internet security
	  protocols are built.  Protocols such as TLS and IPsec <xref
	  target="RFC5246"/><xref target="RFC4301"/> are designed to
	  ensure that each endpoint of the communication knows the
	  identity of the other endpoint, and that only the endpoints
	  of the communication can access the secured contents of the
	  communication. For example, when a user connects to a bank's
	  web site, TLS ensures that the user's banking information is
	  securely communicated to the bank and nobody else, ensuring
	  the data remains confidential while in transit.
	</t>
	
        <t>
	  Some blocking strategies require intermediaries to insert
	  themselves within the end-to-end communications path (network-based web filtering systems, for example),
	  potentially breaking security properties of Internet
	  protocols. In these cases it can be difficult or impossible
	  for endpoints to distinguish between attackers and
	  "authorized" entities conducting blocking.
	</t>
	
	<!--  This seems to confuse some readers.
        <t>
	  A similar notion to the end-to-end principle is the notion
	  of "transparency," that is, the idea that the network should
	  provide a generic connectivity service between endpoints,
	  with minimal interaction by intermediaries aside from
	  forwarding packets from source to destination. In
	  "Reflections on Internet Transparency" <xref
	  target="RFC4924"/>, the IAB assessed the relevance of this
	  principle and concluded that "far from having lessened in
	  relevance, technical implications of intentionally or
	  inadvertently impeding network transparency play a critical
	  role in the Internet's ability to support innovation and
	  global communication."
	</t>
	-->
	
      </section>
      
      <section title="Layering">
	<t>
	  "Different Players on Different Layers."
	</t>
        <t>
	  Internet applications are built out of a collection of
	  loosely-coupled components or "layers." Different layers
	  serve different purposes, and rely on or offer different
	  functions such as routing, transport, and naming (see <xref
	  target="RFC1122"/>, especially Section 1.1.3). The functions
	  at these layers are developed autonomously and almost always
	  operated by different entities. For example, in many
	  networks, physical and link-layer connectivity is provided
	  by an "access provider", IP routing is performed by an
	  "Internet service provider," and application-layer
	  services are provided by completely separate entities (e.g.,
	  web servers). Upper-layer protocols and applications rely
	  on combinations of lower-layer functions in order to
	  work. As a consequence of the end-to-end principle,
	  functionality at higher layers tends to be more specialized,
	  so that many different specialized applications can make use
	  of the same generic underlying network functions.
	</t>

        <t>
	  As a result of this structure, actions taken at one layer
	  can affect functionality or applications at higher
	  layers. For example, manipulating routing or naming
	  functions to restrict access to a narrow set of resources
	  via specific applications will likely affect all
	  applications that depend on those functions.
	</t>
	
      </section>
      
      <section title="Distribution and Mobility">
        <t>
	  The Internet is designed as a distributed system both
	  geographically and topologically. Resources can be made
	  globally accessible regardless of their physical location or
	  connectivity providers used. Resources are also commonly
	  highly mobile -- moving content from one physical or logical
	  address to another can often be easily accomplished.
	</t>
	
        <t>
	  This distribution and mobility underlies a large part of the
	  resiliency of the Internet. Internet routing can survive
	  major outages such as cuts in undersea fibers because the
	  distributed routing system of the Internet allows individual
	  networks to collaborate to route traffic and for alternative
	  paths to reach a given destination to be rapidly
	  computed. Application services are commonly protected using
	  distributed servers. <!-- For example, even though the 2010
	  earthquake in Haiti destroyed almost all of the Internet
	  infrastructure in the country, the Haitian top-level domain
	  name (.ht) had no interruption in service because it was
	  also accessible via servers in the United States, Canada,
	  and France. -->
	</t>
	
        <t>
	  Undesirable communications also benefit from this resiliency
	  -- resources that are blocked or restricted in one part of
	  the Internet can be reconstituted in another part of the
	  Internet (see, for example, <xref target="Malicious-Resolution" />). If a web site is prevented from using a domain
	  name or set of IP addresses, the web site can simply move to
	  another domain name or network.
	</t>
	
	  <t>
	    The distributed and mobile nature of
	    Internet resources limits the effectiveness of blocking
	    actions. Because an Internet service can be reached from
	    anywhere on the Internet, a service that is blocked in one
	    jurisdiction can often be moved or re-instantiated in
	    another jurisdiction. Likewise, services that rely on
	    blocked resources can often be rapidly re-configured to
	    use non-blocked resources. For example, in a process known
	    as "snowshoe spamming," a spam originator uses addresses
	    in many different networks as sources for spam. This
	    technique is already widely used to spread spam generation
	    across a variety of resources and jursidictions to prevent
	    spam blocking from being effective. Alternatively, users may
	    choose to use different sets of protocols to establish
	    desired service. If voice communication based on SIP <xref target="RFC3261" /> is
	    blocked, users are likely to use propriety protocols that
	    allow them to talk to each other. Thus distribution and mobility can hamper efforts to block communications in a number of ways.
	  </t>
	
      </section>

      <section title="Locality and Autonomy">
        <t>
	  The basic unit of Internet routing is an "Autonomous System"
	  -- a network that manages its own routing internally. The
	  concept of autonomy is present in many aspects of the
	  Internet, as is the related concept of locality, the idea
	  that local changes should not have a broader impact on the
	  network (where "local" may be denote a particular service provider or a particular geography).
	</t>

        <t>
	  These concepts are critical to the stability, scalability,
	  and ability to innovate of the Internet. With millions of
	  individual actors engineering different parts of the
	  network, there would be chaos if every change had impact
	  across the entire Internet.
	</t>

        <t>
	  Locality implies that the impact of technical changes made
	  to realize blocking will only be within a defined scope. For example, changes to an access network
	  will only affect a relatively small, well-defined set of
	  users (namely, those connected to the access network), but
	  can affect all applications for those users. Changes to a
	  particular application service can affect users across the entire
	  Internet, but only for that specific application. Thus the scope of the impact might be narrow in one dimension
	  (set of users or set of applications affected) but broad in
	  another. In some cases, applications and/or infrastructure services are so intertwined with each other that filtering a single service or in a single location can have broad effects in multiple directions.</t>  
	
	<t>Changes made to effectuate blocking are often
	  targeted at a particular locality, but result in blocking
	  outside of the intended scope. For example, web filtering
	  systems in India and China have been shown to cause
	  "collateral damage" by blocking users in Oman and the US
	  from accessing web sites in Germany and Korea <xref
	  target="IN-OM-filtering"/><xref
	  target="CCS-GFC-collateral-damage"/>.
	</t>
      </section>
    </section>
    
    <section title="Examples of Blocking">
      <t>
	As noted above, systems to restrict or block Internet
	communications have evolved alongside the Internet
	technologies they seek to restrict.  Looking back at the
	history of the Internet, there have been several such systems
	deployed, with varying degrees of effectiveness.
      </t>
      
      <t><list style="symbols">
          <t>
	    Firewalls: Firewalls are a very common form of service
	    blocking, employed at many points in today's
	    Internet. Typically, firewalls block according to
	    content-neutral rules, e.g., blocking all inbound
	    connections or outbound connections on certain ports,
	    protocols and network layer addresses. More advanced
	    configurations perform deep packet inspection or traffic
	    flow analysis and filter or block based on rich (content-specific) rules and policies. Many firewalls include web filtering capabilities (see below). Firewalls can be deployed
	    either on end hosts (under user control), or at network
	    boundaries.
	  </t>
	  
          <t>
	    Web Filtering: HTTP and HTTPS are common targets for
	    blocking and filtering, typically targeted at specific
	    URLs. Some enterprises use HTTP blocking to block
	    non-work-appropriate web sites, and several nations
	    require HTTP and HTTPS filtering by their ISPs in order to
	    block content deemed illegal. HTTPS is a challenge for these
	    systems, because the URL in an HTTPS request is carried
	    inside the secure (encrypted) channel. To block access to content made
	    accessible via HTTPS, filtering systems thus must either
	    block based only on IP address, or else obtain a trust
	    anchor certificate that is trusted by endpoints (and thus
	    act as a man in the middle). These filtering systems often
	    take the form of "portals" or "enterprise proxies."  These
	    portals present their own HTTPS certificates that are
	    invalid for any given domain according to normal
	    validation rules, but may still be trusted if the user
	    installs a security exception. (See further discussion in <xref target="security" />.)
	  </t>
	  
          <t>
	    Spam Filtering: Spam filtering is one of the oldest forms
	    of service blocking, in the sense that it denies spammers
	    access to recipients' mailboxes. Spam filters evaluate
	    messages based on a variety of criteria and information
	    sources to decide whether a given message is spam. For
	    example, DNS Reverse Black Lists use the reverse DNS to
	    flag whether an IP address is a known spam source <xref
	    target="RFC5782"/>. Spam filters are typically either
	    installed on user devices (e.g., in a mail client) or
	    operated by a mail domain on behalf of users.
	  </t>
	  
          <t>
	    Domain name seizure: In recent years, US law enforcement
	    authorities have been issuing legal orders to domain name
	    registries to seize domain names associated with the
	    distribution of counterfeit goods and other allegedly
	    illegal activity <xref target="US-ICE"/>. When domain
	    names are seized, DNS queries for the seized names are
	    typically redirected to resolve to U.S. government IP
	    addresses that host information about the seizure. The
	    effectiveness of domain seizures is limited by the
	    mobility principle, since the application using the seized
	    name can simply use another name. Seizures can come into
	    conflict with the locality principle, since content is
	    blocked not only within the jurisdiction of the seizure,
	    but globally, even when it may be affirmatively legal
	    elsewhere <xref target="RojaDirecta"/>. When domain
	    redirection is effected via redirections at intermediate
	    resolvers rather than at authoritative servers, it
	    directly contradicts end-to-end assumptions in the DNS
	    security architecture <xref target="RFC4033"/>, potentially causing
	    validation failures by validating end-nodes.
	  </t>
	  
	  <t>
	    Safe Browsing: Modern web browsers provide some measures
	    to prevent users from accessing malicious web sites. For
	    instance, before loading a URL, current versions of Google
	    Chrome and Firefox web browsers use the Google Safe
	    Browsing service to determine whether or not a given URL
	    is safe to load <xref target="SafeBrowsing"/>. The DNS can
	    also be used to store third party information that mark
	    domains as safe or unsafe <xref target="RFC5782"/>.
	  </t>
	  
          <t>
	    Manipulation of routing and addressing data: Governments
	    have recently intervened in the management of IP
	    addressing and routing information in order to maintain
	    control over a specific set of DNS servers. As part of an
	    internationally coordinated response to the DNSChanger
	    malware, a Dutch court ordered the RIPE NCC to freeze the
	    accounts of several resource holders as a means to limit
	    the resource holders' ability to use certain address
	    blocks <xref target="GhostClickRIPE"/>(also see <xref
	    target="SERVER-BLOCK"/>). These actions have led to
	    concerns that the number resource certification system and
	    related secure routing technologies developed by the IETF
	    SIDR working group might be subject to government
	    manipulation as well <xref target="RFC6480"/>, potentially
	    for the purpose of denying targeted networks access to the
	    Internet.
	  </t>
        </list>
      </t>
    </section>
    
    <section title="Blocking Design Patterns">
      <t>
	Broadly speaking, completing a typical end-to-end Internet communication requires the involvement of three classes of entities, each of which has different means available to it for blocking communications. An end user originates the communication, which may be destined for another end user or application provider on the other end. 	At these endpoints, authentication
		and reputation systems enable devices and their users to make
		decisions about which communications should be blocked.</t>
	
	<t>The endpoints are each connected to a series of networks, the operators of which may also be capable of blocking. Network-based mechanisms usually involve an intermediary device in the network that observes Internet traffic and decides which communications to block.</t>
	
	<t>Finally, most communications depend on common "infrastructure" services (for lack of a better term) that globally support many different kinds of applications. These include the Domain Name System, the routing infrastructure, and their supporting information services such as the WHOIS databases. The operators of these services can alter the information they store in their associated databases or provide to endpoints in order to block communications from occuring.
      </t>
      
      <t>
	In this section, we discuss these three "blocking design
	patterns" and how they align with the Internet architectural
	principles outlined above. In general, endpoint-based blocking
	is the most consistent with the Internet architecture.
      </t>
      
      <section title="Network-Based Blocking">
        <t>
	  Being able to block access to resources without the consent or
	  cooperation of either endpoint to a communication is viewed as a desirable feature by some entities that deploy blocking systems. Systems that have this property are often implemented using intermediary devices in
	  the network, such as firewalls or filtering systems. These
	  systems inspect traffic as it passes through the
	  network, decide based on the characteristics or content of a given
	  communication whether it should be blocked, and then block
	  or allow the communication as desired.
	</t>
	
        <t>
	  Common examples of network-based blocking are
	  firewalls and network-based web-filtering systems. For
	  example, web filtering devices usually inspect HTTP requests
	  to determine the URL being requested, compare that URL to a
	  list of black-listed or white-listed URLs, and allow the
	  request to proceed only if it is permitted by policy (or at
	  least not forbidden). Firewalls perform a similar function
	  for other classes of traffic in addition to HTTP. Some blocking systems focus on specific application-layer traffic, while others filter traffic based on lower layer criteria (transport protocol and source or destination addresses or ports). 	
	</t>
	
	<t>In addition to blocking communications based on their ultimate destination or source, network-based blocking may target discovery, rendezvous or store-and-forward components that are critical to the establishment of an application service but are not operated at either end-point of the
	    communications. For example, to establish
	    an end-to-end SIP call the end-nodes (terminals) will
	    rely on presence and session information supplied by SIP servers. Network operators can block the use of SIP-based services by blocking access to SIP servers. [Q: Does this actually happen?]
	</t>
	
        <t>
	  It should be noted that "intermediary" systems used for blocking are often not
	  far from the edge of the network. For example, many
	  enterprise networks operate firewalls that block certain web
	  sites, as do some residential ISPs. In some cases, this
	  filtering is done with the consent or cooperation of the
	  affected users. PCs within an enterprise, for example, might
	  be configured to trust an enterprise proxy, a residential
	  ISP might offer a "safe browsing" service, or mail clients
	  might authorize mail servers on the local network to filter
	  spam on their behalf. These cases share some of the properties of the "Endpoint-Based Blocking" scenarios discussed in <xref target="End-Point-Blocking" /> below,
	  since the endpoint has made an informed decision to
	  authorize the intermediary to block on its behalf and is therefore unlikely to attempt to circumvent the blocking. From an architectural perspective, however, they may create many of the same problems as network-based filtering conducted without consent. <!--The
	  challenges discussed in this section arise mostly for
	  scenarios where endpoints are not assumed to cooperate with
	  filtering (i.e., they might have incentives to circumvent
	  filtering) or where the endpoints have not made an informed
	  decision (i.e. not understanding the consequences of
	  installing a certificate that allows an intermediary to
	  eavedrop on encrypted traffic).-->
	</t>
	
	<section title="Interaction with Architectural Principles">
	
        <t>
	  Blocking that uses intermediaries in the network conflicts
	  with the end-to-end and transparency principles noted
	  above. The very goal of blocking in this way is to impede
	  transparency for particular content or communications. For
	  this reason, intermediary-based approaches to blocking run
	  into several technical issues that limit their viability in
	  practice. In particular, many issues arise from the fact
	  that an intermediary needs to have access to a sufficient
	  amount of traffic to make its blocking determinations.
	</t>
	
        <t>
	  The first challenge to obtaining this traffic is simply
	  gaining access to the constituent packets. The Internet is
	  designed to deliver packets hop-by-hop from source to destination --
	  not to any particular point along the way. In practice,
	  inter-network routing is often asymmetric, and for
	  sufficiently complex local networks, intra-network traffic
	  flows can be asymmetric as well.
	</t>
	
        <t>
	  This asymmetry means that an intermediary will often see
	  only one half of a given communication (if it sees any of it
	  at all), which may limit its ability to effectively filter. For example, a filter aimed at requests destined for particular URLs cannot make accurate blocking decisions if it is only in the data path for
	  HTTP responses and not requests.  Routing can sometimes be
	  forced to be symmetric within a given network using routing
	  configuration, NAT, or layer-2 mechanisms (e.g., MPLS), but
	  these mechanisms are frequently brittle, complex, and costly
	  -- and often reduce network performance relative to
	  asymmetric routing.
	</t>
	
        <t>
	  Once an intermediary has access to traffic, it must identify
	  which packets must be filtered. This decision is usually
	  based on some combination of information at the network
	  layer (e.g., IP addresses), transport layer (ports), or
	  application layer (URLs or other content). Blocking based on application-layer attributes can be potentially more granular and less likely to cause collateral damage than blocking all traffic associated with a particular address, which can impact unrelated occupants of the same address (in violation of the locality principle.)</t>
	
	</section>
	
	<section title="Circumvention">
	
	 <t> 
		Regardless of the layer at which blocking occurs, it may be open to circumvention, particularly in cases where network endpoints have not authorized the blocking. The communicating endpoints can
	  deny the intermediary access to attributes at any layer by using encryption
	  (see below). IP addresses must be visible, even if
	  packets are protected with IPsec, but blocking based on
	  IP addresses is the simplest form of filtering to
	  circumvent. A filtered site may be able to quickly change its IP address using only a few simple steps: changing a single DNS record and provisioning the new address on its server or moving its services to the new address. Indeed, in the face of IP-based blocking in some
	  networks, services such as The Pirate Bay are now using
	  cloud hosting services so that their IP addresses are
	  difficult for intermediaries to predict <xref
	  target="BT-TPB"/><xref target="TPB-cloud"/>.
	</t>
	
        <t>
	  If application content is encrypted with a security protocol
	  such as IPsec or TLS, then the intermediary will require the
	  ability to decrypt the packets to examine application
	  content. Since security protocols are designed to provide
	  end-to-end security (i.e., to prevent intermediaries from
	  examining content), the intermediary would need to
	  masquerade as one of the endpoints, breaking the
	  authentication in the security protocol, reducing the
	  security of the users and services affected, and interfering
	  with legitimate private communication. Besides, various
	  techniques that use public databases with whitelisted keys
	  (e.g. DANE) enable users to detect these sort of
	  intermediaries. Those users are then likely to act as if the
	  service is blocked.
	</t>
	
        <t>
	  If the intermediary is unable to decrypt the security
	  protocol, then its blocking determinations for secure
	  sessions can only be based on unprotected attributes, such
	  as IP addresses, protocol IDs and port numbers. Some blocking systems
	  today still attempt to block based on these attributes, for
	  example by blocking TLS traffic to known proxies that could
	  be used to tunnel through the blocking system. 
	</t>
	
        <t>
	However, as the Telex project recently demonstrated, if an endpoint cooperates with a relay in the network (e.g., a Telex station), it can create a TLS tunnel that is indistinguishable from legitimate traffic <xref target="Telex"/>.  For example, if an ISP used by a banking website were to operate a Telex station at one of its routers, then a blocking system would be unable to distinguish legitimate encrypted banking traffic from Telex-tunneled traffic (potentially carrying content that would have been filtered).  
	</t>
	
        <t>
	  Thus, in principle it is impossible to block tunneled
	  traffic through an intermediary device without blocking all
	  secure traffic. (The only limitation in practice is the
	  requirement for special software on the client.) In most
	  cases, blocking all secure traffic is an unacceptable
	  consequence of blocking, since security is often required
	  for services such as online commerce, enterprise VPNs, and
	  management of critical infrastructure. If governments or
	  network operators were to force these services to use
	  insecure protocols so as to effectuate blocking, they would
	  expose their users to the various attacks that the security
	  protocols were put in place to prevent.
	</t>
	
        <t>
	  Some operators may assume that only blocking access
	  to resources available via unsecure channels is sufficient
	  for their purposes -- i.e., that the size of the user base
	  that will be willing to use secure tunnels and/or special
	  software to circumvent the blocking is low enough to make
	  blocking via intermediaries worthwhile.  Under that
	  assumption, one might decide that there is no need to
	  control secure traffic, and thus that intermediary-based
	  blocking is an attractive option.
	</t>
	
        <t>
	  However, the longer such blocking systems are in place, the
	  more likely it is that efficient and easy-to-use tunneling
	  tools will become available. The proliferation of the Tor
	  network, for example, and its increasingly sophisticated
	  blocking-avoidance techniques demonstrate that there is
	  energy behind this trend <xref target="Tor"/>. Thus,
	  network-based blocking becomes less effective over
	  time.
	</t> 
	
	<t>
	  Network-based blocking is a key contributor to the arms
	  race that has led to the development of these kinds of
	  tools, the result of which is to create unnecessary layers of
	  complexity in the Internet. Before content-based blocking
	  became common, the next best option for network operators was
	  port blocking, the widespread use of which has driven more
	  applications and services to use ports (80 most commonly)
	  that are unlikely to be blocked. In turn, network operators
	  shifted to finer-grained content blocking over port 80,
	  content providers shifted to encrypted channels, and
	  operators began seeking to identify those
	  channels. Because the premise of network-based blocking
	  is that endpoints have incentives to circumvent it, this
	  cat-and-mouse game is an inevitable by-product of this form
	  of blocking.
	</t>
	
        <t>
	  In sum, blocking via intermediaries within networks is only effective in a
	  fairly constrained set of circumstances. First, the traffic
	  needs to flow through the network in  such a way that the
	  intermediary device has access to any communications it intends to
	  block. Second, the blocking system needs an out-of-band
	  mechanism to mitigate the risk of secure protocols being
	  used to avoid blocking (e.g., human analysts identifying IP
	  addresses of tunnel endpoints), which may be
	  resource-prohibitive, especially if tunnel endpoints begin
	  to change frequently. If the network is sufficiently
	  complex, or the risk of tunneling too high, then
	  network-based blocking is unlikely to be effective, and
	  in any case this type of blocking drives the development of
	  increasingly complex layers of circumvention.
	</t>
      </section>
</section>
      
      <section title="Infrastructure-Based Blocking" anchor="SERVER-BLOCK">
        
	<t>
	  Internet applications often require or rely on support from common, global infrastructure services, including the DNS, certificate authorities, WHOIS
	  databases, and Internet Route Registries. These services
	  control or register the structure and availability of
	  Internet applications by providing data elements that are
	  used by application code.	  
	</t>
	
	  <t>
	    These infrastructure services are comprised of generic technical databases intended to
	    record certain facts about the network. The DNS, for
	    example, stores information about which servers provide
	    services for a given name; the RPKI about which entities
	    have been allocated IP addresses. To offer specialized
	    Internet services and applications, different entities rely
	    on these generic records in different ways. Thus the effects
	    of changes to the databases can be much more difficult to
	    predict than, for example, the effect of shutting down a web
	    server (which fulfills the specific purpose of serving web
	    content).
	  </t>
	
	<!-- Removing example.. seems awkward in the context 
	     <t>
	     
	     By changing an A or AAAA record on a DNS server will
	     change the IP address that is bound to a given domain
	     name; applications trying to communicate with the host at
	     that name will then communicate with the host at the new
	     address.  </t>
	-->
	
	<!--
	<t>
	  One could argue that blocking services by disabling or
	  manipulating servers does respect the end-to-end principle,
	  since the affected server is one end of the blocked
	  communication. However, its interactions with layering,
	  resource mobility, and autonomy can limit its effectiveness
	  and cause undesirable consequences.
	</t>
	
	
        <t>
	  The layered architecture of the Internet means that there
	  are several points at which access to a service can be
	  blocked. The service can be denied Internet access (via
	  control of routers), DNS services (DNS servers), or
	  application-layer services (application servers, e.g., web
	  servers). Blocking via these channels, however, can be both
	  amplified and limited by the global nature of the Internet.
	</t>
	
	<t>
	  This section examines the implications of blocking based at
	  application-specific servers and the servers that are
	  needed to support the global and common infrastructure of
	  the Internet.
	</t>
	
	
	    The "seizure" of domain names discussed above is an
	    example of blocking infrastructure services. 
	  </t>
	-->
	
	<t>As physical objects, the servers that are used to provide infrastructure services exist within the jurisdiction of governments, and their operators are
	   thus subject to jurisdictional laws. It is thus possible for laws to
	   be structured to effectuate blocking by imposing obligations on the operators of infrastructure services within a jurisdiction, either via direct government action or by
	   allowing private actors to demand blocking (e.g., through lawsuits).  
	</t>
	
	<t>
	   Blocking by infrastructure operators is at odds with the locality principle. On the one hand, the global nature of Internet services
	    and resources amplifies blocking actions, in the sense
	    that it increases the risk of overblocking -- collateral
	    damage to legitimate use of a resource. A given address or
	    domain name might host both legitimate services and
	    services that governments desire to block. A service
	    hosted under a domain name and operated in a jurisdiction
	    where it is considered undesirable might be considered
	    legitimate in another jurisdiction; a blocking action in
	    the host jurisdiction would deny legitimate services in
	    the other.
	  </t>
  	  <t>
	    The efficacy of infrastructure-based blocking is further limited
	    by the autonomy principle. If the Internet
	    community realizes that a blocking decision has been made
	    and wishes to counter it, then local networks can "patch"
	    the authoritative data that the infrastructure service provides to avoid the blocking (although the development of DNSSEC and the RPKI are causing this to change by requiring updates to be authorized). In the DNS case, registrants whose names get blocked can relocate their resources to different names.
	  </t>
	  <t>
	    Below we provide a few specific examples for routing, DNS, and WHOIS
	    services.  These examples demonstrate that for
	    these types of infrastructure services (services that are
	    often considered a global commons), jusrisdiction-specific legal and ethical motivations impinge on and are constrained by the principles of locality and autonomy.
	  </t>

	    
	  <t>
	    In 2008, Pakistan Telecom attempted to deny
	    access to YouTube within Pakistan by announcing bogus
	    routes for YouTube address space to peers in
	    Pakistan. YouTube was temporarily denied service on a
	    global basis as a result of a route route leak beyond the
	    Pakistan ISP's scope (violation of locality), but service
	    was restored in approximately two hours because network
	    operators around the world re-configured their routers to
	    ignore the bogus routes <xref
	    target="RenesysPK"/> (which demonstrates autonomy). In the
	    context of SIDR and secure routing, a similar
	    re-configuration could theoretically be done if a resource certificate
	    were to be revoked in order to block routing to a given
	    network.
	  </t>
	

	  <t>
	    In the DNS realm, one of the recent cases of US law enforcement seizing domain names involved RojaDirecta, a Spanish web site. Even though several of the affected domain names
	    belonged to Spanish entities, they were subject to blocking by the US
	    government because certain servers were operated in the
	    US. Government officials required the operators of the
	    parent zones of a target name (e.g., "com" for
	    "example.com") to direct queries for that name to a set of
	    US-government-operated name servers. Users of other services
	    under a target name (e.g. e-mail) would thus be unable to
	    locate the servers providing services for that name,
	    denying them the ability to access these services
	    (violation of locality).
	  </t>
	
	 <t>
	    Similar work-arounds as those that were used in the Pakistan Telecom case are also available in the DNS case. If a domain name is blocked by changing
	    authoritative records, network operators can restore
	    service simply by extending TTLs on cached pre-blocking
	    records in recursive resolvers, or by statically
	    configuring resolvers to return un-blocked results for the
	    affected name. However, depending on availability of valid signature data, these types of workarounds will not work with DNSSEC signed data. 
	  </t>


	  <t>
	    The action of the Dutch authorities against the RIPE
	    NCC, where RIPE was ordered to freeze the
	    accounts Internet resource holders, is of a similar character. By
	    controlling the account holders' WHOIS information, this type of action limited the ability of the ISPs in question to manage their Internet resources. This example is slightly different from the others because it does not immediately impact the ability of
	    ISPs to provide connectivity. While ISPs use (and trust)
	    the WHOIS databases to build route filters or use the
	    databases for trouble-shooting information, the use of the
	    WHOIS databases for those purposes is voluntary. Thus, 
	    seizure of this sort may not have any immediate effect on network
	    connectivity, but it may impact overall
	    trust in the common infrastructure. It is similar to the other examples in that action in one jurisdiction can have broader effects, violating locality, and in that reduced trust in the global system may encourage networks to develop their own autonomous solutions.
	  </t>
	  
	  <t>
	    Blocking of infrastructure services also has a variety of
	    other implications that may reduce the stability,
	    accessibility, and usability of the global Internet.
	   Infrastructure-based blocking may erode the trust in the general Internet and encourage
	    the development of parallel or "underground" infrastructures causing forms of Internet balkanisation,
	    for example. This risk may become more acute as the introduction of security infrastructures and mechanisms such as DNSSEC and RPKI "hardens" the authoritative data -- including blocked names or routes -- that the existing infrastructure services provide. Those seeking to circumvent the blocks may opt to use less-secure but unblocked parallel services. As applied to the DNS, these considerations are further
	    discussed in ISOC's whitepaper on DNS filtering <xref
	    target="ISOCFiltering"/>, but they also apply to other
	    global Internet resources.
	  </t>
	  	  
	  <t>
	    In summary, infrastructure-based blocking can sometimes be used to
	    immediately block a target service by removing some of the
	    resources it depends on. However, such blocking actions
	    often have harmful side effects due to the global nature
	    of Internet resources. The fact that Internet
	    resources can quickly shift between network locations, names, and addresses, together with the autonomy of the networks that
	    comprise the Internet, can mean that the effects of
	    infrastructure-based blocking can be negated on short order in some cases. To adapt
	    a quote by John Gilmore, "The Internet treats blocking as
	    damage and routes around it".
	  </t>
	  
	</section>     
      
      <section title="Endpoint-Based Blocking" anchor="End-Point-Blocking">
	<t>[TO DO: Should this section only address "user"-based blocking or should it also discuss server-based blocking (e.g., a web server that prevents abusive users from accessing content?)]</t>
	
	<t>
	  Internet users and their devices constantly make decisions
	  as to whether to engage in particular Internet
	  communications.  Users decide whether to click on links in
	  suspect email messages; browsers advise users on sites that
	  have suspicious characteristics; spam filters evaluate the
	  validity of senders and messages. If the hardware and
	  software making these decisions can be instructed not to
	  engage in certain communications, then the communications
	  are effectively blocked because they never happen.
	</t>
	
	<t>
	  There are several systems in place today that advise user
	  systems about which communications they should engage in. As
	  discussed above, several modern browsers consult with "Safe
	  Browsing" services before loading a web site in order to
	  determine whether the site could potentially be
	  harmful. Spam filtering is one of the oldest blocking
	  systems in the Internet; modern blocking systems typically
	  make use of one or more "reputation" or "blacklist"
	  databases in order to make decisions about whether a given
	  message or sender should be blocked.  These systems
	  typically have the property that many blocking systems
	  (browsers, MTAs) share a single reputation service.
	</t>
	
        <t>
	  This approach to blocking is consistent with the Internet
	  architectural principles discussed above, dealing well with
	  the end-to-end principle, layering, mobility, and
	  locality/autonomy.
	</t>
	
        <t>
	  Endpoint-based blocking is
	  performed at one end of an Internet communication, and thus
	  avoids the problems related to end-to-end security
	  mechanisms that intermediary-based blocking runs
	  into. Endpoint-based blocking also lacks some of the
	  limitations of infrastructure-based blocking: while infrastructure-based
	  blocking can only see and affect the infrastructure service at hand (e.g., DNS name resolution), endpoint-based blocking (depending on how it is designed) can have visibility into the
	  entire application, across all layers and transactions. This
	  visibility can provide endpoint-based blocking systems with a
	  much richer set of information on which to make blocking
	  decisions.
	</t>
	
        <t>
	  In particular, endpoint-based blocking deals well with
	  adversary mobility. If a blocked service relocates resources
	  or uses different resources, an infrastructure- or network-based blocking
	  approach may not be able to affect the new resources (at least not immediately). A network-based blocking system may not even be able to
	  tell whether the new resources are being used, if the
	  previously blocked service uses secure protocols. By contrast,
	  endpoint-based blocking systems can detect when a blocked
	  service's resources have changed (because of their full
	  visibility into transactions) and adjust blocking as quickly
	  as new blocking data can be sent out through a reputation
	  system.
	</t>
	
        <t>
	  Finally, in an endpoint-based blocking system, blocking
	  actions are performed autonomously, by individual endpoints
	  or their delegates.  The effects of blocking are thus
	  usually local in scope, minimizing the effects on other
	  users or other, legitimate services.
	</t>
	
        <t>
	  The primary challenge to endpoint-based blocking is that it
	  requires the cooperation of endpoints. Where this
	  cooperation is willing, this is a fairly low barrier,
	  requiring only reconfiguration or software update. Where
	  cooperation is unwilling, it can be challenging to enforce
	  cooperation for large numbers of endpoints.  That challenge
	  is exacerbated when the endpoints are a diverse set of
	  static, mobile or visiting endpoints.  If cooperation can
	  be achieved, endpoint-based blocking can be much more
	  effective than other approaches because it is so coherent
	  with the Internet's architectural principles.
	</t>


      </section>
    </section>
    
    <section title="Summary of Trade-offs">
      <t>
	Network-based blocking is a relatively low-cost blocking
	solution in some cases, but a poor fit with the Internet
	architecture, especially the end-to-end principle. It thus
	suffers from several limitations.
      </t>
      
      <t>
	<list style="symbols">
          <t>
	    Examples: Firewalls, web filtering systems.
	  </t>
	  
          <t>
	    A single intermediary device can be used to block the access
	    of many users to many services.
	  </t>
	  
          <t>
	    Network-based blocking can be done without the cooperation
	    of either endpoint to a communication (although having
	    that cooperation makes it more likely to be effective).
	  </t>
	  
          <t>
	    Network intermediaries often lack sufficient information to make
	    blocking decisions, due to routing asymmetry or
	    encryption.
	  </t>
	  
          <t>
	    Network-based blocking sometimes involves breaking
	    end-to-end security assurances. 
	  </t>
	  
          <t>
	    Tunneling through blocking is difficult to prevent without
	    preventing legitimate secure services.
	  </t>
        </list>
      </t>
      
      <t>
	Infrastructure-based blocking can provide rapid effects for resources
	under the control of the blocking entity, but its ultimate
	effectiveness is limited by the global, autonomous nature of
	Internet resources and networks, and it may create undesirable
	collateral damage to Internet services.
      </t>
      
      <t>
	<list style="symbols">
          <t>
	    Examples: Domain name seizures, WHOIS account freezing,
	    RPKI certificate revocation.
	  </t>
	  
          <t>
	    Internet services that depend on specific resources can be
	    blocked by disabling those resources.
	  </t>
	  
          <t>
	    Blocked resources can often be easily relocated or
	    reinstantiated in a location where they will not be
	    blocked.
	  </t>
	  
          <t>
	    Resources used by undesirable services are often also used
	    by legitimate services, resulting in collateral damage.
	  </t>
	  
          <t>
	    Autonomy of Internet networks and users allows them to
	    "route around" blocking.  [OK Perhaps: Autonomy principle
	    allows users to innovatively find methods to route around
	    the blocking.]

	  </t>
        </list>
      </t>
      
      <t>
	Endpoint-based blocking matches well with the overall design of the
	Internet.
      </t>
      
      <t>
	<list style="symbols">
          <t>
	    Examples: Safe browsing, spam filtering 
	  </t>
	  
          <t>
	    Endpoints block services by deciding whether or not to engage in
	    a given communication.
	  </t>
	  
          <t>
	    Blocking system has full visibility into all layers involved in a
	    communication.
	  </t>
	  
          <t>
	    Adversary mobility can be quickly observed so that blocking
	    systems can be updated to account for it.
	  </t>
	  
          <t>
	    Requires cooperation of endpoints.
	  </t>
        </list>
      </t>
</section>
 
<section title="Conclusion">
     
      <t>
	Because it agrees so well with Internet architectural
	principles, endpoint-based blocking is the form of Internet
	service blocking that is least harmful to the Internet. From a technical perspective, it is the most preferred option because it maintains transparency of the network, vests functionality at the endpoints in accordance with the end-to-end principle, can be applied granularly so as to avoid collateral damage, and accommodates mobile adversaries. Entities seeking to filter and for whom endpoint-based blocking is a potential choice should view its technical benefits as distinct advtanges compared to the other approaches.
      </t>  
      
      <t>
	In reality, the various approaches discussed above are all
	applied for different reasons, and particular entities may not consider endpoint-based filtering to be viable. Often, the choice of a
	filtering solution is constrained by practical limitations on
	which parts of the network are under the control of the entity
	implementing filtering, and which parts of the network are
	trusted to cooperate. For example, an ISP that is subject to
	filtering requirements might implement an intermediary-based
	filtering approach because it cannot be sure that endpoints
	will cooperate in filtering. As discussed above, government
	agencies tasked with disabling certain foreign web sites have
	done so by manipulating infrastructure servers that are within their own
	jurisdictions, based on legal claims to obtain access to those servers. An
	enterprise with filtering requirements might require employees to install a
	certain filtering software package on enterprise-owned PCs.
      </t>
      
      <t>
	It is therefore realistic to expect that certain entities will
	continue to attempt to conduct network- or infrastructure-based
	filtering since they may not have control over the endpoints
	they wish to affect or because the endpoints do not have
	incentives to consent to the filtering. In some cases, an
	approach that combines one of these with endpoint-based
	filtering can help strike a better balance. For example, a
	filtering system might make it possible for some endpoints to
	cooperate or "opt in" to filtering, rather than deploying a
	purely network-based solution.
      </t>
      
    <t>
	While this document has focused on technical mechanisms used
	to filter Internet content, a variety of non-technical
	mechanisms may also be available depending on the particular
	context and goals of the public or private entity seeking to
	restrict access to content. For example, purveyors of illegal
	online content can be pursued through international
	cooperation, by using the criminal justice system, and by
	targeting the funding that supports their activities through
	collaboration with financial services companies <xref
	target="click-trajectories"/>. Thus even in cases where
	endpoint-based filtering is not viewed as a viable means of
	restricting access to content, entities seeking to filter may
	find other strategies for achieving their goals that do not
	involve interfering with the architecture or operation of the
	Internet.
      </t>

      <t>
	Those with a desire to filter should take into account the
	limitations discussed in this document and holistically
	assess the space of technical and non-technical solutions at
	their disposal and the likely effectiveness of each
	combination of approaches.
      </t>
    </section>
    
    <section title="Security Considerations" anchor="security">
      <t>
	The primary security concern related to Internet service
	blocking is the effect that it has on the end-to-end security
	model of many Internet security protocols. When blocking is
	enforced by an intermediary with respect to a given
	communication, the blocking system may need to obtain access
	to confidentiality-protected data to make blocking decisions.
	Mechanisms for obtaining such access typically require the
	blocking system to defeat the authentication mechanisms built
	into security protocols.
      </t>
      
      <t>
	For example, some enterprise firewalls will dynamically create
	TLS certificates under a trust anchor recognized by endpoints
	subject to blocking. These certificates allow the firewall to
	authenticate as any website, so that it can act as a
	man-in-the-middle on TLS connections passing through the
	firewall. This is not unlike an external attacker using compromised certificates to intercept TLS connections.
      </t>
      
      <t>
	Modifications such as these obviously make the firewall itself
	an attack surface. If an attacker can gain control of the
	firewall or compromise the key pair used by the firewall to
	sign certificates, he will have access to the unencrypted data of all
	current and recorded TLS sessions for all users behind that
	firewall, in a way that is undetectable to users. Besides, if
	the compromised key-pairs can be extracted from the firewall
	all users, not only those behind the firewall, that rely on
	that public key are vulnarable.
      </t>
      
      <t>
	When blocking systems are unable to inspect and surgically block secure
	protocols, it is tempting to completely block those protocols. For
	example, a web blocking system that is unable to inspect HTTPS
	connections might simply block any attempted HTTPS connection.
	However, since Internet security protocols are commonly used
	for critical services such as online commerce and banking,
	blocking these protocols would block access to these services
	as well, or worse, force them to be conducted over insecure
	communication.
      </t>
      
      <t>
	Security protocols can, of course, also be used a mechanism
	for blocking services. For example, if a blocking system can
	insert invalid credentials for one party in an authentication
	protocol, then the other end will typically terminate the
	connection based on the authentication failure. However, it is
	typically much simpler to simply block secure protocols than
	to exploit those protocols for service blocking.
      </t>
    </section>
  </middle>
  
  <!--  *****BACK MATTER ***** -->
  
  <back>
    <references title="Informative References">
      &RFC1122;

      &RFC2775;

	  &RFC3261;

      &RFC3724;

      &RFC4033;

      &RFC4084;

      &RFC4301;

      &RFC4924;

      &RFC5246;

      &RFC5782;

      &RFC6480;

      <reference anchor="RojaDirecta"
                 target="http://www.techdirt.com/articles/20110201/10252412910/homeland-security-seizes-spanish-domain-name-that-had-already-been-declared-legal.shtml">
        <front>
          <title>Homeland Security Seizes Spanish Domain Name That Had Already
          Been Declared Legal</title>

          <author fullname="Mike Masnick" initials="M.M." surname="Masnick">
            <organization>TechDirt</organization>
          </author>

          <date year="2011"/>
        </front>
      </reference>

      <reference anchor="US-ICE"
                 target="http://www.ice.gov/doclib/news/library/factsheets/pdf/operation-in-our-sites.pdf">
        <front>
          <title>Operation in Our Sites</title>

          <author>
            <organization>U.S. Immigration and Customs
            Enforcement</organization>
          </author>

          <date year="2011"/>
        </front>
      </reference>

      <reference anchor="SafeBrowsing"
                 target="https://developers.google.com/safe-browsing/">
        <front>
          <title>Safe Browsing API</title>

          <author>
            <organization>Google</organization>
          </author>

          <date year="2012"/>
        </front>
      </reference>

      <reference anchor="GhostClickRIPE"
                 target="http://www.ripe.net/internet-coordination/news/about-ripe-ncc-and-ripe/ripe-ncc-blocks-registration-in-ripe-registry-following-order-from-dutch-police">
        <front>
          <title>RIPE NCC Blocks Registration in RIPE Registry Following Order
          from Dutch Police</title>

          <author>
            <organization>RIPE NCC</organization>
          </author>

          <date year="2012"/>
        </front>
      </reference>

      <reference anchor="Telex" target="https://telex.cc/">
        <front>
          <title>Telex: Anticensorship in the Network Infrastructure</title>

          <author fullname="Eric Wustrow" initials="E." surname="Wustrow"/>

          <author fullname="Scott Wolchok" initials="S." surname="Wolchok"/>

          <author fullname="Ian Goldberg" initials="I." surname="Goldberg"/>

          <author fullname="J. Alex Halderman" initials="J.A."
                  surname="Halderman"/>

          <date month="August" year="2011"/>
        </front>
      </reference>

      <reference anchor="RenesysPK"
                 target="http://www.renesys.com/blog/2008/02/pakistan_hijacks_youtube_1.shtml">
        <front>
          <title>Pakistan hijacks YouTube</title>

          <author fullname="Martin A. Brown" initials="M." surname="Brown">
            <organization>Renesys</organization>
          </author>

          <date month="February" year="2008"/>
        </front>
      </reference>

      <reference anchor="EarthquakeHT"
                 target="http://www.apricot.net/apricot2010/__data/assets/pdf_file/0019/19018/Lightning-Talk_03_Gaurab-Upadhaya-dotht-apricot-lightning.pdf">
        <front>
          <title>.ht: Recovering DNS from the Quake</title>

          <author fullname="Gaurab Raj Upadhaya" initials="G."
                  surname="Raj Upadhaya">
            <organization>PCH</organization>
          </author>

          <date month="March" year="2010"/>
        </front>
      </reference>

      <reference anchor="ISOCFiltering"
                 target="http://www.internetsociety.org/what-we-do/issues/dns/finding-solutions-illegal-line-activities">
        <front>
          <title>DNS: Finding Solutions to Illegal On-line Activities</title>

          <author fullname="" initials="" surname="">
            <organization>Internet Society</organization>
          </author>

          <date month="" year="2012"/>
        </front>
      </reference>

      <reference anchor="Tor" target="https://www.torproject.org/">
        <front>
          <title>Tor Project: Anonymity Online</title>

          <author fullname="" initials="" surname=""/>

          <date month="" year="2012"/>
        </front>
      </reference>

      <reference anchor="click-trajectories"
                 target="http://cseweb.ucsd.edu/~savage/papers/Oakland11.pdf">
        <front>
          <title>Click Trajectories: End-to-End Analysis of the Spam Value
          Chain</title>

          <author fullname="Kirill Levchenko" initials="K."
                  surname="Levchenko"/>

          <author fullname="Andreas Pitsillidis" initials="A."
                  surname="Pitsillidis"/>

          <author fullname="Neha Chachra" initials="N." surname="Chacra"/>

          <author fullname="Brandon Enright" initials="B." surname="Enright"/>

          <author fullname="Mark Felegyhazi" initials="M."
                  surname="Felegyhazi"/>

          <author fullname="Chris Grier" initials="C." surname="Grier"/>

          <author fullname="Tristan Halvorson" initials="T."
                  surname="Halvorson"/>

          <author fullname="Christian Kreibich" initials="C."
                  surname="Kreibich"/>

          <author fullname="He Liu" initials="H." surname="Liu"/>

          <author fullname="Damon McCoy" initials="D." surname="McCoy"/>

          <author fullname="Nicholas Weaver" initials="N." surname="Weaver"/>

          <author fullname="Vern Paxson" initials="V." surname="Paxson"/>

          <author fullname="Geoffrey M. Voelker" initials="G.M."
                  surname="Voelker"/>

          <author fullname="Stefan Savage" initials="S." surname="Savage"/>

          <date month="" year="2011"/>
        </front>
      </reference>

      <reference anchor="BT-TPB"
                 target="http://www.zdnet.com/bt-blocks-the-pirate-bay-4010026434/">
        <front>
          <title>BT blocks The Pirate Bay</title>

          <author fullname="David Meyer" initials="D." surname="Meyer"/>

          <date day="20" month="June" year="2012"/>
        </front>
      </reference>

      <reference anchor="TPB-cloud" target="http://thepiratebay.se/blog/224">
        <front>
          <title>The Pirate Cloud</title>

          <author/>

          <date day="17" month="October" year="2012"/>
        </front>
      </reference>

      <reference anchor="IN-OM-filtering"
                 target="https://citizenlab.org/2012/07/routing-gone-wild/">
        <front>
          <title>Routing Gone Wild</title>

          <author fullname="Citizen Lab" surname="Citizen Lab"/>

          <date day="12" month="July" year="2012"/>
        </front>
      </reference>

     

      <reference anchor="CCS-GFC-collateral-damage"
                 target="http://conferences.sigcomm.org/sigcomm/2012/paper/ccr-paper266.pdf">
        <front>
          <title>The Collateral Damage of Internet Censorship by DNS
          Injection</title>

          <author/>

          <date day="" month="July" year="2012"/>
        </front>
      </reference>

      <reference anchor="SAC-056"
		 target="http://www.icann.org/en/groups/ssac/documents/sac-056-en.pdf">
	<front>
	  <title>SSAC Advisory on Impacts of Content Blocking via the Domain Name System</title>
	  <author/>
	  <date day="09" month="October" year="2012"/>

	</front>
      </reference>

	<reference anchor="Morris"
                 target="http://groups.csail.mit.edu/mac/classes/6.805/articles/morris-worm.html">
        <front>
          <title>The Robert Morris Internet Worm</title>

          <author fullname="Brendan P. Kehoe" initials="B.P." surname="Kehoe"/>

          <date year="1992"/>
        </front>
      </reference>

	<reference anchor="Malicious-Resolution"
                 target="http://www.citi.umich.edu/u/provos/papers/ndss08_dns.pdf">
        <front>
          <title>Corrupted DNS Resolution Paths: The Rise of a Malicious Resolution Authority</title>

          <author fullname="David Dagon" initials="D." surname="Dagon"/>
		  <author fullname="Niels Provos" initials="N." surname="Provos"/>
		 <author fullname="Christopher P. Lee" initials="C.P." surname="Lee"/>
		 <author fullname="Wenke Lee" initials="W." surname="Lee"/>

          <date year="2008"/>
        </front>
      </reference>

    </references>
  </back>
</rfc>

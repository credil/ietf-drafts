<?xml version="1.0" encoding="US-ASCII"?>
<!-- This template is for creating an Internet Draft using xml2rfc,
     which is available here: http://xml.resource.org. -->
<!DOCTYPE rfc SYSTEM "rfc2629.dtd" [
<!-- One method to get references from the online citation libraries.
     There has to be one entity for each item to be referenced.
     An alternate method (rfc include) is described in the references. -->

<!ENTITY RFC0821 SYSTEM "http://xml.resource.org/public/rfc/bibxml/reference.RFC.0821.xml">
<!ENTITY RFC2821 SYSTEM "http://xml.resource.org/public/rfc/bibxml/reference.RFC.2821.xml">
<!ENTITY RFC5321 SYSTEM "http://xml.resource.org/public/rfc/bibxml/reference.RFC.5321.xml">
]>

<?xml-stylesheet type='text/xsl' href='rfc2629.xslt' ?>
<!-- used by XSLT processors -->
<!-- For a complete list and description of processing instructions (PIs),
     please see http://xml.resource.org/authoring/README.html. -->
<!-- Below are generally applicable Processing Instructions (PIs) that most I-Ds might want to use.
     (Here they are set differently than their defaults in xml2rfc v1.32) -->
<?rfc strict="yes" ?>
<!-- give errors regarding ID-nits and DTD validation -->
<!-- control the table of contents (ToC) -->
<?rfc toc="yes"?>
<!-- generate a ToC -->
<?rfc tocdepth="4"?>
<!-- the number of levels of subsections in ToC. default: 3 -->
<!-- control references -->
<?rfc symrefs="yes"?>
<!-- use symbolic references tags, i.e, [RFC2119] instead of [1] -->
<?rfc sortrefs="yes" ?>
<!-- sort the reference entries alphabetically -->
<!-- control vertical white space
     (using these PIs as follows is recommended by the RFC Editor) -->
<?rfc compact="yes" ?>
<!-- do not start each main section on a new page -->
<?rfc subcompact="no" ?>
<!-- keep one blank line between list items -->
<!-- end of list of popular I-D processing instructions -->
<rfc 
     category="std"
     docName="draft-gellens-negotiating-human-language-02"
     ipr="trust200902"
    >
  <!-- category values: std, bcp, info, exp, and historic
     ipr values: full3667, noModification3667, noDerivatives3667
     you can add the attributes updates="NNNN" and obsoletes="NNNN"
     they will automatically be output with "(if approved)" -->

  <!-- ***** FRONT MATTER ***** -->

  <front>
    <!-- The abbreviated title is used in the page header - it is only necessary if the
         full title is longer than 39 characters -->

    <title abbrev="Negotiating Human Language">Negotiating Human Language Using SDP
    </title>

    <author fullname="Randall Gellens" initials="R." 
            surname="Gellens">
      <organization>Qualcomm Technologies, Inc.</organization>

      <address>
        <postal>
          <street>5775 Morehouse Drive</street>

          <!-- Reorder these if your country does things differently -->

          <city>San Diego</city>
          <region>CA</region>
          <code>92121</code>

          <country>US</country>
        </postal>

        <email>rg+ietf@qti.qualcomm.com</email>
      </address>
    </author>

    <date  year="2013" />

    <!-- If the month and year are both specified and are the current ones, xml2rfc will fill
         in the current day for you. If only the current year is specified, xml2rfc will fill
     in the current day and month for you. If the year is not the current one, it is
     necessary to specify at least a month (xml2rfc assumes day="1" if not specified for the
     purpose of calculating the expiry date).  With drafts it is normally sufficient to
     specify just the year. -->

    <!-- Meta-data Declarations -->

    <area>Real-time Applications and Infrastructure</area>

    <workgroup>MMUSIC Working Group</workgroup>

    <keyword>SDP</keyword>
    <keyword>language</keyword>
    <keyword>human language</keyword>

    <!-- Keywords will be incorporated into HTML output
         files in a meta tag but they have no effect on text or nroff
         output. If you submit your draft to the RFC Editor, the
         keywords will be used for the search engine. -->

    <abstract>
      <t>
      Users have various human (natural) language needs, abilities, and preferences regarding spoken, written, and signed languages.  When establishing interactive communication "calls" there needs to be a way to communicate and ideally match (i.e., negotiate) the caller's language needs, abilities, and preferences with the capabilities of the called party.  This is especially important with emergency calling, where a call can be routed to a PSAP or call taker capable of communicating with the user, or a translator or relay operator can be bridged into the call during setup, but this applies to non-emergency calls as well (as an example, when calling an airline reservation desk).
      </t>
      <t>
      This document describes the need and expected use, and discusses the solution using either an existing or new SDP attribute.
      </t>

    </abstract>

  </front>

  <middle>

    <section title="Introduction">
      <t>
      When setting up interactive communication sessions, human (natural) language negotiation is needed in some cases.  When the caller and callee are known to each other or where context implies language, such language negotiation may not be needed.  In other cases, there is a need for the caller to indicate language preferences, abilities, or needs, including specific spoken, signed, or written languages.  This need exists when setting up SIP or other sessions (including emergency and non-emergency calling).  For various reasons, including the ability to establish multiple streams each using a different media (e.g., voice, text, video), it makes sense to use a per-stream negotiation mechanism, using SDP.
      </t>
      <t>This approach has a number of benefits, including that it is generic and not limited to emergency calls.  In some cases such a facility isn't needed, because the language is known from the context (such as when a caller places a call to a sign language relay center).  But it seems clearly useful in many other cases.  For example, it seems generally useful that someone calling a company call center be able to indicate if a specific sign and/or spoken language is needed.  The UE would need to set this, but could default to the language used for the interface with the user. 
      </t>
      <t>
      Including the user's human (natural) language requirements in the session establishment negotiation is independent of the use of a relay service and is transparent to a voice service provider.  For example, assume a user within the United States who speaks Spanish but not English places a voice call using an IMS device.  It doesn't matter if the call is an emergency call or not (e.g., to an airline reservation desk).  The language information is transparent to the IMS carrier, but is part of the session negotiation between the UE and the terminating entity.  In the case of a call to e.g., an airline, the call can be automatically routed to a Spanish-speaking agent.  In the case of an emergency call, the ESInet and the PSAP may choose to take the language into account when determining how to route and process the call (e.g., language and media needs may be considered within policy-based routing).
      </t>

    <t>
    By treating language as another attribute that is negotiated along with other aspects of a media stream, it becomes possible to accommodate a wide range of users' needs and called party facilities.  For example, some users may be able to speak several languages, but have a preference.  Some called parties may support some of those languages internally but require the use of a translation service for others, or may have a limited number of call takers able to use certain languages.  Another example would be a user who is able to speak but is deaf or hard-of-hearing and requires a voice stream plus a text stream (known as voice carry over).  Making language a media attribute allows the standard session negotiation mechanism to handle this by providing the information and mechanism for the endpoints to make appropriate decisions.
    </t>

    <t>
    Regarding relay services, in the case of an emergency call requiring sign language such as ASL, there are two common approaches: the caller initiates the call to a relay center, or the caller places the call to emergency services (e.g., 911 or 112).  In the former case, the language need is ancillary and supplemental.  In the latter case, the ESInet and/or PSAP may take the need for sign language into account and bridge in a relay center.  In this case, the ESInet and PSAP have all the standard information available (such as location) but are able to bridge the relay sooner in the call processing.
    </t>

    <t>
    By making this facility part of the end-to-end negotiation, the question of which entity provides or engages the relay service becomes separate from the call processing mechanics; if the caller directs the call to a relay service then the human language facility provides extra information to the relay service but calls will still function without it; if the caller directs the call to emergency services, then the ESInet/PSAP are able to take the user's human language needs into account, e.g., by routing to a particular PSAP or call taker or bridging a relay service or translator.
    </t>
    
    <t>
    The term "negotiation" is used here rather than "indication" because human language (spoken/written/signed) is something that can be negotiated in the same way as which forms of media (audio/text/video) or which codecs.
    For example, if we think of non-emergency calls, such as a user calling an airline reservation center, the user may have a set of languages he or she speaks, with perhaps preferences for one or a few, while the airline reservation center will support a fixed set of languages.  Negotiation should select whichever language supported by the call center is most preferred by the user.  Both sides should be aware of which language was negotiated.  This is conceptually similar to the way other aspects of each media stream are negotiated using SDP (e.g., media type and codecs).
    </t>
    </section>
    
    <section title="Terminology">
      <t> The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD
        NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this document are to be interpreted as
        described in <xref target="RFC2119">RFC 2119</xref>.</t>
    </section>

    <section title="Expected Use">
    <t>
    This facility is expected to be used by NENA and 3GPP.  NENA is likely to reference it in NENA 08-01 (i3 Stage 3) in describing attributes of calls presented to an ESInet, and in that or other documents describing Policy-Based Routing capabilities within a Policy-Based Routing Function (PCRF).  3GPP is expected to reference this mechanism in general call handling and emergency call handling.  Recent CRs introduced in SA1 have anticipated this functionality being provided within SDP.
    </t>
    </section>

    <section title="Desired Semantics">
    <t>
    The desired solution is a media attribute that may be used
    within an offer to indicate the preferred language of each
    media stream, and within an answer to indicate the accepted
    language.  The semantics of including multiple values for a media stream within
    an offer is that the languages are listed in order of
    preference.
    </t>
    
    <t>
    (While it is true that a conversation among multilingual people often involves multiple languages, it does not seem useful enough as a general facility to warrant complicating the desired semantics of the SDP attribute to allow negotiation of multiple simultaneous languages within an interactive media stream.)
    </t>
    </section>

    <section title="Proposed Solution">
    <t>
    An SDP attribute seems the natural choice to negotiate human (natural) language of an interactive media stream.  The attribute value should be a language tag from RFC 4566 <xref target="RFC4566"/> or the IANA registry
    <xref target="IANA-lang-tags"/>
    </t>
    
    <section title="Possibility: Re-Use existing 'lang' attribute">
    
    <t>
    RFC 4566 specifies an attribute 'lang' which sounds similar to what is needed here, the difference being that it specifies that 'a=lang' is declarative with the semantics of multiple 'lang' attributes being that all of them are used, while we want a means to negotiate which one is used in each stream.  This difference means that either the existing 'lang' attribute can't be used and we need to define a new attribute; or we finese/update the semantics of 'lang' such that the existing semantics apply to non-interactive streams (multiple 'lang' values means all are used), while for interactive streams, one is used; (or possibly the author of this memo has misunderstood RFC 4566).
    </t>

    <t>
    The text from RFC 4566 <xref target="RFC4566"/> is:
    </t>

    <t>
    <list>
        <t>
        a=lang:&lt;language tag&gt;
        </t>

        <t>
         This can be a session-level attribute or a media-level
         attribute.  As a session-level attribute, it specifies the
         default language for the session being described.  As a media-
         level attribute, it specifies the language for that media,
         overriding any session-level language specified.  Multiple lang
         attributes can be provided either at session or media level if
         the session description or media use multiple languages, in
         which case the order of the attributes indicates the order of
         importance of the various languages in the session or media
         from most important to least important.
        </t>

        <t>
         The "lang" attribute value must be a single <xref target="RFC3066"/> language
         tag in US-ASCII <xref target="RFC3066"/>.  It is not dependent on the charset
         attribute.  A "lang" attribute SHOULD be specified when a
         session is of sufficient scope to cross geographic boundaries
         where the language of recipients cannot be assumed, or where
         the session is in a different language from the locally assumed
         norm.
        </t>
    </list>
    </t>
        
    <t>
The question is: Can the 'lang' attribute be used for our purposes?  Using it to negotiate the language for a media seems at first glance to violate its semantics as defined in RFC 4566 <xref target="RFC4566"/>.  But there are existing examples of it being used in exactly the way we need.  For example, draft-saintandre-sip-xmpp-chat-04 <xref target="I-D.saintandre-sip-xmpp-chat"/> contains an example where the initial invitation contains two 'a=lang' entries for a media stream (for English and Italian) and the OK accepts one of them (Italian), which matches what we need:
    </t>

    <t>
    <list>
    <t>
   Example: (F1) SIP user starts the session
    </t>
    </list>
    </t>

    <figure>
    <artwork>
        INVITE sip:juliet@example.com SIP/2.0
        To: &lt;sip:juliet@example.com&gt;
        From: &lt;sip:romeo@example.net&gt;;tag=576
        Subject: Open chat with Romeo?
        Call-ID: 742507no
        Content-Type: application/sdp
        
        c=IN IP4 s2x.example.net
        m=message 7313 TCP/MSRP *
        a=accept-types:text/plain
        a=lang:en
        a=lang:it
        a=path:msrp://s2x.example.net:7313/ansp71weztas;tcp
   </artwork>
   </figure>
 
 
    <t>
    <list>
    <t>
   Example: (F2) Gateway accepts session on Juliet's behalf
    </t>
    </list>
    </t>

    <figure>
    <artwork>
        SIP/2.0 200 OK
        To: &lt;sip:juliet@example.com&gt;;tag=534
        From: &lt;sip:romeo@example.net&gt;;tag=576
        Call-ID: 742507no
        Content-Type: application/sdp
        
        c=IN IP4 x2s.example.com
        m=message 8763 TCP/MSRP *
        a=accept-types:text/plain
        a=lang:it
        a=path:msrp://x2s.example.com:8763/lkjh37s2s20w2a;tcp
    </artwork>
    </figure>

    <t>
    To re-use the existing 'lang' attribute, we'd update its registration to specify that for non-interactive media, multiple
    'lang' values in an offer have the existing RFC 4566 <xref target="RFC4566"/> semantics (all languages are used in the media), while for interactive media streams, one of the values should be selected in the answer and that language used in the media stream.
    </t>

    </section>

    <section title="Possibility: Define new 'humintlang' attribute">
    
    <t>
    Instead of re-using 'lang' we may define a new media-level attribute 'humintlang' (short for "human interactive language") to negotiate which human language is used in each (interactive) media stream:
    </t>

    <t>
    <list>
        <t>
        a=humintlang:&lt;language tag&gt;
        </t>

        <t>
         This is a media-level attribute.  In an offer, it specifies the desired language(s) for the media.  Multiple "humintlang"
         attributes can be provided in an offer for a media stream, in
         which case the order of the attributes indicates the order of
         preference of the various languages
         from most preferred to least preferred.  When the "humintlang"
         attribute appears within an answer it indicates the accepted language for the media.
        </t>

        <t>
         The "humintlang" attribute value MUST be a language tag per RFC 5646 <xref target="RFC5646"/>.  A "humintlang" attribute SHOULD be specified for each media stream in an offer when placing an emergency call (to avoid ambiguity) and in any other case where the language cannot be assumed from context.
        </t>

        <t>
        When an offer includes media with one or more language tags, each accepted media in the answer MUST include one of the language tags offered for the media.
        RFC 5646 describes mechanisms for matching language tags.
        </t>
    </list>
    </t>
    </section>

    </section>

    <section title="Silly States">
    <t>
    It's possible to specify a "silly state" where the language specified does not make sense for the media type, such as specifying a signed language for an audio media stream.
    </t>
    
    <t>
    An offer MUST NOT be created where the language does not make sense for the media type.  If such an offer is received, the receiver MAY reject the media, ignore the language specified, or attempt to interpret the intent (e.g., if American Sign Language is specified for an audio media stream, this might be interpreted as a desire to use spoken English). 
    </t>
    </section>


    <section title="IANA Considerations">
      <t>
      TBD.
      </t>
    </section>

    <section title="Security Considerations">
      <t>
      TBD
      </t>
    </section>

    <section title="Changes from Previous Versions">
      <section title="Changes from -00 to -01">
        <t>
        <list style="symbols">
            <t>Changed name of (possible) new attribute from 'humlang" to "humintlang"</t>
            <t>Added discussion of silly state (language not appropriate for media type)</t>
            <t>Added Voice Carry Over example</t>
            <t>Added mention of multilingual people and multiple languages</t>
            <t>Minor text clarifications</t>
        </list>
        </t>
      </section>

        <section title="Changes from -01 to -02">
        <t>
        <list style="symbols">
            <t>Updated text for (possible) new attribute "humintlang" to reference RFC 5646</t>
            <t>Added clarifying text for (possible) re-use of existing 'lang' attribute saying that the registration would be updated to reflect different semantics for multiple values for interactive versus non-interactive media.</t>
            <t>Added clarifying text for (possible) new attribute "humintlang" to attempt to better describe the role of language tags in media in an offer and an answer.</t>
        </list>
        </t>
      </section>

    </section>

    <section title="Acknowledgments">
      <t>Many thanks to Doug Ewell for his review and corrections/suggestions.</t>
    </section>

  </middle>

  <!--  *****BACK MATTER ***** -->

  <back>
    <!-- References split into informative and normative -->

    <!-- There are 2 ways to insert reference entries from the citation libraries:
     1. define an ENTITY at the top, and use "ampersand character"RFC2629; here (as shown)
     2. simply use a PI "less than character"?rfc include="reference.RFC.2119.xml"?> here
        (for I-Ds: include="reference.I-D.narten-iana-considerations-rfc2434bis.xml")

     Both are cited textually in the same manner: by using xref elements.
     If you use the PI option, xml2rfc will, by default, try to find included files in the same
     directory as the including file. You can also define the XML_LIBRARY environment variable
     with a value containing a set of directories to search.  These can be either in the local
     filing system or remote ones accessed by http (http://domain/dir/... ).-->

    <references title="Normative References">
      <?rfc include="reference.RFC.2119" ?>
      <?rfc include="reference.RFC.4566"?>
      <?rfc include="reference.RFC.5646"?>
    </references>
    <references title="Informational References">
      <?rfc include="reference.RFC.3066"?>
      <?rfc include="reference.I-D.saintandre-sip-xmpp-chat"?>
      <?rfc include="reference.I-D.iab-privacy-considerations"?>    
      
    <reference anchor="IANA-lang-tags" target="www.iana.org/assignments/language-subtag-registry">
        <front>
        <title>IANA Language Subtag Registry</title>
        <author/>
        <date/>
        </front>
    </reference>

    </references>



  </back>
</rfc>
